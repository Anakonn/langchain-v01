---
canonical: https://python.langchain.com/v0.1/docs/integrations/providers/ollama
translated: false
---

# Ollama

>[Ollama](https://ollama.ai/) is a python library. It allows you to run open-source large language models,
> such as LLaMA2, locally.
>
>`Ollama` bundles model weights, configuration, and data into a single package, defined by a Modelfile.
>It optimizes setup and configuration details, including GPU usage.
>For a complete list of supported models and model variants, see the [Ollama model library](https://ollama.ai/library).

See [this guide](/docs/guides/development/local_llms#quickstart) for more details
on how to use `Ollama` with LangChain.

## Installation and Setup

Follow [these instructions](https://github.com/jmorganca/ollama?tab=readme-ov-file#ollama)
to set up and run a local Ollama instance.
To use, you should set up the environment variables `ANYSCALE_API_BASE` and
`ANYSCALE_API_KEY`.

## LLM

```python
<!--IMPORTS:[{"imported": "Ollama", "source": "langchain_community.llms", "docs": "https://api.python.langchain.com/en/latest/llms/langchain_community.llms.ollama.Ollama.html", "title": "Ollama"}]-->
from langchain_community.llms import Ollama
```

See the notebook example [here](/docs/integrations/llms/ollama).

## Chat Models

### Chat Ollama

```python
<!--IMPORTS:[{"imported": "ChatOllama", "source": "langchain_community.chat_models", "docs": "https://api.python.langchain.com/en/latest/chat_models/langchain_community.chat_models.ollama.ChatOllama.html", "title": "Ollama"}]-->
from langchain_community.chat_models import ChatOllama
```

See the notebook example [here](/docs/integrations/chat/ollama).

### Ollama functions

```python
<!--IMPORTS:[{"imported": "OllamaFunctions", "source": "langchain_experimental.llms.ollama_functions", "docs": "https://api.python.langchain.com/en/latest/llms/langchain_experimental.llms.ollama_functions.OllamaFunctions.html", "title": "Ollama"}]-->
from langchain_experimental.llms.ollama_functions import OllamaFunctions
```

See the notebook example [here](/docs/integrations/chat/ollama_functions).

## Embedding models

```python
<!--IMPORTS:[{"imported": "OllamaEmbeddings", "source": "langchain_community.embeddings", "docs": "https://api.python.langchain.com/en/latest/embeddings/langchain_community.embeddings.ollama.OllamaEmbeddings.html", "title": "Ollama"}]-->
from langchain_community.embeddings import OllamaEmbeddings
```

See the notebook example [here](/docs/integrations/text_embedding/ollama).