---
translated: true
---

# Rememberizer

>[Rememberizer](https://rememberizer.ai/) es un servicio de mejora del conocimiento para aplicaciones de IA creado por SkyDeck AI Inc.

Este cuaderno muestra cómo recuperar documentos de `Rememberizer` en el formato de Documento que se utiliza posteriormente.

# Preparación

Necesitarás una clave API: puedes obtenerla después de crear un conocimiento común en [https://rememberizer.ai](https://rememberizer.ai/). Una vez que tengas una clave API, debes establecerla como una variable de entorno `REMEMBERIZER_API_KEY` o pasarla como `rememberizer_api_key` al inicializar `RememberizerRetriever`.

`RememberizerRetriever` tiene estos argumentos:
- opcional `top_k_results`: predeterminado=10. Úsalo para limitar el número de documentos devueltos.
- opcional `rememberizer_api_key`: requerido si no estableces la variable de entorno `REMEMBERIZER_API_KEY`.

`get_relevant_documents()` tiene un argumento, `query`: texto libre que se usa para encontrar documentos en el conocimiento común de `Rememberizer.ai`

# Ejemplos

## Uso básico

```python
# Setup API key
from getpass import getpass

REMEMBERIZER_API_KEY = getpass()
```

```python
import os

from langchain_community.retrievers import RememberizerRetriever

os.environ["REMEMBERIZER_API_KEY"] = REMEMBERIZER_API_KEY
retriever = RememberizerRetriever(top_k_results=5)
```

```python
docs = retriever.get_relevant_documents(query="How does Large Language Models works?")
```

```python
docs[0].metadata  # meta-information of the Document
```

```output
{'id': 13646493,
 'document_id': '17s3LlMbpkTk0ikvGwV0iLMCj-MNubIaP',
 'name': 'What is a large language model (LLM)_ _ Cloudflare.pdf',
 'type': 'application/pdf',
 'path': '/langchain/What is a large language model (LLM)_ _ Cloudflare.pdf',
 'url': 'https://drive.google.com/file/d/17s3LlMbpkTk0ikvGwV0iLMCj-MNubIaP/view',
 'size': 337089,
 'created_time': '',
 'modified_time': '',
 'indexed_on': '2024-04-04T03:36:28.886170Z',
 'integration': {'id': 347, 'integration_type': 'google_drive'}}
```

```python
print(docs[0].page_content[:400])  # a content of the Document
```

```output
before, or contextualized in new ways. on some level they " understand " semantics in that they can associate words and concepts by their meaning, having seen them grouped together in that way millions or billions of times. how developers can quickly start building their own llms to build llm applications, developers need easy access to multiple data sets, and they need places for those data sets
```

# Uso en una cadena

```python
OPENAI_API_KEY = getpass()
```

```python
os.environ["OPENAI_API_KEY"] = OPENAI_API_KEY
```

```python
from langchain.chains import ConversationalRetrievalChain
from langchain_openai import ChatOpenAI

model = ChatOpenAI(model_name="gpt-3.5-turbo")
qa = ConversationalRetrievalChain.from_llm(model, retriever=retriever)
```

```python
questions = [
    "What is RAG?",
    "How does Large Language Models works?",
]
chat_history = []

for question in questions:
    result = qa.invoke({"question": question, "chat_history": chat_history})
    chat_history.append((question, result["answer"]))
    print(f"-> **Question**: {question} \n")
    print(f"**Answer**: {result['answer']} \n")
```

```output
-> **Question**: What is RAG?

**Answer**: RAG stands for Retrieval-Augmented Generation. It is an AI framework that retrieves facts from an external knowledge base to enhance the responses generated by Large Language Models (LLMs) by providing up-to-date and accurate information. This framework helps users understand the generative process of LLMs and ensures that the model has access to reliable information sources.

-> **Question**: How does Large Language Models works?

**Answer**: Large Language Models (LLMs) work by analyzing massive data sets of language to comprehend and generate human language text. They are built on machine learning, specifically deep learning, which involves training a program to recognize features of data without human intervention. LLMs use neural networks, specifically transformer models, to understand context in human language, making them better at interpreting language even in vague or new contexts. Developers can quickly start building their own LLMs by accessing multiple data sets and using services like Cloudflare's Vectorize and Cloudflare Workers AI platform.
```
