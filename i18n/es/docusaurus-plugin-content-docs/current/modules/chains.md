---
hide_table_of_contents: true
sidebar_class_name: hidden
sidebar_position: 3
title: Cadenas
translated: true
---

Las cadenas se refieren a secuencias de llamadas, ya sea a un LLM, una herramienta o un paso de preprocesamiento de datos. La forma principal de hacer esto es con [LCEL](/docs/expression_language).

LCEL es excelente para construir tus cadenas, pero también es bueno tener cadenas listas para usar. Hay dos tipos de cadenas listas para usar que LangChain admite:

- Cadenas que se construyen con LCEL. En este caso, LangChain ofrece un método constructor de alto nivel. Sin embargo, todo lo que se hace bajo el capó es construir una cadena con LCEL.
- Cadenas [Legacy] construidas mediante la subclase de una clase `Chain` heredada. Estas cadenas no usan LCEL bajo el capó, sino que son clases independientes.

Estamos trabajando en crear métodos que creen versiones LCEL de todas las cadenas. Hacemos esto por varias razones.

1. Las cadenas construidas de esta manera son agradables porque si deseas modificar los internos de una cadena, simplemente puedes modificar el LCEL.
2. Estas cadenas admiten nativamente el streaming, async y batch de forma predeterminada.
3. Estas cadenas obtienen automáticamente observabilidad en cada paso.

Esta página contiene dos listas. Primero, una lista de todos los constructores de cadenas LCEL. Segundo, una lista de todas las cadenas Legacy.

## Cadenas LCEL

A continuación se muestra una tabla de todos los `constructores de cadenas LCEL`.

Columnas de la tabla:

- **Constructor de Cadena:** La función constructora para esta cadena. Todos estos métodos devuelven LCEL Runnables. También enlazamos a la documentación de la API.
- **Llamada de Función:** Si esto requiere llamada de función OpenAI.
- **Otras Herramientas:** Otras herramientas (si las hay) utilizadas en esta cadena.
- **Cuándo Usar:** Nuestro comentario sobre cuándo usar esta cadena.

| Constructor de Cadena                | Llamada de Función      | Otras Herramientas  | Cuándo Usar                                                                    |
|--------------------------------------|-------------------------|---------------------|--------------------------------------------------------------------------------|
| [create_stuff_documents_chain](https://api.python.langchain.com/en/latest/chains/langchain.chains.combine_documents.stuff.create_stuff_documents_chain.html#langchain.chains.combine_documents.stuff.create_stuff_documents_chain)     |                         |                     | Esta cadena toma una lista de documentos y los formatea todos en un prompt, luego pasa ese prompt a un LLM. Pasa TODOS los documentos, por lo que debes asegurarte de que quepa dentro de la ventana de contexto del LLM que estás usando. |
| [create_openai_fn_runnable](https://api.python.langchain.com/en/latest/chains/langchain.chains.structured_output.base.create_openai_fn_runnable.html#langchain.chains.structured_output.base.create_openai_fn_runnable)     | ✅ |                     | Si deseas usar la llamada de función de OpenAI para estructurar OPCIONALMENTE una respuesta de salida. Puedes pasar múltiples funciones para su llamada, pero no tiene que llamarla.                                     |
| [create_structured_output_runnable](https://api.python.langchain.com/en/latest/chains/langchain.chains.structured_output.base.create_structured_output_runnable.html#langchain.chains.structured_output.base.create_structured_output_runnable)   | ✅ |                     | Si deseas usar la llamada de función de OpenAI para FORZAR al LLM a responder con una determinada función. Solo puedes pasar una función, y la cadena SIEMPRE devolverá esta respuesta.                                      |
| [load_query_constructor_runnable](https://api.python.langchain.com/en/latest/chains/langchain.chains.query_constructor.base.load_query_constructor_runnable.html#langchain.chains.query_constructor.base.load_query_constructor_runnable)  |                         |                     | Puede usarse para generar consultas. Debes especificar una lista de operaciones permitidas y luego devolver un runnable que convierta una consulta en lenguaje natural en esas operaciones permitidas.                                                                               |
| [create_sql_query_chain](https://api.python.langchain.com/en/latest/chains/langchain.chains.sql_database.query.create_sql_query_chain.html#langchain.chains.sql_database.query.create_sql_query_chain)           |                         | Base de Datos SQL  | Si deseas construir una consulta para una base de datos SQL a partir de lenguaje natural.                            |
| [create_history_aware_retriever](https://api.python.langchain.com/en/latest/chains/langchain.chains.history_aware_retriever.create_history_aware_retriever.html#langchain.chains.history_aware_retriever.create_history_aware_retriever)   |                         | Retriever          | Esta cadena toma el historial de la conversación y luego lo usa para generar una consulta de búsqueda que se pasa al retriever subyacente.                       |
| [create_retrieval_chain](https://api.python.langchain.com/en/latest/chains/langchain.chains.retrieval.create_retrieval_chain.html#langchain.chains.retrieval.create_retrieval_chain)           |                         | Retriever          | Esta cadena toma una consulta del usuario, que luego se pasa al retriever para obtener documentos relevantes. Esos documentos (y entradas originales) se pasan luego a un LLM para generar una respuesta.      |

## Cadenas Legadas

A continuación se presentan las `cadenas legadas`. Mantendremos el soporte para estas hasta que creemos una alternativa LCEL.

Columnas de la tabla:

- **Cadena:** Nombre de la cadena o nombre del método del constructor. Si es un método del constructor, esto devolverá una subclase de `Chain`.
- **Llamada de Función:** Si la cadena requiere Llamada de Función de OpenAI.
- **Otras Herramientas:** Otras herramientas usadas en la cadena.
- **Cuándo Usar:** Nuestro comentario sobre cuándo usar.

| Cadena                        |  Llamada de Función | Otras Herramientas            | Cuándo Usar |
|------------------------------|--------------------|------------------------|-------------|
| [APIChain](https://api.python.langchain.com/en/latest/chains/langchain.chains.api.base.APIChain.html#langchain.chains.api.base.APIChain)                    |                                            | Requests Wrapper               | Esta cadena usa un LLM para convertir una consulta en una solicitud de API, luego ejecuta esa solicitud, obtiene una respuesta y luego pasa esa solicitud a un LLM para responder.            |
| [OpenAPIEndpointChain](https://api.python.langchain.com/en/latest/chains/langchain.chains.api.openapi.chain.OpenAPIEndpointChain.html#langchain.chains.api.openapi.chain.OpenAPIEndpointChain)         |                                            | OpenAPI Spec           | Similar a APIChain, esta cadena está diseñada para interactuar con APIs. La principal diferencia es que está optimizada para facilitar el uso con puntos finales OpenAPI.            |
| [ConversationalRetrievalChain](https://api.python.langchain.com/en/latest/chains/langchain.chains.conversational_retrieval.base.ConversationalRetrievalChain.html#langchain.chains.conversational_retrieval.base.ConversationalRetrievalChain) |                                            | Retriever              |Esta cadena se puede usar para tener **conversaciones** con un documento. Toma una pregunta y (opcional) el historial de conversación previo. Si hay un historial de conversación previo, utiliza un LLM para reescribir la conversación en una consulta para enviar a un retriever (de lo contrario, solo usa la entrada más reciente del usuario). Luego obtiene esos documentos y los pasa (junto con la conversación) a un LLM para responder.             |
| [StuffDocumentsChain](https://api.python.langchain.com/en/latest/chains/langchain.chains.combine_documents.stuff.StuffDocumentsChain.html#langchain.chains.combine_documents.stuff.StuffDocumentsChain)           |                    |                        |Esta cadena toma una lista de documentos y los formatea todos en un prompt, luego pasa ese prompt a un LLM. Pasa TODOS los documentos, por lo que debes asegurarte de que quepan dentro de la ventana de contexto del LLM que estás usando.             |
| [ReduceDocumentsChain](https://api.python.langchain.com/en/latest/chains/langchain.chains.combine_documents.reduce.ReduceDocumentsChain.html#langchain.chains.combine_documents.reduce.ReduceDocumentsChain)         |                                            |                        |Esta cadena combina documentos reduciéndolos iterativamente. Agrupa documentos en fragmentos (menores a cierta longitud de contexto) y luego los pasa a un LLM. Luego toma las respuestas y continúa haciendo esto hasta que puede encajar todo en una llamada final de LLM. Es útil cuando tienes muchos documentos, quieres que el LLM los recorra todos y puedes hacerlo en paralelo.              |
| [MapReduceDocumentsChain](https://api.python.langchain.com/en/latest/chains/langchain.chains.combine_documents.map_reduce.MapReduceDocumentsChain.html#langchain.chains.combine_documents.map_reduce.MapReduceDocumentsChain)      |                        |                                            |Esta cadena primero pasa cada documento a través de un LLM, luego los reduce usando el `ReduceDocumentsChain`. Es útil en las mismas situaciones que `ReduceDocumentsChain`, pero hace una llamada inicial al LLM antes de intentar reducir los documentos.          |
| [RefineDocumentsChain](https://api.python.langchain.com/en/latest/chains/langchain.chains.combine_documents.refine.RefineDocumentsChain.html#langchain.chains.combine_documents.refine.RefineDocumentsChain)         |    |                                        |Esta cadena colapsa documentos generando una respuesta inicial basada en el primer documento y luego buclea sobre los documentos restantes para *refinar* su respuesta. Esto opera secuencialmente, por lo que no se puede paralelizar. Es útil en situaciones similares a MapReduceDocuments Chain, pero para casos donde deseas construir una respuesta refinando la respuesta anterior (en lugar de paralelizar llamadas).                        |             |
| [MapRerankDocumentsChain](https://api.python.langchain.com/en/latest/chains/langchain.chains.combine_documents.map_rerank.MapRerankDocumentsChain.html#langchain.chains.combine_documents.map_rerank.MapRerankDocumentsChain)      |                        |                    |                                      Esto llama a un LLM en cada documento, pidiéndole no solo responder sino también producir una puntuación de cuán confiado está. La respuesta con la mayor confianza es entonces devuelta. Esto es útil cuando tienes muchos documentos, pero solo quieres responder basado en un solo documento, en lugar de intentar combinar respuestas (como lo hacen los métodos Refine y Reduce).|
| [ConstitutionalChain](https://api.python.langchain.com/en/latest/chains/langchain.chains.constitutional_ai.base.ConstitutionalChain.html#langchain.chains.constitutional_ai.base.ConstitutionalChain)          |                                            |                        |Esta cadena responde y luego intenta refinar su respuesta basado en principios constitucionales que se proporcionan. Usa esto para asegurar que la respuesta de una cadena siga algunos principios.             |
| [LLMChain](https://api.python.langchain.com/en/latest/chains/langchain.chains.llm.LLMChain.html#langchain.chains.llm.LLMChain)                                 |  |                  |                        |Esta cadena simplemente combina un prompt con un LLM y un analizador de salida. La forma recomendada de hacer esto es usar LCEL.             |
| [ElasticsearchDatabaseChain](https://api.python.langchain.com/en/latest/chains/langchain.chains.elasticsearch_database.base.ElasticsearchDatabaseChain.html#langchain.chains.elasticsearch_database.base.ElasticsearchDatabaseChain)                           |                    | Elasticsearch Instance |Esta cadena convierte una pregunta en lenguaje natural en una consulta `Elasticsearch`, luego la ejecuta y luego resume la respuesta. Esto es útil cuando deseas hacer preguntas en lenguaje natural a una base de datos `Elasticsearch`.             |
| [FlareChain](https://api.python.langchain.com/en/latest/chains/langchain.chains.flare.base.FlareChain.html#langchain.chains.flare.base.FlareChain)                   |                                            |                        |Esta implementa [FLARE](https://arxiv.org/abs/2305.06983), una técnica de recuperación avanzada. Está principalmente destinada como un método exploratorio de recuperación avanzada.             |
| [ArangoGraphQAChain](https://api.python.langchain.com/en/latest/chains/langchain.chains.graph_qa.arangodb.ArangoGraphQAChain.html#langchain.chains.graph_qa.arangodb.ArangoGraphQAChain)                                   |                    |Arango Graph                        |Esta cadena construye una consulta Arango desde el lenguaje natural, ejecuta esa consulta contra el grafo y luego pasa los resultados a un LLM para responder.             |
|[GraphCypherQAChain](https://api.python.langchain.com/en/latest/chains/langchain.chains.graph_qa.cypher.GraphCypherQAChain.html#langchain.chains.graph_qa.cypher.GraphCypherQAChain)                                                      |                    |Un grafo que funciona con lenguaje de consulta Cypher                        |Esta cadena construye una consulta Cypher desde el lenguaje natural, ejecuta esa consulta contra el grafo y luego pasa los resultados a un LLM para responder.             |
|[FalkorDBGraphQAChain](https://api.python.langchain.com/en/latest/chains/langchain.chains.graph_qa.falkordb.FalkorDBQAChain.html#langchain.chains.graph_qa.falkordb.FalkorDBQAChain)                                                      |                    |Base de Datos Falkor                        | Esta cadena construye una consulta FalkorDB desde el lenguaje natural, ejecuta esa consulta contra el grafo y luego pasa los resultados a un LLM para responder.             |
|[HugeGraphQAChain](https://api.python.langchain.com/en/latest/chains/langchain.chains.graph_qa.hugegraph.HugeGraphQAChain.html#langchain.chains.graph_qa.hugegraph.HugeGraphQAChain)                                                     |                    |HugeGraph                        |Esta cadena construye una consulta HugeGraph desde el lenguaje natural, ejecuta esa consulta contra el grafo y luego pasa los resultados a un LLM para responder.              |
|[KuzuQAChain](https://api.python.langchain.com/en/latest/chains/langchain.chains.graph_qa.kuzu.KuzuQAChain.html#langchain.chains.graph_qa.kuzu.KuzuQAChain)                                                      |                    |Kuzu Graph                        |Esta cadena construye una consulta Kuzu Graph desde el lenguaje natural, ejecuta esa consulta contra el grafo y luego pasa los resultados a un LLM para responder.              |
|[NebulaGraphQAChain](https://api.python.langchain.com/en/latest/chains/langchain.chains.graph_qa.nebulagraph.NebulaGraphQAChain.html#langchain.chains.graph_qa.nebulagraph.NebulaGraphQAChain)                                                      |                    |Nebula Graph                        |Esta cadena construye una consulta Nebula Graph desde el lenguaje natural, ejecuta esa consulta contra el grafo y luego pasa los resultados a un LLM para responder.              |
|[NeptuneOpenCypherQAChain](https://api.python.langchain.com/en/latest/chains/langchain.chains.graph_qa.neptune_cypher.NeptuneOpenCypherQAChain.html#langchain.chains.graph_qa.neptune_cypher.NeptuneOpenCypherQAChain)                                                     |                    |Neptune Graph                        |Esta cadena construye una consulta Neptune Graph desde el lenguaje natural, ejecuta esa consulta contra el grafo y luego pasa los resultados a un LLM para responder.              |
|[GraphSparqlChain](https://api.python.langchain.com/en/latest/chains/langchain.chains.graph_qa.sparql.GraphSparqlQAChain.html#langchain.chains.graph_qa.sparql.GraphSparqlQAChain)                                                      |                    |Grafo que funciona con SparQL                        |Esta cadena construye una consulta SparQL desde el lenguaje natural, ejecuta esa consulta contra el grafo y luego pasa los resultados a un LLM para responder.              |
|[LLMMath](https://api.python.langchain.com/en/latest/chains/langchain.chains.llm_math.base.LLMMathChain.html#langchain.chains.llm_math.base.LLMMathChain)                                                      |                    |                        |Esta cadena convierte una pregunta del usuario en un problema matemático y luego lo ejecuta (usando [numexpr](https://github.com/pydata/numexpr)).             |
|[LLMCheckerChain](https://api.python.langchain.com/en/latest/chains/langchain.chains.llm_checker.base.LLMCheckerChain.html#langchain.chains.llm_checker.base.LLMCheckerChain)                                                      |                    |                        |Esta cadena usa una segunda llamada LLM para verificar su respuesta inicial. Usa esto cuando tienes una capa adicional de validación en la llamada inicial del LLM.             |
|[LLMSummarizationChecker](https://api.python.langchain.com/en/latest/chains/langchain.chains.llm_summarization_checker.base.LLMSummarizationCheckerChain.html#langchain.chains.llm_summarization_checker.base.LLMSummarizationCheckerChain)                              |                        |                                            |Esta cadena crea un resumen usando una secuencia de llamadas LLM para asegurarse de que sea extra correcto. Usa esto en lugar de la cadena de resumen normal cuando estás de acuerdo con múltiples llamadas LLM (por ejemplo, te importa más la precisión que la velocidad/costo).             |
|[create_citation_fuzzy_match_chain](https://api.python.langchain.com/en/latest/chains/langchain.chains.openai_functions.citation_fuzzy_match.create_citation_fuzzy_match_chain.html#langchain.chains.openai_functions.citation_fuzzy_match.create_citation_fuzzy_match_chain)                                                      |✅                    |                        |Usa la llamada de función de OpenAI para responder preguntas y citar sus fuentes.             |
|[create_extraction_chain](https://api.python.langchain.com/en/latest/chains/langchain.chains.openai_functions.extraction.create_extraction_chain.html#langchain.chains.openai_functions.extraction.create_extraction_chain)                              |                        ✅                    |                        |Usa la llamada de función de OpenAI para extraer información del texto.             |
|[create_extraction_chain_pydantic](https://api.python.langchain.com/en/latest/chains/langchain.chains.openai_functions.extraction.create_extraction_chain_pydantic.html#langchain.chains.openai_functions.extraction.create_extraction_chain_pydantic)                              |                        ✅                    |                        |Usa la llamada de función de OpenAI para extraer información del texto en un modelo Pydantic. En comparación con `create_extraction_chain`, esta tiene una integración más estrecha con Pydantic.             |
|[get_openapi_chain](https://api.python.langchain.com/en/latest/chains/langchain.chains.openai_functions.openapi.get_openapi_chain.html#langchain.chains.openai_functions.openapi.get_openapi_chain)                              |                        ✅                    |OpenAPI Spec                        |Usa la llamada de función de OpenAI para consultar un OpenAPI.             |
|[create_qa_with_structure_chain](https://api.python.langchain.com/en/latest/chains/langchain.chains.openai_functions.qa_with_structure.create_qa_with_structure_chain.html#langchain.chains.openai_functions.qa_with_structure.create_qa_with_structure_chain)                              |                        ✅                    |                        |Usa la llamada de función de OpenAI para realizar preguntas y respuestas sobre texto y responder en un formato específico.             |
|[create_qa_with_sources_chain](https://api.python.langchain.com/en/latest/chains/langchain.chains.openai_functions.qa_with_structure.create_qa_with_sources_chain.html#langchain.chains.openai_functions.qa_with_structure.create_qa_with_sources_chain)                              |                        ✅                    |                        |Usa la llamada de función de OpenAI para responder preguntas con citas.             |
|[QAGenerationChain](https://api.python.langchain.com/en/latest/chains/langchain.chains.qa_generation.base.QAGenerationChain.html#langchain.chains.qa_generation.base.QAGenerationChain)                                          |            |                    |Crea tanto preguntas como respuestas a partir de documentos. Se utiliza para generar pares de preguntas/respuestas para la evaluación de proyectos de recuperación.                        |
|[RetrievalQAWithSourcesChain](https://api.python.langchain.com/en/latest/chains/langchain.chains.qa_with_sources.retrieval.RetrievalQAWithSourcesChain.html#langchain.chains.qa_with_sources.retrieval.RetrievalQAWithSourcesChain)                              |                        |                          Retriever                    |Realiza preguntas y respuestas sobre documentos recuperados y cita sus fuentes. Usa esto cuando deseas que la respuesta tenga fuentes en la respuesta de texto. Usa esto en lugar de `load_qa_with_sources_chain` cuando deseas usar un retriever para obtener el documento relevante como parte de la cadena (en lugar de pasarlos directamente).|
|[load_qa_with_sources_chain](https://api.python.langchain.com/en/latest/chains/langchain.chains.qa_with_sources.loading.load_qa_with_sources_chain.html#langchain.chains.qa_with_sources.loading.load_qa_with_sources_chain)                                                     | |Retriever                    |Realiza preguntas y respuestas sobre documentos que pasas y cita sus fuentes. Usa esto cuando deseas que la respuesta tenga fuentes en la respuesta de texto. Usa esto en lugar de RetrievalQAWithSources cuando deseas pasar los documentos directamente (en lugar de confiar en un retriever para obtenerlos).|
|[RetrievalQA](https://api.python.langchain.com/en/latest/chains/langchain.chains.retrieval_qa.base.RetrievalQA.html#langchain.chains.retrieval_qa.base.RetrievalQA)   |                                            |Retriever                        |Esta cadena primero realiza un paso de recuperación para obtener documentos relevantes, luego pasa esos documentos a un LLM para generar una respuesta.|
|[MultiPromptChain](https://api.python.langchain.com/en/latest/chains/langchain.chains.router.multi_prompt.MultiPromptChain.html#langchain.chains.router.multi_prompt.MultiPromptChain)                                                      |                    |                        |Esta cadena enruta la entrada entre múltiples prompts. Usa esto cuando tienes múltiples posibles prompts que podrías usar para responder y deseas enrutar a solo uno. |
|[MultiRetrievalQAChain](https://api.python.langchain.com/en/latest/chains/langchain.chains.router.multi_retrieval_qa.MultiRetrievalQAChain.html#langchain.chains.router.multi_retrieval_qa.MultiRetrievalQAChain)|                                            |Retriever                        |Esta cadena enruta la entrada entre múltiples retrievers. Usa esto cuando tienes múltiples posibles retrievers de los que podrías obtener documentos relevantes y deseas enrutar a solo uno. |
|[EmbeddingRouterChain](https://api.python.langchain.com/en/latest/chains/langchain.chains.router.embedding_router.EmbeddingRouterChain.html#langchain.chains.router.embedding_router.EmbeddingRouterChain)|                                            |                        |Esta cadena usa la similitud de embeddings para enrutar consultas entrantes.|
|[LLMRouterChain](https://api.python.langchain.com/en/latest/chains/langchain.chains.router.llm_router.LLMRouterChain.html#langchain.chains.router.llm_router.LLMRouterChain)|                                            |                        |Esta cadena usa un LLM para enrutar entre opciones potenciales.|
|load_summarize_chain|                        |                    |                        |Esta cadena resume texto|
|[LLMRequestsChain](https://api.python.langchain.com/en/latest/chains/langchain.chains.llm_requests.LLMRequestsChain.html#langchain.chains.llm_requests.LLMRequestsChain)|                        |                                            |Esta cadena construye una URL a partir de la entrada del usuario, obtiene datos en esa URL y luego resume la respuesta. En comparación con APIChain, esta cadena no se enfoca en una única especificación de API, sino que es más general.       |
