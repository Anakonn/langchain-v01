---
sidebar_label: ‡§ü‡•Ç‡§≤ ‡§ï‡•â‡§≤‡§ø‡§Ç‡§ó
sidebar_position: 0
translated: true
---

# ‡§ü‡•Ç‡§≤ ‡§ï‡•â‡§≤‡§ø‡§Ç‡§ó ‡§è‡§ú‡•á‡§Ç‡§ü

[‡§ü‡•Ç‡§≤ ‡§ï‡•â‡§≤‡§ø‡§Ç‡§ó](/docs/modules/model_io/chat/function_calling) ‡§ï‡§ø‡§∏‡•Ä ‡§Æ‡•â‡§°‡§≤ ‡§ï‡•ã ‡§Ø‡§π ‡§™‡§§‡§æ ‡§≤‡§ó‡§æ‡§®‡•á ‡§ï‡•Ä ‡§Ö‡§®‡•Å‡§Æ‡§§‡§ø ‡§¶‡•á‡§§‡§æ ‡§π‡•à ‡§ï‡§ø ‡§è‡§ï ‡§Ø‡§æ ‡§è‡§ï ‡§∏‡•á ‡§Ö‡§ß‡§ø‡§ï ‡§ü‡•Ç‡§≤ ‡§ï‡•ã ‡§ï‡•â‡§≤ ‡§ï‡§ø‡§Ø‡§æ ‡§ú‡§æ‡§®‡§æ ‡§ö‡§æ‡§π‡§ø‡§è ‡§î‡§∞ ‡§â‡§® ‡§ü‡•Ç‡§≤‡•ã‡§Ç ‡§ï‡•ã ‡§™‡§æ‡§∏ ‡§ï‡§ø‡§è ‡§ú‡§æ‡§®‡•á ‡§µ‡§æ‡§≤‡•á ‡§á‡§®‡§™‡•Å‡§ü ‡§ï‡•á ‡§∏‡§æ‡§• ‡§™‡•ç‡§∞‡§§‡§ø‡§ï‡•ç‡§∞‡§ø‡§Ø‡§æ ‡§¶‡•á‡§§‡§æ ‡§π‡•à‡•§ ‡§è‡§ï API ‡§ï‡•â‡§≤ ‡§Æ‡•á‡§Ç, ‡§Ü‡§™ ‡§ü‡•Ç‡§≤‡•ã‡§Ç ‡§ï‡§æ ‡§µ‡§∞‡•ç‡§£‡§® ‡§ï‡§∞ ‡§∏‡§ï‡§§‡•á ‡§π‡•à‡§Ç ‡§î‡§∞ ‡§Æ‡•â‡§°‡§≤ ‡§ï‡•ã ‡§á‡§® ‡§ü‡•Ç‡§≤‡•ã‡§Ç ‡§ï‡•ã ‡§ï‡•â‡§≤ ‡§ï‡§∞‡§®‡•á ‡§ï‡•á ‡§≤‡§ø‡§è JSON ‡§ú‡•à‡§∏‡•á ‡§∏‡§Ç‡§∞‡§ö‡§ø‡§§ ‡§ë‡§¨‡•ç‡§ú‡•á‡§ï‡•ç‡§ü ‡§Ü‡§â‡§ü‡§™‡•Å‡§ü ‡§ï‡§∞‡§®‡•á ‡§ï‡•á ‡§≤‡§ø‡§è ‡§¨‡•Å‡§¶‡•ç‡§ß‡§ø‡§Æ‡§æ‡§®‡•Ä ‡§∏‡•á ‡§ö‡•Å‡§®‡§®‡•á ‡§ï‡•Ä ‡§Ö‡§®‡•Å‡§Æ‡§§‡§ø ‡§¶‡•á ‡§∏‡§ï‡§§‡•á ‡§π‡•à‡§Ç‡•§ ‡§ü‡•Ç‡§≤ API ‡§ï‡§æ ‡§≤‡§ï‡•ç‡§∑‡•ç‡§Ø ‡§ú‡•á‡§®‡§∞‡§ø‡§ï ‡§ü‡•á‡§ï‡•ç‡§∏‡•ç‡§ü ‡§™‡•Ç‡§∞‡•ç‡§£‡§§‡§æ ‡§Ø‡§æ ‡§ö‡•à‡§ü API ‡§ï‡§æ ‡§â‡§™‡§Ø‡•ã‡§ó ‡§ï‡§∞‡§ï‡•á ‡§ï‡§ø‡§è ‡§ú‡§æ ‡§∏‡§ï‡§®‡•á ‡§µ‡§æ‡§≤‡•á ‡§∏‡•á ‡§Ö‡§ß‡§ø‡§ï ‡§µ‡§ø‡§∂‡•ç‡§µ‡§∏‡§®‡•Ä‡§Ø ‡§î‡§∞ ‡§â‡§™‡§Ø‡•ã‡§ó‡•Ä ‡§ü‡•Ç‡§≤ ‡§ï‡•â‡§≤ ‡§µ‡§æ‡§™‡§∏ ‡§ï‡§∞‡§®‡§æ ‡§π‡•à‡•§

‡§π‡§Æ ‡§á‡§∏ ‡§∏‡§Ç‡§∞‡§ö‡§ø‡§§ ‡§Ü‡§â‡§ü‡§™‡•Å‡§ü ‡§ï‡§æ ‡§≤‡§æ‡§≠ ‡§â‡§†‡§æ ‡§∏‡§ï‡§§‡•á ‡§π‡•à‡§Ç, ‡§ú‡§ø‡§∏‡§ï‡•á ‡§∏‡§æ‡§•-‡§∏‡§æ‡§• ‡§Ü‡§™ ‡§è‡§ï [‡§ü‡•Ç‡§≤ ‡§ï‡•â‡§≤‡§ø‡§Ç‡§ó ‡§ö‡•à‡§ü ‡§Æ‡•â‡§°‡§≤](/docs/integrations/chat/) ‡§∏‡•á ‡§ï‡§à ‡§ü‡•Ç‡§≤ ‡§ï‡•ã ‡§¨‡§æ‡§á‡§Ç‡§° ‡§ï‡§∞ ‡§∏‡§ï‡§§‡•á ‡§π‡•à‡§Ç ‡§î‡§∞ ‡§Æ‡•â‡§°‡§≤ ‡§ï‡•ã ‡§â‡§®‡§Æ‡•á‡§Ç ‡§∏‡•á ‡§ï‡§ø‡§∏‡•á ‡§ï‡•â‡§≤ ‡§ï‡§∞‡§®‡§æ ‡§π‡•à, ‡§Ø‡§π ‡§ö‡•Å‡§®‡§®‡•á ‡§ï‡•Ä ‡§Ö‡§®‡•Å‡§Æ‡§§‡§ø ‡§¶‡•á ‡§∏‡§ï‡§§‡•á ‡§π‡•à‡§Ç, ‡§è‡§ï ‡§ê‡§∏‡§æ ‡§è‡§ú‡•á‡§Ç‡§ü ‡§¨‡§®‡§æ‡§®‡•á ‡§ï‡•á ‡§≤‡§ø‡§è ‡§ú‡•ã ‡§¨‡§æ‡§∞-‡§¨‡§æ‡§∞ ‡§ü‡•Ç‡§≤ ‡§ï‡•â‡§≤ ‡§ï‡§∞‡§§‡§æ ‡§π‡•à ‡§î‡§∞ ‡§è‡§ï ‡§ï‡•ç‡§µ‡•á‡§∞‡•Ä ‡§ï‡•ã ‡§π‡§≤ ‡§ï‡§∞‡§®‡•á ‡§§‡§ï ‡§™‡§∞‡§ø‡§£‡§æ‡§Æ ‡§™‡•ç‡§∞‡§æ‡§™‡•ç‡§§ ‡§ï‡§∞‡§§‡§æ ‡§π‡•à‡•§

‡§Ø‡§π [OpenAI ‡§ü‡•Ç‡§≤ ‡§è‡§ú‡•á‡§Ç‡§ü](/docs/modules/agents/agent_types/openai_tools/) ‡§ï‡§æ ‡§è‡§ï ‡§Ö‡§ß‡§ø‡§ï ‡§∏‡§æ‡§Æ‡§æ‡§®‡•ç‡§Ø‡•Ä‡§ï‡•É‡§§ ‡§∏‡§Ç‡§∏‡•ç‡§ï‡§∞‡§£ ‡§π‡•à, ‡§ú‡•ã OpenAI ‡§ï‡•á ‡§ü‡•Ç‡§≤ ‡§ï‡•â‡§≤‡§ø‡§Ç‡§ó ‡§ï‡•á ‡§µ‡§ø‡§∂‡§ø‡§∑‡•ç‡§ü ‡§∂‡•à‡§≤‡•Ä ‡§ï‡•á ‡§≤‡§ø‡§è ‡§°‡§ø‡§ú‡§º‡§æ‡§á‡§® ‡§ï‡§ø‡§Ø‡§æ ‡§ó‡§Ø‡§æ ‡§•‡§æ‡•§ ‡§Ø‡§π LangChain ‡§ï‡•á ToolCall ‡§á‡§Ç‡§ü‡§∞‡§´‡§º‡•á‡§∏ ‡§ï‡§æ ‡§â‡§™‡§Ø‡•ã‡§ó ‡§ï‡§∞‡§ï‡•á ‡§è‡§ï ‡§µ‡•ç‡§Ø‡§æ‡§™‡§ï ‡§∂‡•ç‡§∞‡•É‡§Ç‡§ñ‡§≤‡§æ ‡§ï‡•á ‡§™‡•ç‡§∞‡§¶‡§æ‡§§‡§æ ‡§ï‡§æ‡§∞‡•ç‡§Ø‡§æ‡§®‡•ç‡§µ‡§Ø‡§®‡•ã‡§Ç ‡§ï‡§æ ‡§∏‡§Æ‡§∞‡•ç‡§•‡§® ‡§ï‡§∞‡§§‡§æ ‡§π‡•à, ‡§ú‡•à‡§∏‡•á [Anthropic](/docs/integrations/chat/anthropic/), [Google Gemini](/docs/integrations/chat/google_vertex_ai_palm/), ‡§î‡§∞ [Mistral](/docs/integrations/chat/mistralai/) ‡§ï‡•á ‡§Ö‡§≤‡§æ‡§µ‡§æ [OpenAI](/docs/integrations/chat/openai/)‡•§

## ‡§∏‡•á‡§ü‡§Ö‡§™

‡§ü‡•Ç‡§≤ ‡§ï‡•â‡§≤‡§ø‡§Ç‡§ó ‡§ï‡§æ ‡§∏‡§Æ‡§∞‡•ç‡§•‡§® ‡§ï‡§∞‡§®‡•á ‡§µ‡§æ‡§≤‡•á ‡§ï‡§ø‡§∏‡•Ä ‡§≠‡•Ä ‡§Æ‡•â‡§°‡§≤ ‡§ï‡§æ ‡§â‡§™‡§Ø‡•ã‡§ó ‡§á‡§∏ ‡§è‡§ú‡•á‡§Ç‡§ü ‡§Æ‡•á‡§Ç ‡§ï‡§ø‡§Ø‡§æ ‡§ú‡§æ ‡§∏‡§ï‡§§‡§æ ‡§π‡•à‡•§ ‡§Ü‡§™ ‡§Ø‡§π‡§æ‡§Ç ‡§¶‡•á‡§ñ ‡§∏‡§ï‡§§‡•á ‡§π‡•à‡§Ç ‡§ï‡§ø ‡§ï‡•å‡§® ‡§∏‡•á ‡§Æ‡•â‡§°‡§≤ ‡§ü‡•Ç‡§≤ ‡§ï‡•â‡§≤‡§ø‡§Ç‡§ó ‡§ï‡§æ ‡§∏‡§Æ‡§∞‡•ç‡§•‡§® ‡§ï‡§∞‡§§‡•á ‡§π‡•à‡§Ç [‡§Ø‡§π‡§æ‡§Ç](/docs/integrations/chat/)

‡§Ø‡§π ‡§°‡•á‡§Æ‡•ã [Tavily](https://app.tavily.com) ‡§ï‡§æ ‡§â‡§™‡§Ø‡•ã‡§ó ‡§ï‡§∞‡§§‡§æ ‡§π‡•à, ‡§≤‡•á‡§ï‡§ø‡§® ‡§Ü‡§™ ‡§ï‡§ø‡§∏‡•Ä ‡§Ö‡§®‡•ç‡§Ø [‡§¨‡§ø‡§≤‡•ç‡§ü-‡§á‡§® ‡§ü‡•Ç‡§≤](/docs/integrations/tools) ‡§ï‡•ã ‡§≠‡•Ä ‡§∏‡•ç‡§µ‡•à‡§™ ‡§ï‡§∞ ‡§∏‡§ï‡§§‡•á ‡§π‡•à‡§Ç ‡§Ø‡§æ [‡§ï‡§∏‡•ç‡§ü‡§Æ ‡§ü‡•Ç‡§≤](/docs/modules/tools/custom_tools/) ‡§ú‡•ã‡§°‡§º ‡§∏‡§ï‡§§‡•á ‡§π‡•à‡§Ç‡•§
‡§Ü‡§™‡§ï‡•ã ‡§è‡§ï API ‡§ï‡•Å‡§Ç‡§ú‡•Ä ‡§ï‡•á ‡§≤‡§ø‡§è ‡§∏‡§æ‡§á‡§® ‡§Ö‡§™ ‡§ï‡§∞‡§®‡§æ ‡§π‡•ã‡§ó‡§æ ‡§î‡§∞ ‡§á‡§∏‡•á `process.env.TAVILY_API_KEY` ‡§ï‡•á ‡§∞‡•Ç‡§™ ‡§Æ‡•á‡§Ç ‡§∏‡•á‡§ü ‡§ï‡§∞‡§®‡§æ ‡§π‡•ã‡§ó‡§æ‡•§

import ChatModelTabs from "@theme/ChatModelTabs";

<ChatModelTabs
  customVarName="llm"
  hideCohere
/>

```python
# | output: false
# | echo: false

from langchain_anthropic import ChatAnthropic

llm = ChatAnthropic(model="claude-3-sonnet-20240229", temperature=0)
```

## ‡§ü‡•Ç‡§≤‡•ç‡§∏ ‡§ï‡•ã ‡§á‡§®‡§ø‡§∂‡§ø‡§Ø‡§≤‡§æ‡§á‡§ú‡§º ‡§ï‡§∞‡•á‡§Ç

‡§π‡§Æ ‡§™‡§π‡§≤‡•á ‡§è‡§ï ‡§ê‡§∏‡§æ ‡§ü‡•Ç‡§≤ ‡§¨‡§®‡§æ‡§è‡§Ç‡§ó‡•á ‡§ú‡•ã ‡§µ‡•á‡§¨ ‡§ï‡•ã ‡§ñ‡•ã‡§ú ‡§∏‡§ï‡§§‡§æ ‡§π‡•à:

```python
from langchain.agents import AgentExecutor, create_tool_calling_agent
from langchain_community.tools.tavily_search import TavilySearchResults
from langchain_core.prompts import ChatPromptTemplate

tools = [TavilySearchResults(max_results=1)]
```

## ‡§è‡§ú‡•á‡§Ç‡§ü ‡§¨‡§®‡§æ‡§è‡§Ç

‡§Ö‡§¨, ‡§Ü‡§á‡§è ‡§π‡§Æ‡§æ‡§∞‡•á ‡§ü‡•Ç‡§≤ ‡§ï‡•â‡§≤‡§ø‡§Ç‡§ó ‡§è‡§ú‡•á‡§Ç‡§ü ‡§ï‡•ã ‡§á‡§®‡§ø‡§∂‡§ø‡§Ø‡§≤‡§æ‡§á‡§ú‡§º ‡§ï‡§∞‡•á‡§Ç:

```python
prompt = ChatPromptTemplate.from_messages(
    [
        (
            "system",
            "You are a helpful assistant. Make sure to use the tavily_search_results_json tool for information.",
        ),
        ("placeholder", "{chat_history}"),
        ("human", "{input}"),
        ("placeholder", "{agent_scratchpad}"),
    ]
)

# Construct the Tools agent
agent = create_tool_calling_agent(llm, tools, prompt)
```

## ‡§è‡§ú‡•á‡§Ç‡§ü ‡§ö‡§≤‡§æ‡§è‡§Ç

‡§Ö‡§¨, ‡§ö‡§≤‡§ø‡§è ‡§π‡§Æ ‡§â‡§∏ ‡§ï‡§æ‡§∞‡•ç‡§Ø‡§™‡§æ‡§≤‡§ï ‡§ï‡•ã ‡§™‡•ç‡§∞‡§æ‡§∞‡§Ç‡§≠ ‡§ï‡§∞‡§§‡•á ‡§π‡•à‡§Ç ‡§ú‡•ã ‡§π‡§Æ‡§æ‡§∞‡•á ‡§è‡§ú‡•á‡§Ç‡§ü ‡§ï‡•ã ‡§ö‡§≤‡§æ‡§è‡§ó‡§æ ‡§î‡§∞ ‡§á‡§∏‡•á ‡§Ü‡§Æ‡§Ç‡§§‡•ç‡§∞‡§ø‡§§ ‡§ï‡§∞‡•á‡§Ç‡§ó‡•á!

```python
# Create an agent executor by passing in the agent and tools
agent_executor = AgentExecutor(agent=agent, tools=tools, verbose=True)
agent_executor.invoke({"input": "what is LangChain?"})
```

```output


[1m> Entering new AgentExecutor chain...[0m

/Users/bagatur/langchain/libs/partners/anthropic/langchain_anthropic/chat_models.py:347: UserWarning: stream: Tool use is not yet supported in streaming mode.
  warnings.warn("stream: Tool use is not yet supported in streaming mode.")

[32;1m[1;3m
Invoking: `tavily_search_results_json` with `{'query': 'LangChain'}`
responded: [{'id': 'toolu_01QxrrT9srzkYCNyEZMDhGeg', 'input': {'query': 'LangChain'}, 'name': 'tavily_search_results_json', 'type': 'tool_use'}]

[0m[36;1m[1;3m[{'url': 'https://github.com/langchain-ai/langchain', 'content': 'About\n‚ö° Building applications with LLMs through composability ‚ö°\nResources\nLicense\nCode of conduct\nSecurity policy\nStars\nWatchers\nForks\nReleases\n291\nPackages\n0\nUsed by 39k\nContributors\n1,848\nLanguages\nFooter\nFooter navigation Latest commit\nGit stats\nFiles\nREADME.md\nü¶úÔ∏èüîó LangChain\n‚ö° Building applications with LLMs through composability ‚ö°\nLooking for the JS/TS library? ‚ö° Building applications with LLMs through composability ‚ö°\nLicense\nlangchain-ai/langchain\nName already in use\nUse Git or checkout with SVN using the web URL.\n üìñ Documentation\nPlease see here for full documentation, which includes:\nüíÅ Contributing\nAs an open-source project in a rapidly developing field, we are extremely open to contributions, whether it be in the form of a new feature, improved infrastructure, or better documentation.\n What can you build with LangChain?\n‚ùì Retrieval augmented generation\nüí¨ Analyzing structured data\nü§ñ Chatbots\nAnd much more!'}][0m

/Users/bagatur/langchain/libs/partners/anthropic/langchain_anthropic/chat_models.py:347: UserWarning: stream: Tool use is not yet supported in streaming mode.
  warnings.warn("stream: Tool use is not yet supported in streaming mode.")

[32;1m[1;3mLangChain is an open-source Python library that helps developers build applications with large language models (LLMs) through composability. Some key features of LangChain include:

- Retrieval augmented generation - Allowing LLMs to retrieve and utilize external data sources when generating outputs.

- Analyzing structured data - Tools for working with structured data like databases, APIs, PDFs, etc. and allowing LLMs to reason over this data.

- Building chatbots and agents - Frameworks for building conversational AI applications.

- Composability - LangChain allows you to chain together different LLM capabilities and data sources in a modular and reusable way.

The library aims to make it easier to build real-world applications that leverage the power of large language models in a scalable and robust way. It provides abstractions and primitives for working with LLMs from different providers like OpenAI, Anthropic, Cohere, etc. LangChain is open-source and has an active community contributing new features and improvements.[0m

[1m> Finished chain.[0m
```

```output
{'input': 'what is LangChain?',
 'output': 'LangChain is an open-source Python library that helps developers build applications with large language models (LLMs) through composability. Some key features of LangChain include:\n\n- Retrieval augmented generation - Allowing LLMs to retrieve and utilize external data sources when generating outputs.\n\n- Analyzing structured data - Tools for working with structured data like databases, APIs, PDFs, etc. and allowing LLMs to reason over this data.\n\n- Building chatbots and agents - Frameworks for building conversational AI applications.\n\n- Composability - LangChain allows you to chain together different LLM capabilities and data sources in a modular and reusable way.\n\nThe library aims to make it easier to build real-world applications that leverage the power of large language models in a scalable and robust way. It provides abstractions and primitives for working with LLMs from different providers like OpenAI, Anthropic, Cohere, etc. LangChain is open-source and has an active community contributing new features and improvements.'}
```

:::tip
[LangSmith trace](https://smith.langchain.com/public/2f956a2e-0820-47c4-a798-c83f024e5ca1/r)
:::

## ‡§ö‡•à‡§ü ‡§á‡§§‡§ø‡§π‡§æ‡§∏ ‡§ï‡•á ‡§∏‡§æ‡§• ‡§â‡§™‡§Ø‡•ã‡§ó ‡§ï‡§∞‡§®‡§æ

‡§á‡§∏ ‡§™‡•ç‡§∞‡§ï‡§æ‡§∞ ‡§ï‡§æ ‡§è‡§ú‡•á‡§Ç‡§ü ‡§µ‡•à‡§ï‡§≤‡•ç‡§™‡§ø‡§ï ‡§∞‡•Ç‡§™ ‡§∏‡•á ‡§™‡§ø‡§õ‡§≤‡•á ‡§µ‡§æ‡§∞‡•ç‡§§‡§æ‡§≤‡§æ‡§™ ‡§ü‡§∞‡•ç‡§® ‡§ï‡•ã ‡§™‡•ç‡§∞‡§§‡§ø‡§®‡§ø‡§ß‡§ø‡§§‡•ç‡§µ ‡§ï‡§∞‡§®‡•á ‡§µ‡§æ‡§≤‡•á ‡§ö‡•à‡§ü ‡§∏‡§Ç‡§¶‡•á‡§∂‡•ã‡§Ç ‡§ï‡•ã ‡§≤‡•á ‡§∏‡§ï‡§§‡§æ ‡§π‡•à‡•§ ‡§Ø‡§π ‡§™‡§ø‡§õ‡§≤‡•á ‡§á‡§§‡§ø‡§π‡§æ‡§∏ ‡§ï‡§æ ‡§â‡§™‡§Ø‡•ã‡§ó ‡§ï‡§∞‡§ï‡•á ‡§∏‡§Ç‡§µ‡§æ‡§¶‡§æ‡§§‡•ç‡§Æ‡§ï ‡§∞‡•Ç‡§™ ‡§∏‡•á ‡§™‡•ç‡§∞‡§§‡§ø‡§ï‡•ç‡§∞‡§ø‡§Ø‡§æ ‡§¶‡•á ‡§∏‡§ï‡§§‡§æ ‡§π‡•à‡•§ ‡§Ö‡§ß‡§ø‡§ï ‡§ú‡§æ‡§®‡§ï‡§æ‡§∞‡•Ä ‡§ï‡•á ‡§≤‡§ø‡§è, [‡§è‡§ú‡•á‡§Ç‡§ü ‡§§‡•ç‡§µ‡§∞‡§ø‡§§ ‡§∂‡•Å‡§∞‡•Å‡§Ü‡§§ ‡§ï‡•á ‡§á‡§∏ ‡§ñ‡§Ç‡§°](/docs/modules/agents/quick_start#adding-in-memory) ‡§¶‡•á‡§ñ‡•á‡§Ç‡•§

```python
from langchain_core.messages import AIMessage, HumanMessage

agent_executor.invoke(
    {
        "input": "what's my name? Don't use tools to look this up unless you NEED to",
        "chat_history": [
            HumanMessage(content="hi! my name is bob"),
            AIMessage(content="Hello Bob! How can I assist you today?"),
        ],
    }
)
```

```output


[1m> Entering new AgentExecutor chain...[0m

/Users/bagatur/langchain/libs/partners/anthropic/langchain_anthropic/chat_models.py:347: UserWarning: stream: Tool use is not yet supported in streaming mode.
  warnings.warn("stream: Tool use is not yet supported in streaming mode.")

[32;1m[1;3mBased on what you told me, your name is Bob. I don't need to use any tools to look that up since you directly provided your name.[0m

[1m> Finished chain.[0m
```

```output
{'input': "what's my name? Don't use tools to look this up unless you NEED to",
 'chat_history': [HumanMessage(content='hi! my name is bob'),
  AIMessage(content='Hello Bob! How can I assist you today?')],
 'output': "Based on what you told me, your name is Bob. I don't need to use any tools to look that up since you directly provided your name."}
```

:::tip
[LangSmith trace](https://smith.langchain.com/public/e21ececb-2e60-49e5-9f06-a91b0fb11fb8/r)
:::
