---
sidebar_label: рдЯреВрд▓ рдХреЙрд▓рд┐рдВрдЧ
sidebar_position: 0
translated: true
---

# рдЯреВрд▓ рдХреЙрд▓рд┐рдВрдЧ рдПрдЬреЗрдВрдЯ

[рдЯреВрд▓ рдХреЙрд▓рд┐рдВрдЧ](/docs/modules/model_io/chat/function_calling) рдХрд┐рд╕реА рдореЙрдбрд▓ рдХреЛ рдпрд╣ рдкрддрд╛ рд▓рдЧрд╛рдиреЗ рдХреА рдЕрдиреБрдорддрд┐ рджреЗрддрд╛ рд╣реИ рдХрд┐ рдПрдХ рдпрд╛ рдПрдХ рд╕реЗ рдЕрдзрд┐рдХ рдЯреВрд▓ рдХреЛ рдХреЙрд▓ рдХрд┐рдпрд╛ рдЬрд╛рдирд╛ рдЪрд╛рд╣рд┐рдП рдФрд░ рдЙрди рдЯреВрд▓реЛрдВ рдХреЛ рдкрд╛рд╕ рдХрд┐рдП рдЬрд╛рдиреЗ рд╡рд╛рд▓реЗ рдЗрдирдкреБрдЯ рдХреЗ рд╕рд╛рде рдкреНрд░рддрд┐рдХреНрд░рд┐рдпрд╛ рджреЗрддрд╛ рд╣реИред рдПрдХ API рдХреЙрд▓ рдореЗрдВ, рдЖрдк рдЯреВрд▓реЛрдВ рдХрд╛ рд╡рд░реНрдгрди рдХрд░ рд╕рдХрддреЗ рд╣реИрдВ рдФрд░ рдореЙрдбрд▓ рдХреЛ рдЗрди рдЯреВрд▓реЛрдВ рдХреЛ рдХреЙрд▓ рдХрд░рдиреЗ рдХреЗ рд▓рд┐рдП JSON рдЬреИрд╕реЗ рд╕рдВрд░рдЪрд┐рдд рдСрдмреНрдЬреЗрдХреНрдЯ рдЖрдЙрдЯрдкреБрдЯ рдХрд░рдиреЗ рдХреЗ рд▓рд┐рдП рдмреБрджреНрдзрд┐рдорд╛рдиреА рд╕реЗ рдЪреБрдирдиреЗ рдХреА рдЕрдиреБрдорддрд┐ рджреЗ рд╕рдХрддреЗ рд╣реИрдВред рдЯреВрд▓ API рдХрд╛ рд▓рдХреНрд╖реНрдп рдЬреЗрдирд░рд┐рдХ рдЯреЗрдХреНрд╕реНрдЯ рдкреВрд░реНрдгрддрд╛ рдпрд╛ рдЪреИрдЯ API рдХрд╛ рдЙрдкрдпреЛрдЧ рдХрд░рдХреЗ рдХрд┐рдП рдЬрд╛ рд╕рдХрдиреЗ рд╡рд╛рд▓реЗ рд╕реЗ рдЕрдзрд┐рдХ рд╡рд┐рд╢реНрд╡рд╕рдиреАрдп рдФрд░ рдЙрдкрдпреЛрдЧреА рдЯреВрд▓ рдХреЙрд▓ рд╡рд╛рдкрд╕ рдХрд░рдирд╛ рд╣реИред

рд╣рдо рдЗрд╕ рд╕рдВрд░рдЪрд┐рдд рдЖрдЙрдЯрдкреБрдЯ рдХрд╛ рд▓рд╛рдн рдЙрдард╛ рд╕рдХрддреЗ рд╣реИрдВ, рдЬрд┐рд╕рдХреЗ рд╕рд╛рде-рд╕рд╛рде рдЖрдк рдПрдХ [рдЯреВрд▓ рдХреЙрд▓рд┐рдВрдЧ рдЪреИрдЯ рдореЙрдбрд▓](/docs/integrations/chat/) рд╕реЗ рдХрдИ рдЯреВрд▓ рдХреЛ рдмрд╛рдЗрдВрдб рдХрд░ рд╕рдХрддреЗ рд╣реИрдВ рдФрд░ рдореЙрдбрд▓ рдХреЛ рдЙрдирдореЗрдВ рд╕реЗ рдХрд┐рд╕реЗ рдХреЙрд▓ рдХрд░рдирд╛ рд╣реИ, рдпрд╣ рдЪреБрдирдиреЗ рдХреА рдЕрдиреБрдорддрд┐ рджреЗ рд╕рдХрддреЗ рд╣реИрдВ, рдПрдХ рдРрд╕рд╛ рдПрдЬреЗрдВрдЯ рдмрдирд╛рдиреЗ рдХреЗ рд▓рд┐рдП рдЬреЛ рдмрд╛рд░-рдмрд╛рд░ рдЯреВрд▓ рдХреЙрд▓ рдХрд░рддрд╛ рд╣реИ рдФрд░ рдПрдХ рдХреНрд╡реЗрд░реА рдХреЛ рд╣рд▓ рдХрд░рдиреЗ рддрдХ рдкрд░рд┐рдгрд╛рдо рдкреНрд░рд╛рдкреНрдд рдХрд░рддрд╛ рд╣реИред

рдпрд╣ [OpenAI рдЯреВрд▓ рдПрдЬреЗрдВрдЯ](/docs/modules/agents/agent_types/openai_tools/) рдХрд╛ рдПрдХ рдЕрдзрд┐рдХ рд╕рд╛рдорд╛рдиреНрдпреАрдХреГрдд рд╕рдВрд╕реНрдХрд░рдг рд╣реИ, рдЬреЛ OpenAI рдХреЗ рдЯреВрд▓ рдХреЙрд▓рд┐рдВрдЧ рдХреЗ рд╡рд┐рд╢рд┐рд╖реНрдЯ рд╢реИрд▓реА рдХреЗ рд▓рд┐рдП рдбрд┐рдЬрд╝рд╛рдЗрди рдХрд┐рдпрд╛ рдЧрдпрд╛ рдерд╛ред рдпрд╣ LangChain рдХреЗ ToolCall рдЗрдВрдЯрд░рдлрд╝реЗрд╕ рдХрд╛ рдЙрдкрдпреЛрдЧ рдХрд░рдХреЗ рдПрдХ рд╡реНрдпрд╛рдкрдХ рд╢реНрд░реГрдВрдЦрд▓рд╛ рдХреЗ рдкреНрд░рджрд╛рддрд╛ рдХрд╛рд░реНрдпрд╛рдиреНрд╡рдпрдиреЛрдВ рдХрд╛ рд╕рдорд░реНрдерди рдХрд░рддрд╛ рд╣реИ, рдЬреИрд╕реЗ [Anthropic](/docs/integrations/chat/anthropic/), [Google Gemini](/docs/integrations/chat/google_vertex_ai_palm/), рдФрд░ [Mistral](/docs/integrations/chat/mistralai/) рдХреЗ рдЕрд▓рд╛рд╡рд╛ [OpenAI](/docs/integrations/chat/openai/)ред

## рд╕реЗрдЯрдЕрдк

рдЯреВрд▓ рдХреЙрд▓рд┐рдВрдЧ рдХрд╛ рд╕рдорд░реНрдерди рдХрд░рдиреЗ рд╡рд╛рд▓реЗ рдХрд┐рд╕реА рднреА рдореЙрдбрд▓ рдХрд╛ рдЙрдкрдпреЛрдЧ рдЗрд╕ рдПрдЬреЗрдВрдЯ рдореЗрдВ рдХрд┐рдпрд╛ рдЬрд╛ рд╕рдХрддрд╛ рд╣реИред рдЖрдк рдпрд╣рд╛рдВ рджреЗрдЦ рд╕рдХрддреЗ рд╣реИрдВ рдХрд┐ рдХреМрди рд╕реЗ рдореЙрдбрд▓ рдЯреВрд▓ рдХреЙрд▓рд┐рдВрдЧ рдХрд╛ рд╕рдорд░реНрдерди рдХрд░рддреЗ рд╣реИрдВ [рдпрд╣рд╛рдВ](/docs/integrations/chat/)

рдпрд╣ рдбреЗрдореЛ [Tavily](https://app.tavily.com) рдХрд╛ рдЙрдкрдпреЛрдЧ рдХрд░рддрд╛ рд╣реИ, рд▓реЗрдХрд┐рди рдЖрдк рдХрд┐рд╕реА рдЕрдиреНрдп [рдмрд┐рд▓реНрдЯ-рдЗрди рдЯреВрд▓](/docs/integrations/tools) рдХреЛ рднреА рд╕реНрд╡реИрдк рдХрд░ рд╕рдХрддреЗ рд╣реИрдВ рдпрд╛ [рдХрд╕реНрдЯрдо рдЯреВрд▓](/docs/modules/tools/custom_tools/) рдЬреЛрдбрд╝ рд╕рдХрддреЗ рд╣реИрдВред
рдЖрдкрдХреЛ рдПрдХ API рдХреБрдВрдЬреА рдХреЗ рд▓рд┐рдП рд╕рд╛рдЗрди рдЕрдк рдХрд░рдирд╛ рд╣реЛрдЧрд╛ рдФрд░ рдЗрд╕реЗ `process.env.TAVILY_API_KEY` рдХреЗ рд░реВрдк рдореЗрдВ рд╕реЗрдЯ рдХрд░рдирд╛ рд╣реЛрдЧрд╛ред

import ChatModelTabs from "@theme/ChatModelTabs";

<ChatModelTabs
  customVarName="llm"
  hideCohere
/>

```python
# | output: false
# | echo: false

from langchain_anthropic import ChatAnthropic

llm = ChatAnthropic(model="claude-3-sonnet-20240229", temperature=0)
```

## рдЯреВрд▓реНрд╕ рдХреЛ рдЗрдирд┐рд╢рд┐рдпрд▓рд╛рдЗрдЬрд╝ рдХрд░реЗрдВ

рд╣рдо рдкрд╣рд▓реЗ рдПрдХ рдРрд╕рд╛ рдЯреВрд▓ рдмрдирд╛рдПрдВрдЧреЗ рдЬреЛ рд╡реЗрдм рдХреЛ рдЦреЛрдЬ рд╕рдХрддрд╛ рд╣реИ:

```python
from langchain.agents import AgentExecutor, create_tool_calling_agent
from langchain_community.tools.tavily_search import TavilySearchResults
from langchain_core.prompts import ChatPromptTemplate

tools = [TavilySearchResults(max_results=1)]
```

## рдПрдЬреЗрдВрдЯ рдмрдирд╛рдПрдВ

рдЕрдм, рдЖрдЗрдП рд╣рдорд╛рд░реЗ рдЯреВрд▓ рдХреЙрд▓рд┐рдВрдЧ рдПрдЬреЗрдВрдЯ рдХреЛ рдЗрдирд┐рд╢рд┐рдпрд▓рд╛рдЗрдЬрд╝ рдХрд░реЗрдВ:

```python
prompt = ChatPromptTemplate.from_messages(
    [
        (
            "system",
            "You are a helpful assistant. Make sure to use the tavily_search_results_json tool for information.",
        ),
        ("placeholder", "{chat_history}"),
        ("human", "{input}"),
        ("placeholder", "{agent_scratchpad}"),
    ]
)

# Construct the Tools agent
agent = create_tool_calling_agent(llm, tools, prompt)
```

## рдПрдЬреЗрдВрдЯ рдЪрд▓рд╛рдПрдВ

рдЕрдм, рдЪрд▓рд┐рдП рд╣рдо рдЙрд╕ рдХрд╛рд░реНрдпрдкрд╛рд▓рдХ рдХреЛ рдкреНрд░рд╛рд░рдВрдн рдХрд░рддреЗ рд╣реИрдВ рдЬреЛ рд╣рдорд╛рд░реЗ рдПрдЬреЗрдВрдЯ рдХреЛ рдЪрд▓рд╛рдПрдЧрд╛ рдФрд░ рдЗрд╕реЗ рдЖрдордВрддреНрд░рд┐рдд рдХрд░реЗрдВрдЧреЗ!

```python
# Create an agent executor by passing in the agent and tools
agent_executor = AgentExecutor(agent=agent, tools=tools, verbose=True)
agent_executor.invoke({"input": "what is LangChain?"})
```

```output


[1m> Entering new AgentExecutor chain...[0m

/Users/bagatur/langchain/libs/partners/anthropic/langchain_anthropic/chat_models.py:347: UserWarning: stream: Tool use is not yet supported in streaming mode.
  warnings.warn("stream: Tool use is not yet supported in streaming mode.")

[32;1m[1;3m
Invoking: `tavily_search_results_json` with `{'query': 'LangChain'}`
responded: [{'id': 'toolu_01QxrrT9srzkYCNyEZMDhGeg', 'input': {'query': 'LangChain'}, 'name': 'tavily_search_results_json', 'type': 'tool_use'}]

[0m[36;1m[1;3m[{'url': 'https://github.com/langchain-ai/langchain', 'content': 'About\nтЪб Building applications with LLMs through composability тЪб\nResources\nLicense\nCode of conduct\nSecurity policy\nStars\nWatchers\nForks\nReleases\n291\nPackages\n0\nUsed by 39k\nContributors\n1,848\nLanguages\nFooter\nFooter navigation Latest commit\nGit stats\nFiles\nREADME.md\nЁЯжЬя╕ПЁЯФЧ LangChain\nтЪб Building applications with LLMs through composability тЪб\nLooking for the JS/TS library? тЪб Building applications with LLMs through composability тЪб\nLicense\nlangchain-ai/langchain\nName already in use\nUse Git or checkout with SVN using the web URL.\n ЁЯУЦ Documentation\nPlease see here for full documentation, which includes:\nЁЯТБ Contributing\nAs an open-source project in a rapidly developing field, we are extremely open to contributions, whether it be in the form of a new feature, improved infrastructure, or better documentation.\n What can you build with LangChain?\nтЭУ Retrieval augmented generation\nЁЯТм Analyzing structured data\nЁЯдЦ Chatbots\nAnd much more!'}][0m

/Users/bagatur/langchain/libs/partners/anthropic/langchain_anthropic/chat_models.py:347: UserWarning: stream: Tool use is not yet supported in streaming mode.
  warnings.warn("stream: Tool use is not yet supported in streaming mode.")

[32;1m[1;3mLangChain is an open-source Python library that helps developers build applications with large language models (LLMs) through composability. Some key features of LangChain include:

- Retrieval augmented generation - Allowing LLMs to retrieve and utilize external data sources when generating outputs.

- Analyzing structured data - Tools for working with structured data like databases, APIs, PDFs, etc. and allowing LLMs to reason over this data.

- Building chatbots and agents - Frameworks for building conversational AI applications.

- Composability - LangChain allows you to chain together different LLM capabilities and data sources in a modular and reusable way.

The library aims to make it easier to build real-world applications that leverage the power of large language models in a scalable and robust way. It provides abstractions and primitives for working with LLMs from different providers like OpenAI, Anthropic, Cohere, etc. LangChain is open-source and has an active community contributing new features and improvements.[0m

[1m> Finished chain.[0m
```

```output
{'input': 'what is LangChain?',
 'output': 'LangChain is an open-source Python library that helps developers build applications with large language models (LLMs) through composability. Some key features of LangChain include:\n\n- Retrieval augmented generation - Allowing LLMs to retrieve and utilize external data sources when generating outputs.\n\n- Analyzing structured data - Tools for working with structured data like databases, APIs, PDFs, etc. and allowing LLMs to reason over this data.\n\n- Building chatbots and agents - Frameworks for building conversational AI applications.\n\n- Composability - LangChain allows you to chain together different LLM capabilities and data sources in a modular and reusable way.\n\nThe library aims to make it easier to build real-world applications that leverage the power of large language models in a scalable and robust way. It provides abstractions and primitives for working with LLMs from different providers like OpenAI, Anthropic, Cohere, etc. LangChain is open-source and has an active community contributing new features and improvements.'}
```

:::tip
[LangSmith trace](https://smith.langchain.com/public/2f956a2e-0820-47c4-a798-c83f024e5ca1/r)
:::

## рдЪреИрдЯ рдЗрддрд┐рд╣рд╛рд╕ рдХреЗ рд╕рд╛рде рдЙрдкрдпреЛрдЧ рдХрд░рдирд╛

рдЗрд╕ рдкреНрд░рдХрд╛рд░ рдХрд╛ рдПрдЬреЗрдВрдЯ рд╡реИрдХрд▓реНрдкрд┐рдХ рд░реВрдк рд╕реЗ рдкрд┐рдЫрд▓реЗ рд╡рд╛рд░реНрддрд╛рд▓рд╛рдк рдЯрд░реНрди рдХреЛ рдкреНрд░рддрд┐рдирд┐рдзрд┐рддреНрд╡ рдХрд░рдиреЗ рд╡рд╛рд▓реЗ рдЪреИрдЯ рд╕рдВрджреЗрд╢реЛрдВ рдХреЛ рд▓реЗ рд╕рдХрддрд╛ рд╣реИред рдпрд╣ рдкрд┐рдЫрд▓реЗ рдЗрддрд┐рд╣рд╛рд╕ рдХрд╛ рдЙрдкрдпреЛрдЧ рдХрд░рдХреЗ рд╕рдВрд╡рд╛рджрд╛рддреНрдордХ рд░реВрдк рд╕реЗ рдкреНрд░рддрд┐рдХреНрд░рд┐рдпрд╛ рджреЗ рд╕рдХрддрд╛ рд╣реИред рдЕрдзрд┐рдХ рдЬрд╛рдирдХрд╛рд░реА рдХреЗ рд▓рд┐рдП, [рдПрдЬреЗрдВрдЯ рддреНрд╡рд░рд┐рдд рд╢реБрд░реБрдЖрдд рдХреЗ рдЗрд╕ рдЦрдВрдб](/docs/modules/agents/quick_start#adding-in-memory) рджреЗрдЦреЗрдВред

```python
from langchain_core.messages import AIMessage, HumanMessage

agent_executor.invoke(
    {
        "input": "what's my name? Don't use tools to look this up unless you NEED to",
        "chat_history": [
            HumanMessage(content="hi! my name is bob"),
            AIMessage(content="Hello Bob! How can I assist you today?"),
        ],
    }
)
```

```output


[1m> Entering new AgentExecutor chain...[0m

/Users/bagatur/langchain/libs/partners/anthropic/langchain_anthropic/chat_models.py:347: UserWarning: stream: Tool use is not yet supported in streaming mode.
  warnings.warn("stream: Tool use is not yet supported in streaming mode.")

[32;1m[1;3mBased on what you told me, your name is Bob. I don't need to use any tools to look that up since you directly provided your name.[0m

[1m> Finished chain.[0m
```

```output
{'input': "what's my name? Don't use tools to look this up unless you NEED to",
 'chat_history': [HumanMessage(content='hi! my name is bob'),
  AIMessage(content='Hello Bob! How can I assist you today?')],
 'output': "Based on what you told me, your name is Bob. I don't need to use any tools to look that up since you directly provided your name."}
```

:::tip
[LangSmith trace](https://smith.langchain.com/public/e21ececb-2e60-49e5-9f06-a91b0fb11fb8/r)
:::
