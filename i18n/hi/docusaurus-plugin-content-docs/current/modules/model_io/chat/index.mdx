---
sidebar_class_name: hidden
sidebar_position: 3
translated: true
---

# चैट मॉडल

चैट मॉडल LangChain का एक प्रमुख घटक हैं।

एक चैट मॉडल एक भाषा मॉडल है जो चैट संदेशों को इनपुट के रूप में उपयोग करता है और चैट संदेशों को आउटपुट के रूप में वापस देता है (सादे पाठ के विपरीत)।

LangChain के पास कई मॉडल प्रदाताओं (OpenAI, Cohere, Hugging Face आदि) के साथ एकीकरण हैं और इन सभी मॉडलों के साथ इंटरैक्ट करने के लिए एक मानक इंटरफ़ेस प्रदान करता है।

LangChain आपको सिंक, असिंक, बैचिंग और स्ट्रीमिंग मोड में मॉडलों का उपयोग करने और अन्य सुविधाएं (जैसे कैशिंग) और अधिक प्रदान करने की अनुमति देता है।

## [त्वरित शुरुआत](./quick_start)

[इस त्वरित शुरुआत](./quick_start) को देखें ताकि ChatModels के साथ काम करने के सभी अलग-अलग तरीकों का अवलोकन प्राप्त कर सकें

## [एकीकरण](/docs/integrations/chat/)

LangChain द्वारा प्रदान किए गए सभी एलएलएम एकीकरणों की पूरी सूची के लिए, कृपया [एकीकरण पृष्ठ](/docs/integrations/chat/) पर जाएं

## कैसे-करें गाइड

हम LLM के अधिक उन्नत उपयोग के लिए कई कैसे-करें गाइड हैं।
इसमें शामिल हैं:

- [ChatModel प्रतिक्रियाओं को कैशे करने का तरीका](./chat_model_caching)
- [कार्य कॉलिंग का समर्थन करने वाले ChatModels का उपयोग करने का तरीका](./function_calling)
- [ChatModel से प्रतिक्रियाएं स्ट्रीम करने का तरीका](./streaming)
- [ChatModel कॉल में टोकन उपयोग ट्रैक करने का तरीका](./token_usage_tracking)
- [कस्टम ChatModel कैसे बनाएं](./custom_chat_model)
