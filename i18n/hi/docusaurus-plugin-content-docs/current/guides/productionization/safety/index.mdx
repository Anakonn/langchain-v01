---
translated: true
---

# गोपनीयता और सुरक्षा

एलएलएम का उपयोग करने के साथ एक प्रमुख चिंता यह है कि वे निजी डेटा का दुरुपयोग कर सकते हैं या हानिकारक या अनैतिक पाठ उत्पन्न कर सकते हैं। यह क्षेत्र में सक्रिय अनुसंधान का एक क्षेत्र है। यहां हम इस अनुसंधान से प्रेरित कुछ बिल्ट-इन श्रृंखलाएं प्रस्तुत करते हैं, जिनका उद्देश्य एलएलएम के आउटपुट को सुरक्षित बनाना है।

- [Amazon Comprehend मॉडरेशन श्रृंखला](/docs/guides/productionization/safety/amazon_comprehend_chain): व्यक्तिगत रूप से पहचानने योग्य जानकारी (PII) और विषाक्तता का पता लगाने और संभाल करने के लिए [Amazon Comprehend](https://aws.amazon.com/comprehend/) का उपयोग करें।
- [संवैधानिक श्रृंखला](/docs/guides/productionization/safety/constitutional_chain): मॉडल के व्यवहार को मार्गदर्शित करने वाले सिद्धांतों का सेट मॉडल को प्रेरित करें।
- [Hugging Face प्रॉम्प्ट इंजेक्शन पहचान](/docs/guides/productionization/safety/hugging_face_prompt_injection): प्रॉम्प्ट इंजेक्शन हमलों का पता लगाएं और संभालें।
- [Layerup सुरक्षा](/docs/guides/productionization/safety/layerup_security): आसानी से PII और संवेदनशील डेटा को मास्क करें, 10+ एलएलएम-आधारित खतरों का पता लगाएं और उन्हें कम करें, जिनमें PII और संवेदनशील डेटा, प्रॉम्प्ट इंजेक्शन, हैल्यूसिनेशन, दुरुपयोग और अधिक शामिल हैं।
- [तार्किक दोष श्रृंखला](/docs/guides/productionization/safety/logical_fallacy_chain): किसी भी विचलन को सुधारने के लिए मॉडल आउटपुट को तार्किक दोषों के खिलाफ जांचता है।
- [मॉडरेशन श्रृंखला](/docs/guides/productionization/safety/moderation): यह देखने के लिए कि क्या कोई आउटपुट पाठ हानिकारक है और उसे फ्लैग करें।
- [Presidio डेटा अनोनीमाइजेशन](/docs/guides/productionization/safety/presidio_data_anonymization): संवेदनशील डेटा को उचित रूप से प्रबंधित और शासित किया जाना सुनिश्चित करने में मदद करता है।
