---
translated: true
---

# बैडू क़्यानफ़ान

बैडू एआई क्लाउड क़्यानफ़ान प्लेटफ़ॉर्म एक वन-स्टॉप बड़े मॉडल विकास और सेवा संचालन प्लेटफ़ॉर्म है जो उद्यम डेवलपर्स के लिए है। क़्यानफ़ान न केवल वेनक्सिन यियान (ERNIE-Bot) और तीसरे पक्ष के ओपन-सोर्स मॉडल्स को प्रदान करता है, बल्कि विभिन्न एआई विकास उपकरण और पूरा विकास वातावरण भी प्रदान करता है, जो ग्राहकों को बड़े मॉडल अनुप्रयोगों का उपयोग और विकास करने में आसान बनाता है।

मूल रूप से, ये मॉडल निम्नलिखित प्रकार में विभाजित हैं:

- एम्बेडिंग
- चैट
- पूर्णता

इस नोटबुक में, हम लैंगचेन के साथ [क़्यानफ़ान](https://cloud.baidu.com/doc/WENXINWORKSHOP/index.html) का उपयोग करने के बारे में बताएंगे, मुख्य रूप से `एम्बेडिंग` के लिए जो लैंगचेन में `langchain/embeddings` पैकेज से संबंधित है:

## एपीआई प्रारंभीकरण

बैडू क़्यानफ़ान पर आधारित एलएलएम सेवाओं का उपयोग करने के लिए, आपको इन पैरामीटरों को प्रारंभ करना होगा:

आप या तो पर्यावरण चर में एके, एसके को प्रारंभ कर सकते हैं या पैरामीटर प्रारंभ कर सकते हैं:

```base
export QIANFAN_AK=XXX
export QIANFAN_SK=XXX
```

```python
"""For basic init and call"""
import os

from langchain_community.embeddings import QianfanEmbeddingsEndpoint

os.environ["QIANFAN_AK"] = "your_ak"
os.environ["QIANFAN_SK"] = "your_sk"

embed = QianfanEmbeddingsEndpoint(
    # qianfan_ak='xxx',
    # qianfan_sk='xxx'
)
res = embed.embed_documents(["hi", "world"])


async def aioEmbed():
    res = await embed.aembed_query("qianfan")
    print(res[:8])


await aioEmbed()


async def aioEmbedDocs():
    res = await embed.aembed_documents(["hi", "world"])
    for r in res:
        print("", r[:8])


await aioEmbedDocs()
```

```output
[INFO] [09-15 20:01:35] logging.py:55 [t:140292313159488]: trying to refresh access_token
[INFO] [09-15 20:01:35] logging.py:55 [t:140292313159488]: successfully refresh access_token
[INFO] [09-15 20:01:35] logging.py:55 [t:140292313159488]: requesting llm api endpoint: /embeddings/embedding-v1
[INFO] [09-15 20:01:35] logging.py:55 [t:140292313159488]: async requesting llm api endpoint: /embeddings/embedding-v1
[INFO] [09-15 20:01:35] logging.py:55 [t:140292313159488]: async requesting llm api endpoint: /embeddings/embedding-v1

[-0.03313107788562775, 0.052325375378131866, 0.04951248690485954, 0.0077608139254152775, -0.05907672271132469, -0.010798933915793896, 0.03741293027997017, 0.013969100080430508]
 [0.0427522286772728, -0.030367236584424973, -0.14847028255462646, 0.055074431002140045, -0.04177454113960266, -0.059512972831726074, -0.043774791061878204, 0.0028191760648041964]
 [0.03803155943751335, -0.013231384567916393, 0.0032379645854234695, 0.015074018388986588, -0.006529552862048149, -0.13813287019729614, 0.03297128155827522, 0.044519297778606415]
```

## क़्यानफ़ान में विभिन्न मॉडल का उपयोग करें

अगर आप अपना खुद का मॉडल एर्नी बॉट या तीसरे पक्ष के ओपन सोर्स मॉडल पर आधारित तैनात करना चाहते हैं, तो आप इन चरणों का पालन कर सकते हैं:

- 1. (वैकल्पिक, यदि मॉडल डिफ़ॉल्ट मॉडलों में शामिल हैं, तो इसे छोड़ दें) क़्यानफ़ान कंसोल में अपना मॉडल तैनात करें, अपना कस्टमाइज़्ड तैनाती एंडपॉइंट प्राप्त करें।
- 2. प्रारंभीकरण में `endpoint` नामक फ़ील्ड को सेट करें:

```python
embed = QianfanEmbeddingsEndpoint(model="bge_large_zh", endpoint="bge_large_zh")

res = embed.embed_documents(["hi", "world"])
for r in res:
    print(r[:8])
```

```output
[INFO] [09-15 20:01:40] logging.py:55 [t:140292313159488]: requesting llm api endpoint: /embeddings/bge_large_zh

[-0.0001582596160005778, -0.025089964270591736, -0.03997539356350899, 0.013156415894627571, 0.000135212714667432, 0.012428865768015385, 0.016216561198234558, -0.04126659780740738]
[0.0019113451708108187, -0.008625439368188381, -0.0531032420694828, -0.0018436014652252197, -0.01818147301673889, 0.010310115292668343, -0.008867680095136166, -0.021067561581730843]
```
