---
sidebar_position: 2
translated: true
---

# рдкреБрдирд░реНрдкреНрд░рд╛рдкреНрддрд┐

рдкреБрдирд░реНрдкреНрд░рд╛рдкреНрддрд┐ рдПрдХ рд╕рд╛рдорд╛рдиреНрдп рддрдХрдиреАрдХ рд╣реИ рдЬрд┐рд╕рдХрд╛ рдЙрдкрдпреЛрдЧ рдЪреИрдЯрдмреЙрдЯ рдЕрдкрдиреЗ рдкреНрд░рд╢рд┐рдХреНрд╖рдг рдбреЗрдЯрд╛ рдХреЗ рдмрд╛рд╣рд░ рдХреЗ рдбреЗрдЯрд╛ рд╕реЗ рдЕрдкрдиреЗ рдкреНрд░рддрд┐рдХреНрд░рд┐рдпрд╛рдУрдВ рдХреЛ рдмрдврд╝рд╛рдиреЗ рдХреЗ рд▓рд┐рдП рдХрд░рддреЗ рд╣реИрдВред рдпрд╣ рдЦрдВрдб рдЪреИрдЯрдмреЙрдЯ рдХреЗ рд╕рдВрджрд░реНрдн рдореЗрдВ рдкреБрдирд░реНрдкреНрд░рд╛рдкреНрддрд┐ рдХреЛ рдХреИрд╕реЗ рд▓рд╛рдЧреВ рдХрд░реЗрдВ, рдЗрд╕ рдкрд░ рдХрд╡рд░ рдХрд░реЗрдЧрд╛, рд▓реЗрдХрд┐рди рдпрд╣ рдзреНрдпрд╛рди рджреЗрдиреЗ рдпреЛрдЧреНрдп рд╣реИ рдХрд┐ рдкреБрдирд░реНрдкреНрд░рд╛рдкреНрддрд┐ рдПрдХ рдмрд╣реБрдд рд╣реА рд╕реВрдХреНрд╖реНрдо рдФрд░ рдЧрд╣рд░рд╛ рд╡рд┐рд╖рдп рд╣реИ - рд╣рдо рдЖрдкрдХреЛ [рдкреНрд░рд▓реЗрдЦрди рдХреЗ рдЕрдиреНрдп рднрд╛рдЧреЛрдВ](/docs/use_cases/question_answering/) рдХрд╛ рдЕрдиреНрд╡реЗрд╖рдг рдХрд░рдиреЗ рдХреЗ рд▓рд┐рдП рдкреНрд░реЛрддреНрд╕рд╛рд╣рд┐рдд рдХрд░рддреЗ рд╣реИрдВ рдЬреЛ рдЗрд╕ рдкрд░ рдЕрдзрд┐рдХ рдЧрд╣рд░рд╛рдИ рд╕реЗ рдЬрд╛рддреЗ рд╣реИрдВ!

## рд╕реЗрдЯрдЕрдк

рдЖрдкрдХреЛ рдХреБрдЫ рдкреИрдХреЗрдЬ рдЗрдВрд╕реНрдЯреЙрд▓ рдХрд░рдиреЗ рд╣реЛрдВрдЧреЗ, рдФрд░ рдЖрдкрдХрд╛ OpenAI API рдХреБрдВрдЬреА `OPENAI_API_KEY` рдирд╛рдо рдХреЗ рдПрдХ рдкрд░реНрдпрд╛рд╡рд░рдг рдЪрд░ рдХреЗ рд░реВрдк рдореЗрдВ рд╕реЗрдЯ рд╣реЛрдиреА рдЪрд╛рд╣рд┐рдП:

```python
%pip install --upgrade --quiet langchain langchain-openai langchain-chroma beautifulsoup4

# Set env var OPENAI_API_KEY or load from a .env file:
import dotenv

dotenv.load_dotenv()
```

```output
[33mWARNING: You are using pip version 22.0.4; however, version 23.3.2 is available.
You should consider upgrading via the '/Users/jacoblee/.pyenv/versions/3.10.5/bin/python -m pip install --upgrade pip' command.[0m[33m
[0mNote: you may need to restart the kernel to use updated packages.
```

```output
True
```

рдЖрдЗрдП рдиреАрдЪреЗ рджрд┐рдП рдЧрдП рдЙрджрд╛рд╣рд░рдгреЛрдВ рдХреЗ рд▓рд┐рдП рдЙрдкрдпреЛрдЧ рдХрд░рдиреЗ рдХреЗ рд▓рд┐рдП рдПрдХ рдЪреИрдЯ рдореЙрдбрд▓ рднреА рд╕реЗрдЯ рдХрд░реЗрдВред

```python
from langchain_openai import ChatOpenAI

chat = ChatOpenAI(model="gpt-3.5-turbo-1106", temperature=0.2)
```

## рдПрдХ рдкреБрдирд░реНрдкреНрд░рд╛рдкреНрддрдХрд░реНрддрд╛ рдмрдирд╛рдирд╛

рд╣рдо [LangSmith рдкреНрд░рд▓реЗрдЦрди](https://docs.smith.langchain.com/overview) рдХреЛ рд╕реНрд░реЛрдд рд╕рд╛рдордЧреНрд░реА рдХреЗ рд░реВрдк рдореЗрдВ рдЙрдкрдпреЛрдЧ рдХрд░реЗрдВрдЧреЗ рдФрд░ рдмрд╛рдж рдореЗрдВ рдкреБрдирд░реНрдкреНрд░рд╛рдкреНрддрд┐ рдХреЗ рд▓рд┐рдП рд╕рд╛рдордЧреНрд░реА рдХреЛ рдПрдХ рд╡реЗрдХреНрдЯрд░ рд╕реНрдЯреЛрд░ рдореЗрдВ рд╕рдВрдЧреНрд░рд╣реАрдд рдХрд░реЗрдВрдЧреЗред рдзреНрдпрд╛рди рджреЗрдВ рдХрд┐ рдЗрд╕ рдЙрджрд╛рд╣рд░рдг рдореЗрдВ рдбреЗрдЯрд╛ рд╕реНрд░реЛрдд рдХреЛ рдкрд╛рд░реНрд╕ рдФрд░ рд╕рдВрдЧреНрд░рд╣реАрдд рдХрд░рдиреЗ рдХреЗ рд╡рд┐рд╢рд┐рд╖реНрдЯреЛрдВ рдХреЛ рдирдЬрд╝рд░рдЕрдВрджрд╛рдЬрд╝ рдХрд░ рджрд┐рдпрд╛ рдЬрд╛рдПрдЧрд╛ - рдЖрдк [рдкреБрдирд░реНрдкреНрд░рд╛рдкреНрддрд┐ рдкреНрд░рдгрд╛рд▓рд┐рдпреЛрдВ рдХреЛ рдмрдирд╛рдиреЗ рдкрд░ рдЕрдзрд┐рдХ рдЧрд╣рди рдкреНрд░рд▓реЗрдЦрди](/docs/use_cases/question_answering/) рджреЗрдЦ рд╕рдХрддреЗ рд╣реИрдВред

рдЖрдЗрдП рдПрдХ рджрд╕реНрддрд╛рд╡реЗрдЬрд╝ рд▓реЛрдбрд░ рдХрд╛ рдЙрдкрдпреЛрдЧ рдХрд░рдХреЗ рджрд╕реНрддрд╛рд╡реЗрдЬрд╝реЛрдВ рд╕реЗ рдкрд╛рда рдЦреАрдВрдЪреЗрдВ:

```python
from langchain_community.document_loaders import WebBaseLoader

loader = WebBaseLoader("https://docs.smith.langchain.com/overview")
data = loader.load()
```

рдЕрдЧрд▓рд╛, рд╣рдо рдЗрд╕реЗ рдЫреЛрдЯреЗ-рдЫреЛрдЯреЗ рдЯреБрдХрдбрд╝реЛрдВ рдореЗрдВ рд╡рд┐рднрд╛рдЬрд┐рдд рдХрд░реЗрдВрдЧреЗ рдЬрд┐рдирдХрд╛ LLM рдХрд╛ рд╕рдВрджрд░реНрдн рд╡рд┐рдВрдбреЛ рд╕рдВрднрд╛рд▓ рд╕рдХрддрд╛ рд╣реИ рдФрд░ рдЙрдиреНрд╣реЗрдВ рдПрдХ рд╡реЗрдХреНрдЯрд░ рдбреЗрдЯрд╛рдмреЗрд╕ рдореЗрдВ рд╕рдВрдЧреНрд░рд╣реАрдд рдХрд░реЗрдВрдЧреЗ:

```python
from langchain_text_splitters import RecursiveCharacterTextSplitter

text_splitter = RecursiveCharacterTextSplitter(chunk_size=500, chunk_overlap=0)
all_splits = text_splitter.split_documents(data)
```

рдлрд┐рд░ рд╣рдо рдЙрди рдЯреБрдХрдбрд╝реЛрдВ рдХреЛ рдПрдореНрдмреЗрдб рдХрд░рдХреЗ рдПрдХ рд╡реЗрдХреНрдЯрд░ рдбреЗрдЯрд╛рдмреЗрд╕ рдореЗрдВ рд╕рдВрдЧреНрд░рд╣реАрдд рдХрд░реЗрдВрдЧреЗ:

```python
from langchain_chroma import Chroma
from langchain_openai import OpenAIEmbeddings

vectorstore = Chroma.from_documents(documents=all_splits, embedding=OpenAIEmbeddings())
```

рдФрд░ рдЕрдВрдд рдореЗрдВ, рдЖрдЗрдП рд╣рдорд╛рд░реЗ рдкрд╣рд▓реЗ рд╕реЗ рд╣реА рдкреНрд░рд╛рд░рдВрдн рдХрд┐рдП рдЧрдП рд╡реЗрдХреНрдЯрд░ рд╕реНрдЯреЛрд░ рд╕реЗ рдПрдХ рдкреБрдирд░реНрдкреНрд░рд╛рдкреНрддрдХрд░реНрддрд╛ рдмрдирд╛рдПрдВ:

```python
# k is the number of chunks to retrieve
retriever = vectorstore.as_retriever(k=4)

docs = retriever.invoke("Can LangSmith help test my LLM applications?")

docs
```

```output
[Document(page_content='Skip to main contentЁЯжЬя╕ПЁЯЫая╕П LangSmith DocsPython DocsJS/TS DocsSearchGo to AppLangSmithOverviewTracingTesting & EvaluationOrganizationsHubLangSmith CookbookOverviewOn this pageLangSmith Overview and User GuideBuilding reliable LLM applications can be challenging. LangChain simplifies the initial setup, but there is still work needed to bring the performance of prompts, chains and agents up the level where they are reliable enough to be used in production.Over the past two months, we at LangChain', metadata={'description': 'Building reliable LLM applications can be challenging. LangChain simplifies the initial setup, but there is still work needed to bring the performance of prompts, chains and agents up the level where they are reliable enough to be used in production.', 'language': 'en', 'source': 'https://docs.smith.langchain.com/overview', 'title': 'LangSmith Overview and User Guide | ЁЯжЬя╕ПЁЯЫая╕П LangSmith'}),
 Document(page_content='LangSmith Overview and User Guide | ЁЯжЬя╕ПЁЯЫая╕П LangSmith', metadata={'description': 'Building reliable LLM applications can be challenging. LangChain simplifies the initial setup, but there is still work needed to bring the performance of prompts, chains and agents up the level where they are reliable enough to be used in production.', 'language': 'en', 'source': 'https://docs.smith.langchain.com/overview', 'title': 'LangSmith Overview and User Guide | ЁЯжЬя╕ПЁЯЫая╕П LangSmith'}),
 Document(page_content='You can also quickly edit examples and add them to datasets to expand the surface area of your evaluation sets or to fine-tune a model for improved quality or reduced costs.Monitoring\u200bAfter all this, your app might finally ready to go in production. LangSmith can also be used to monitor your application in much the same way that you used for debugging. You can log all traces, visualize latency and token usage statistics, and troubleshoot specific issues as they arise. Each run can also be', metadata={'description': 'Building reliable LLM applications can be challenging. LangChain simplifies the initial setup, but there is still work needed to bring the performance of prompts, chains and agents up the level where they are reliable enough to be used in production.', 'language': 'en', 'source': 'https://docs.smith.langchain.com/overview', 'title': 'LangSmith Overview and User Guide | ЁЯжЬя╕ПЁЯЫая╕П LangSmith'}),
 Document(page_content="does that affect the output?\u200bSo you notice a bad output, and you go into LangSmith to see what's going on. You find the faulty LLM call and are now looking at the exact input. You want to try changing a word or a phrase to see what happens -- what do you do?We constantly ran into this issue. Initially, we copied the prompt to a playground of sorts. But this got annoying, so we built a playground of our own! When examining an LLM call, you can click the Open in Playground button to access this", metadata={'description': 'Building reliable LLM applications can be challenging. LangChain simplifies the initial setup, but there is still work needed to bring the performance of prompts, chains and agents up the level where they are reliable enough to be used in production.', 'language': 'en', 'source': 'https://docs.smith.langchain.com/overview', 'title': 'LangSmith Overview and User Guide | ЁЯжЬя╕ПЁЯЫая╕П LangSmith'})]
```

рд╣рдо рджреЗрдЦ рд╕рдХрддреЗ рд╣реИрдВ рдХрд┐ рдЙрдкрд░реЛрдХреНрдд рдкреБрдирд░реНрдкреНрд░рд╛рдкреНрддрдХрд░реНрддрд╛ рдХреЛ рдХреЙрд▓ рдХрд░рдиреЗ рд╕реЗ LangSmith рджрд╕реНрддрд╛рд╡реЗрдЬрд╝реЛрдВ рдХреЗ рдХреБрдЫ рд╣рд┐рд╕реНрд╕реЗ рдорд┐рд▓рддреЗ рд╣реИрдВ рдЬреЛ рд╣рдорд╛рд░реЗ рдЪреИрдЯрдмреЙрдЯ рдХреЛ рдкрд░реАрдХреНрд╖рдг рдХреЗ рдмрд╛рд░реЗ рдореЗрдВ рдЬрд╛рдирдХрд╛рд░реА рджреЗрдиреЗ рдореЗрдВ рдорджрдж рдХрд░ рд╕рдХрддреЗ рд╣реИрдВред рдФрд░ рдЕрдм рд╣рдорд╛рд░реЗ рдкрд╛рд╕ LangSmith рджрд╕реНрддрд╛рд╡реЗрдЬрд╝реЛрдВ рд╕реЗ рд╕рдВрдмрдВрдзрд┐рдд рдбреЗрдЯрд╛ рдХреЛ рд╡рд╛рдкрд╕ рд▓реМрдЯрд╛рдиреЗ рд╡рд╛рд▓рд╛ рдПрдХ рдкреБрдирд░реНрдкреНрд░рд╛рдкреНрддрдХрд░реНрддрд╛ рд╣реИ!

## рджрд╕реНрддрд╛рд╡реЗрдЬрд╝ рд╢реНрд░реГрдВрдЦрд▓рд╛

рдЕрдм рдЬрдм рд╣рдорд╛рд░реЗ рдкрд╛рд╕ LangChain рджрд╕реНрддрд╛рд╡реЗрдЬрд╝реЛрдВ рдХреЛ рд╡рд╛рдкрд╕ рд▓реМрдЯрд╛рдиреЗ рд╡рд╛рд▓рд╛ рдПрдХ рдкреБрдирд░реНрдкреНрд░рд╛рдкреНрддрдХрд░реНрддрд╛ рд╣реИ, рддреЛ рдЖрдЗрдП рдПрдХ рдРрд╕реА рд╢реНрд░реГрдВрдЦрд▓рд╛ рдмрдирд╛рдПрдВ рдЬреЛ рдЙрдиреНрд╣реЗрдВ рд╕рдВрджрд░реНрдн рдХреЗ рд░реВрдк рдореЗрдВ рдЙрдкрдпреЛрдЧ рдХрд░ рд╕рдХрддреА рд╣реИ рдФрд░ рдкреНрд░рд╢реНрдиреЛрдВ рдХрд╛ рдЙрддреНрддрд░ рджреЗ рд╕рдХрддреА рд╣реИред рд╣рдо `create_stuff_documents_chain` рд╣реЗрд▓реНрдкрд░ рдлрд╝рдВрдХреНрд╢рди рдХрд╛ рдЙрдкрдпреЛрдЧ рдХрд░реЗрдВрдЧреЗ рдЬреЛ рдЗрдирдкреБрдЯ рджрд╕реНрддрд╛рд╡реЗрдЬрд╝реЛрдВ рдХреЛ рдкреНрд░реЙрдореНрдкреНрдЯ рдореЗрдВ "рднрд░" рджреЗрдЧрд╛ред рдпрд╣ рджрд╕реНрддрд╛рд╡реЗрдЬрд╝реЛрдВ рдХреЛ рд╕реНрдЯреНрд░рд┐рдВрдЧ рдХреЗ рд░реВрдк рдореЗрдВ рднреА рдлрд╝реЙрд░реНрдореИрдЯ рдХрд░реЗрдЧрд╛ред

рдПрдХ рдЪреИрдЯ рдореЙрдбрд▓ рдХреЗ рдЕрд▓рд╛рд╡рд╛, рдлрд╝рдВрдХреНрд╢рди рдПрдХ рдкреНрд░реЙрдореНрдкреНрдЯ рднреА рдЕрдкреЗрдХреНрд╖рд┐рдд рдХрд░рддрд╛ рд╣реИ рдЬрд┐рд╕рдореЗрдВ `context` рдЪрд░ рд╣реЛрддрд╛ рд╣реИ, рд╕рд╛рде рд╣реА рдЪреИрдЯ рдЗрддрд┐рд╣рд╛рд╕ рд╕рдВрджреЗрд╢реЛрдВ рдХреЗ рд▓рд┐рдП `messages` рдирд╛рдо рдХрд╛ рд╕реНрдерд╛рди рд╣реЛрддрд╛ рд╣реИред рд╣рдо рдПрдХ рдЙрдЪрд┐рдд рдкреНрд░реЙрдореНрдкреНрдЯ рдмрдирд╛рдПрдВрдЧреЗ рдФрд░ рдиреАрдЪреЗ рджрд┐рдЦрд╛рдП рдЧрдП рддрд░реАрдХреЗ рд╕реЗ рдЙрд╕реЗ рдкрд╛рд╕ рдХрд░реЗрдВрдЧреЗ:

```python
from langchain.chains.combine_documents import create_stuff_documents_chain
from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder

SYSTEM_TEMPLATE = """
Answer the user's questions based on the below context.
If the context doesn't contain any relevant information to the question, don't make something up and just say "I don't know":

<context>
{context}
</context>
"""

question_answering_prompt = ChatPromptTemplate.from_messages(
    [
        (
            "system",
            SYSTEM_TEMPLATE,
        ),
        MessagesPlaceholder(variable_name="messages"),
    ]
)

document_chain = create_stuff_documents_chain(chat, question_answering_prompt)
```

рд╣рдо рдЗрд╕ `document_chain` рдХреЛ рдЕрдХреЗрд▓реЗ рдмреБрд▓рд╛ рдХрд░ рдкреНрд░рд╢реНрдиреЛрдВ рдХрд╛ рдЙрддреНрддрд░ рджреЗ рд╕рдХрддреЗ рд╣реИрдВред рдЖрдЗрдП рдЙрдкрд░ рдкреНрд░рд╛рдкреНрдд рджрд╕реНрддрд╛рд╡реЗрдЬрд╝реЛрдВ рдФрд░ рд╕рдорд╛рди рдкреНрд░рд╢реНрди `how can langsmith help with testing?` рдХрд╛ рдЙрдкрдпреЛрдЧ рдХрд░реЗрдВ:

```python
from langchain_core.messages import HumanMessage

document_chain.invoke(
    {
        "context": docs,
        "messages": [
            HumanMessage(content="Can LangSmith help test my LLM applications?")
        ],
    }
)
```

```output
'Yes, LangSmith can help test and evaluate your LLM applications. It simplifies the initial setup, and you can use it to monitor your application, log all traces, visualize latency and token usage statistics, and troubleshoot specific issues as they arise.'
```

рдЕрдЪреНрдЫрд╛ рд▓рдЧ рд░рд╣рд╛ рд╣реИ! рддреБрд▓рдирд╛ рдХреЗ рд▓рд┐рдП, рд╣рдо рдмрд┐рдирд╛ рдХрд┐рд╕реА рд╕рдВрджрд░реНрдн рджрд╕реНрддрд╛рд╡реЗрдЬрд╝реЛрдВ рдХреЗ рднреА рдЗрд╕реЗ рдЖрдЬрд╝рдорд╛ рд╕рдХрддреЗ рд╣реИрдВ рдФрд░ рдкрд░рд┐рдгрд╛рдо рдХреА рддреБрд▓рдирд╛ рдХрд░ рд╕рдХрддреЗ рд╣реИрдВ:

```python
document_chain.invoke(
    {
        "context": [],
        "messages": [
            HumanMessage(content="Can LangSmith help test my LLM applications?")
        ],
    }
)
```

```output
"I don't know about LangSmith's specific capabilities for testing LLM applications. It's best to reach out to LangSmith directly to inquire about their services and how they can assist with testing your LLM applications."
```

рд╣рдо рджреЗрдЦ рд╕рдХрддреЗ рд╣реИрдВ рдХрд┐ LLM рдХреЛрдИ рдкрд░рд┐рдгрд╛рдо рдирд╣реАрдВ рджреЗрддрд╛ред

## рдкреБрдирд░реНрдкреНрд░рд╛рдкреНрддрд┐ рд╢реНрд░реГрдВрдЦрд▓рд╛

рдЖрдЗрдП рдЗрд╕ рджрд╕реНрддрд╛рд╡реЗрдЬрд╝ рд╢реНрд░реГрдВрдЦрд▓рд╛ рдХреЛ рдкреБрдирд░реНрдкреНрд░рд╛рдкреНрддрдХрд░реНрддрд╛ рдХреЗ рд╕рд╛рде рдЬреЛрдбрд╝реЗрдВред рдпрд╣ рдЗрд╕ рддрд░рд╣ рджрд┐рдЦ рд╕рдХрддрд╛ рд╣реИ:

```python
from typing import Dict

from langchain_core.runnables import RunnablePassthrough


def parse_retriever_input(params: Dict):
    return params["messages"][-1].content


retrieval_chain = RunnablePassthrough.assign(
    context=parse_retriever_input | retriever,
).assign(
    answer=document_chain,
)
```

рджрд┐рдП рдЧрдП рдЗрдирдкреБрдЯ рд╕рдВрджреЗрд╢реЛрдВ рдХреА рд╕реВрдЪреА рд╕реЗ, рд╣рдо рд╕реВрдЪреА рдореЗрдВ рдЕрдВрддрд┐рдо рд╕рдВрджреЗрд╢ рдХреЗ рд╕рд╛рдордЧреНрд░реА рдХреЛ рдирд┐рдХрд╛рд▓рддреЗ рд╣реИрдВ рдФрд░ рдЙрд╕реЗ рдкреБрдирд░реНрдкреНрд░рд╛рдкреНрддрдХрд░реНрддрд╛ рдХреЛ рдкрд╛рд╕ рдХрд░рддреЗ рд╣реИрдВ рддрд╛рдХрд┐ рдХреБрдЫ рджрд╕реНрддрд╛рд╡реЗрдЬрд╝ рдкреНрд░рд╛рдкреНрдд рд╣реЛ рд╕рдХреЗрдВред рдлрд┐рд░, рд╣рдо рдЙрди рджрд╕реНрддрд╛рд╡реЗрдЬрд╝реЛрдВ рдХреЛ рд╕рдВрджрд░реНрдн рдХреЗ рд░реВрдк рдореЗрдВ рдЕрдкрдиреЗ рджрд╕реНрддрд╛рд╡реЗрдЬрд╝ рд╢реНрд░реГрдВрдЦрд▓рд╛ рдХреЛ рдкрд╛рд╕ рдХрд░рддреЗ рд╣реИрдВ рддрд╛рдХрд┐ рдПрдХ рдЕрдВрддрд┐рдо рдкреНрд░рддрд┐рдХреНрд░рд┐рдпрд╛ рдЙрддреНрдкрдиреНрди рд╣реЛ рд╕рдХреЗред

рдЗрд╕ рд╢реНрд░реГрдВрдЦрд▓рд╛ рдХреЛ рдХреЙрд▓ рдХрд░рдиреЗ рд╕реЗ рдЙрдкрд░реЛрдХреНрдд рджреЛрдиреЛрдВ рдЪрд░рдг рдПрдХреАрдХреГрдд рд╣реЛ рдЬрд╛рддреЗ рд╣реИрдВ:

```python
retrieval_chain.invoke(
    {
        "messages": [
            HumanMessage(content="Can LangSmith help test my LLM applications?")
        ],
    }
)
```

```output
{'messages': [HumanMessage(content='Can LangSmith help test my LLM applications?')],
 'context': [Document(page_content='Skip to main contentЁЯжЬя╕ПЁЯЫая╕П LangSmith DocsPython DocsJS/TS DocsSearchGo to AppLangSmithOverviewTracingTesting & EvaluationOrganizationsHubLangSmith CookbookOverviewOn this pageLangSmith Overview and User GuideBuilding reliable LLM applications can be challenging. LangChain simplifies the initial setup, but there is still work needed to bring the performance of prompts, chains and agents up the level where they are reliable enough to be used in production.Over the past two months, we at LangChain', metadata={'description': 'Building reliable LLM applications can be challenging. LangChain simplifies the initial setup, but there is still work needed to bring the performance of prompts, chains and agents up the level where they are reliable enough to be used in production.', 'language': 'en', 'source': 'https://docs.smith.langchain.com/overview', 'title': 'LangSmith Overview and User Guide | ЁЯжЬя╕ПЁЯЫая╕П LangSmith'}),
  Document(page_content='LangSmith Overview and User Guide | ЁЯжЬя╕ПЁЯЫая╕П LangSmith', metadata={'description': 'Building reliable LLM applications can be challenging. LangChain simplifies the initial setup, but there is still work needed to bring the performance of prompts, chains and agents up the level where they are reliable enough to be used in production.', 'language': 'en', 'source': 'https://docs.smith.langchain.com/overview', 'title': 'LangSmith Overview and User Guide | ЁЯжЬя╕ПЁЯЫая╕П LangSmith'}),
  Document(page_content='You can also quickly edit examples and add them to datasets to expand the surface area of your evaluation sets or to fine-tune a model for improved quality or reduced costs.Monitoring\u200bAfter all this, your app might finally ready to go in production. LangSmith can also be used to monitor your application in much the same way that you used for debugging. You can log all traces, visualize latency and token usage statistics, and troubleshoot specific issues as they arise. Each run can also be', metadata={'description': 'Building reliable LLM applications can be challenging. LangChain simplifies the initial setup, but there is still work needed to bring the performance of prompts, chains and agents up the level where they are reliable enough to be used in production.', 'language': 'en', 'source': 'https://docs.smith.langchain.com/overview', 'title': 'LangSmith Overview and User Guide | ЁЯжЬя╕ПЁЯЫая╕П LangSmith'}),
  Document(page_content="does that affect the output?\u200bSo you notice a bad output, and you go into LangSmith to see what's going on. You find the faulty LLM call and are now looking at the exact input. You want to try changing a word or a phrase to see what happens -- what do you do?We constantly ran into this issue. Initially, we copied the prompt to a playground of sorts. But this got annoying, so we built a playground of our own! When examining an LLM call, you can click the Open in Playground button to access this", metadata={'description': 'Building reliable LLM applications can be challenging. LangChain simplifies the initial setup, but there is still work needed to bring the performance of prompts, chains and agents up the level where they are reliable enough to be used in production.', 'language': 'en', 'source': 'https://docs.smith.langchain.com/overview', 'title': 'LangSmith Overview and User Guide | ЁЯжЬя╕ПЁЯЫая╕П LangSmith'})],
 'answer': 'Yes, LangSmith can help test and evaluate your LLM applications. It simplifies the initial setup, and you can use it to monitor your application, log all traces, visualize latency and token usage statistics, and troubleshoot specific issues as they arise.'}
```

рдЕрдЪреНрдЫрд╛ рд▓рдЧ рд░рд╣рд╛ рд╣реИ!

## рдХреНрд╡реЗрд░реА рд░реВрдкрд╛рдВрддрд░рдг

рд╣рдорд╛рд░реА рдкреБрдирд░реНрдкреНрд░рд╛рдкреНрддрд┐ рд╢реНрд░реГрдВрдЦрд▓рд╛ LangSmith рдХреЗ рдмрд╛рд░реЗ рдореЗрдВ рдкреНрд░рд╢реНрдиреЛрдВ рдХрд╛ рдЙрддреНрддрд░ рджреЗрдиреЗ рдореЗрдВ рд╕рдХреНрд╖рдо рд╣реИ, рд▓реЗрдХрд┐рди рдПрдХ рд╕рдорд╕реНрдпрд╛ рд╣реИ - рдЪреИрдЯрдмреЙрдЯ рдЙрдкрдпреЛрдЧрдХрд░реНрддрд╛рдУрдВ рдХреЗ рд╕рд╛рде рд╡рд╛рд░реНрддрд╛рд▓рд╛рдк рдХрд░рддреЗ рд╣реИрдВ, рдФрд░ рдЗрд╕рд▓рд┐рдП рдЙрдиреНрд╣реЗрдВ рдлреЙрд▓реЛрдЕрдк рдкреНрд░рд╢реНрдиреЛрдВ рдХрд╛ рд╕рд╛рдордирд╛ рдХрд░рдирд╛ рдкрдбрд╝рддрд╛ рд╣реИред

рд╡рд░реНрддрдорд╛рди рд░реВрдк рдореЗрдВ рд╢реНрд░реГрдВрдЦрд▓рд╛ рдЗрд╕рд╕реЗ рдирд┐рдкрдЯрдиреЗ рдореЗрдВ рдЕрд╕рдорд░реНрде рд╣реЛрдЧреАред рд╣рдорд╛рд░реЗ рдореВрд▓ рдкреНрд░рд╢реНрди рдХреЗ рдПрдХ рдлреЙрд▓реЛрдЕрдк рдкреНрд░рд╢реНрди рдкрд░ рд╡рд┐рдЪрд╛рд░ рдХрд░реЗрдВ рдЬреИрд╕реЗ `Tell me more!`ред рдпрджрд┐ рд╣рдо рдкреБрдирд░реНрдкреНрд░рд╛рдкреНрддрдХрд░реНрддрд╛ рдХреЛ рд╕реАрдзреЗ рдЗрд╕ рдХреНрд╡реЗрд░реА рдХреЗ рд╕рд╛рде рдХреЙрд▓ рдХрд░рддреЗ рд╣реИрдВ, рддреЛ рд╣рдореЗрдВ LLM рдЕрдиреБрдкреНрд░рдпреЛрдЧ рдкрд░реАрдХреНрд╖рдг рд╕реЗ рдЕрдкреНрд░рд╛рд╕рдВрдЧрд┐рдХ рджрд╕реНрддрд╛рд╡реЗрдЬрд╝ рдорд┐рд▓рддреЗ рд╣реИрдВ:

```python
retriever.invoke("Tell me more!")
```

```output
[Document(page_content='You can also quickly edit examples and add them to datasets to expand the surface area of your evaluation sets or to fine-tune a model for improved quality or reduced costs.Monitoring\u200bAfter all this, your app might finally ready to go in production. LangSmith can also be used to monitor your application in much the same way that you used for debugging. You can log all traces, visualize latency and token usage statistics, and troubleshoot specific issues as they arise. Each run can also be', metadata={'description': 'Building reliable LLM applications can be challenging. LangChain simplifies the initial setup, but there is still work needed to bring the performance of prompts, chains and agents up the level where they are reliable enough to be used in production.', 'language': 'en', 'source': 'https://docs.smith.langchain.com/overview', 'title': 'LangSmith Overview and User Guide | ЁЯжЬя╕ПЁЯЫая╕П LangSmith'}),
 Document(page_content='playground. Here, you can modify the prompt and re-run it to observe the resulting changes to the output - as many times as needed!Currently, this feature supports only OpenAI and Anthropic models and works for LLM and Chat Model calls. We plan to extend its functionality to more LLM types, chains, agents, and retrievers in the future.What is the exact sequence of events?\u200bIn complicated chains and agents, it can often be hard to understand what is going on under the hood. What calls are being', metadata={'description': 'Building reliable LLM applications can be challenging. LangChain simplifies the initial setup, but there is still work needed to bring the performance of prompts, chains and agents up the level where they are reliable enough to be used in production.', 'language': 'en', 'source': 'https://docs.smith.langchain.com/overview', 'title': 'LangSmith Overview and User Guide | ЁЯжЬя╕ПЁЯЫая╕П LangSmith'}),
 Document(page_content='however, there is still no complete substitute for human review to get the utmost quality and reliability from your application.', metadata={'description': 'Building reliable LLM applications can be challenging. LangChain simplifies the initial setup, but there is still work needed to bring the performance of prompts, chains and agents up the level where they are reliable enough to be used in production.', 'language': 'en', 'source': 'https://docs.smith.langchain.com/overview', 'title': 'LangSmith Overview and User Guide | ЁЯжЬя╕ПЁЯЫая╕П LangSmith'}),
 Document(page_content='Skip to main contentЁЯжЬя╕ПЁЯЫая╕П LangSmith DocsPython DocsJS/TS DocsSearchGo to AppLangSmithOverviewTracingTesting & EvaluationOrganizationsHubLangSmith CookbookOverviewOn this pageLangSmith Overview and User GuideBuilding reliable LLM applications can be challenging. LangChain simplifies the initial setup, but there is still work needed to bring the performance of prompts, chains and agents up the level where they are reliable enough to be used in production.Over the past two months, we at LangChain', metadata={'description': 'Building reliable LLM applications can be challenging. LangChain simplifies the initial setup, but there is still work needed to bring the performance of prompts, chains and agents up the level where they are reliable enough to be used in production.', 'language': 'en', 'source': 'https://docs.smith.langchain.com/overview', 'title': 'LangSmith Overview and User Guide | ЁЯжЬя╕ПЁЯЫая╕П LangSmith'})]
```

рдпрд╣ рдЗрд╕рд▓рд┐рдП рд╣реИ рдХреНрдпреЛрдВрдХрд┐ рдкреБрдирд░реНрдкреНрд░рд╛рдкреНрддрдХрд░реНрддрд╛ рдореЗрдВ рд╕реНрдерд┐рддрд┐ рдХрд╛ рдХреЛрдИ рдЕрдВрддрд░реНрдирд┐рд╣рд┐рдд рдЕрд╡рдзрд╛рд░рдгрд╛ рдирд╣реАрдВ рд╣реИ, рдФрд░ рд╡рд╣ рдХреЗрд╡рд▓ рджреА рдЧрдИ рдХреНрд╡реЗрд░реА рдХреЗ рд╕рдмрд╕реЗ рд╕рдорд╛рди рджрд╕реНрддрд╛рд╡реЗрдЬрд╝ рдЦреАрдВрдЪреЗрдЧрд╛ред рдЗрд╕рдХрд╛ рд╕рдорд╛рдзрд╛рди рдХрд░рдиреЗ рдХреЗ рд▓рд┐рдП, рд╣рдо рдХреНрд╡реЗрд░реА рдХреЛ рдПрдХ рд╕реНрд╡рддрдВрддреНрд░ рдХреНрд╡реЗрд░реА рдореЗрдВ рд░реВрдкрд╛рдВрддрд░рд┐рдд рдХрд░ рд╕рдХрддреЗ рд╣реИрдВ рдЬрд┐рд╕рдореЗрдВ рдХреЛрдИ рдмрд╛рд╣рд░реА рд╕рдВрджрд░реНрдн рдирд╣реАрдВ рд╣реЛрддрд╛ред

рдпрд╣рд╛рдБ рдПрдХ рдЙрджрд╛рд╣рд░рдг рд╣реИ:

```python
from langchain_core.messages import AIMessage, HumanMessage

query_transform_prompt = ChatPromptTemplate.from_messages(
    [
        MessagesPlaceholder(variable_name="messages"),
        (
            "user",
            "Given the above conversation, generate a search query to look up in order to get information relevant to the conversation. Only respond with the query, nothing else.",
        ),
    ]
)

query_transformation_chain = query_transform_prompt | chat

query_transformation_chain.invoke(
    {
        "messages": [
            HumanMessage(content="Can LangSmith help test my LLM applications?"),
            AIMessage(
                content="Yes, LangSmith can help test and evaluate your LLM applications. It allows you to quickly edit examples and add them to datasets to expand the surface area of your evaluation sets or to fine-tune a model for improved quality or reduced costs. Additionally, LangSmith can be used to monitor your application, log all traces, visualize latency and token usage statistics, and troubleshoot specific issues as they arise."
            ),
            HumanMessage(content="Tell me more!"),
        ],
    }
)
```

```output
AIMessage(content='"LangSmith LLM application testing and evaluation"')
```

рд╢рд╛рдирджрд╛рд░! рдЗрд╕ рд░реВрдкрд╛рдВрддрд░рд┐рдд рдХреНрд╡реЗрд░реА рд╕реЗ LLM рдЕрдиреБрдкреНрд░рдпреЛрдЧ рдкрд░реАрдХреНрд╖рдг рд╕реЗ рд╕рдВрдмрдВрдзрд┐рдд рд╕рдВрджрд░реНрдн рджрд╕реНрддрд╛рд╡реЗрдЬрд╝ рдкреНрд░рд╛рдкреНрдд рд╣реЛрдВрдЧреЗред

рдЖрдЗрдП рдЗрд╕реЗ рд╣рдорд╛рд░реА рдкреБрдирд░реНрдкреНрд░рд╛рдкреНрддрд┐ рд╢реНрд░реГрдВрдЦрд▓рд╛ рдореЗрдВ рдЬреЛрдбрд╝реЗрдВред рд╣рдо рдЕрдкрдиреЗ рдкреБрдирд░реНрдкреНрд░рд╛рдкреНрддрдХрд░реНрддрд╛ рдХреЛ рдирд┐рдореНрдирд╛рдиреБрд╕рд╛рд░ рд▓рдкреЗрдЯ рд╕рдХрддреЗ рд╣реИрдВ:

```python
from langchain_core.output_parsers import StrOutputParser
from langchain_core.runnables import RunnableBranch

query_transforming_retriever_chain = RunnableBranch(
    (
        lambda x: len(x.get("messages", [])) == 1,
        # If only one message, then we just pass that message's content to retriever
        (lambda x: x["messages"][-1].content) | retriever,
    ),
    # If messages, then we pass inputs to LLM chain to transform the query, then pass to retriever
    query_transform_prompt | chat | StrOutputParser() | retriever,
).with_config(run_name="chat_retriever_chain")
```

рдлрд┐рд░, рд╣рдо рдЗрд╕ рдХреНрд╡реЗрд░реА рд░реВрдкрд╛рдВрддрд░рдг рд╢реНрд░реГрдВрдЦрд▓рд╛ рдХрд╛ рдЙрдкрдпреЛрдЧ рдХрд░ рд╕рдХрддреЗ рд╣реИрдВ рддрд╛рдХрд┐ рд╣рдорд╛рд░реА рдкреБрдирд░реНрдкреНрд░рд╛рдкреНрддрд┐ рд╢реНрд░реГрдВрдЦрд▓рд╛ рдРрд╕реЗ рдлреЙрд▓реЛрдЕрдк рдкреНрд░рд╢реНрдиреЛрдВ рд╕реЗ рдмреЗрд╣рддрд░ рдврдВрдЧ рд╕реЗ рдирд┐рдкрдЯ рд╕рдХреЗ:

```python
SYSTEM_TEMPLATE = """
Answer the user's questions based on the below context.
If the context doesn't contain any relevant information to the question, don't make something up and just say "I don't know":

<context>
{context}
</context>
"""

question_answering_prompt = ChatPromptTemplate.from_messages(
    [
        (
            "system",
            SYSTEM_TEMPLATE,
        ),
        MessagesPlaceholder(variable_name="messages"),
    ]
)

document_chain = create_stuff_documents_chain(chat, question_answering_prompt)

conversational_retrieval_chain = RunnablePassthrough.assign(
    context=query_transforming_retriever_chain,
).assign(
    answer=document_chain,
)
```

рд╢рд╛рдирджрд╛рд░! рдЖрдЗрдП рдЗрд╕ рдирдИ рд╢реНрд░реГрдВрдЦрд▓рд╛ рдХреЛ рдкрд╣рд▓реЗ рдХреА рддрд░рд╣ рд╣реА рдЗрдирдкреБрдЯ рдХреЗ рд╕рд╛рде рдХреЙрд▓ рдХрд░реЗрдВ:

```python
conversational_retrieval_chain.invoke(
    {
        "messages": [
            HumanMessage(content="Can LangSmith help test my LLM applications?"),
        ]
    }
)
```

```output
{'messages': [HumanMessage(content='Can LangSmith help test my LLM applications?')],
 'context': [Document(page_content='Skip to main contentЁЯжЬя╕ПЁЯЫая╕П LangSmith DocsPython DocsJS/TS DocsSearchGo to AppLangSmithOverviewTracingTesting & EvaluationOrganizationsHubLangSmith CookbookOverviewOn this pageLangSmith Overview and User GuideBuilding reliable LLM applications can be challenging. LangChain simplifies the initial setup, but there is still work needed to bring the performance of prompts, chains and agents up the level where they are reliable enough to be used in production.Over the past two months, we at LangChain', metadata={'description': 'Building reliable LLM applications can be challenging. LangChain simplifies the initial setup, but there is still work needed to bring the performance of prompts, chains and agents up the level where they are reliable enough to be used in production.', 'language': 'en', 'source': 'https://docs.smith.langchain.com/overview', 'title': 'LangSmith Overview and User Guide | ЁЯжЬя╕ПЁЯЫая╕П LangSmith'}),
  Document(page_content='LangSmith Overview and User Guide | ЁЯжЬя╕ПЁЯЫая╕П LangSmith', metadata={'description': 'Building reliable LLM applications can be challenging. LangChain simplifies the initial setup, but there is still work needed to bring the performance of prompts, chains and agents up the level where they are reliable enough to be used in production.', 'language': 'en', 'source': 'https://docs.smith.langchain.com/overview', 'title': 'LangSmith Overview and User Guide | ЁЯжЬя╕ПЁЯЫая╕П LangSmith'}),
  Document(page_content='You can also quickly edit examples and add them to datasets to expand the surface area of your evaluation sets or to fine-tune a model for improved quality or reduced costs.Monitoring\u200bAfter all this, your app might finally ready to go in production. LangSmith can also be used to monitor your application in much the same way that you used for debugging. You can log all traces, visualize latency and token usage statistics, and troubleshoot specific issues as they arise. Each run can also be', metadata={'description': 'Building reliable LLM applications can be challenging. LangChain simplifies the initial setup, but there is still work needed to bring the performance of prompts, chains and agents up the level where they are reliable enough to be used in production.', 'language': 'en', 'source': 'https://docs.smith.langchain.com/overview', 'title': 'LangSmith Overview and User Guide | ЁЯжЬя╕ПЁЯЫая╕П LangSmith'}),
  Document(page_content="does that affect the output?\u200bSo you notice a bad output, and you go into LangSmith to see what's going on. You find the faulty LLM call and are now looking at the exact input. You want to try changing a word or a phrase to see what happens -- what do you do?We constantly ran into this issue. Initially, we copied the prompt to a playground of sorts. But this got annoying, so we built a playground of our own! When examining an LLM call, you can click the Open in Playground button to access this", metadata={'description': 'Building reliable LLM applications can be challenging. LangChain simplifies the initial setup, but there is still work needed to bring the performance of prompts, chains and agents up the level where they are reliable enough to be used in production.', 'language': 'en', 'source': 'https://docs.smith.langchain.com/overview', 'title': 'LangSmith Overview and User Guide | ЁЯжЬя╕ПЁЯЫая╕П LangSmith'})],
 'answer': 'Yes, LangSmith can help test and evaluate LLM (Language Model) applications. It simplifies the initial setup, and you can use it to monitor your application, log all traces, visualize latency and token usage statistics, and troubleshoot specific issues as they arise.'}
```

```python
conversational_retrieval_chain.invoke(
    {
        "messages": [
            HumanMessage(content="Can LangSmith help test my LLM applications?"),
            AIMessage(
                content="Yes, LangSmith can help test and evaluate your LLM applications. It allows you to quickly edit examples and add them to datasets to expand the surface area of your evaluation sets or to fine-tune a model for improved quality or reduced costs. Additionally, LangSmith can be used to monitor your application, log all traces, visualize latency and token usage statistics, and troubleshoot specific issues as they arise."
            ),
            HumanMessage(content="Tell me more!"),
        ],
    }
)
```

```output
{'messages': [HumanMessage(content='Can LangSmith help test my LLM applications?'),
  AIMessage(content='Yes, LangSmith can help test and evaluate your LLM applications. It allows you to quickly edit examples and add them to datasets to expand the surface area of your evaluation sets or to fine-tune a model for improved quality or reduced costs. Additionally, LangSmith can be used to monitor your application, log all traces, visualize latency and token usage statistics, and troubleshoot specific issues as they arise.'),
  HumanMessage(content='Tell me more!')],
 'context': [Document(page_content='LangSmith Overview and User Guide | ЁЯжЬя╕ПЁЯЫая╕П LangSmith', metadata={'description': 'Building reliable LLM applications can be challenging. LangChain simplifies the initial setup, but there is still work needed to bring the performance of prompts, chains and agents up the level where they are reliable enough to be used in production.', 'language': 'en', 'source': 'https://docs.smith.langchain.com/overview', 'title': 'LangSmith Overview and User Guide | ЁЯжЬя╕ПЁЯЫая╕П LangSmith'}),
  Document(page_content='You can also quickly edit examples and add them to datasets to expand the surface area of your evaluation sets or to fine-tune a model for improved quality or reduced costs.Monitoring\u200bAfter all this, your app might finally ready to go in production. LangSmith can also be used to monitor your application in much the same way that you used for debugging. You can log all traces, visualize latency and token usage statistics, and troubleshoot specific issues as they arise. Each run can also be', metadata={'description': 'Building reliable LLM applications can be challenging. LangChain simplifies the initial setup, but there is still work needed to bring the performance of prompts, chains and agents up the level where they are reliable enough to be used in production.', 'language': 'en', 'source': 'https://docs.smith.langchain.com/overview', 'title': 'LangSmith Overview and User Guide | ЁЯжЬя╕ПЁЯЫая╕П LangSmith'}),
  Document(page_content='Skip to main contentЁЯжЬя╕ПЁЯЫая╕П LangSmith DocsPython DocsJS/TS DocsSearchGo to AppLangSmithOverviewTracingTesting & EvaluationOrganizationsHubLangSmith CookbookOverviewOn this pageLangSmith Overview and User GuideBuilding reliable LLM applications can be challenging. LangChain simplifies the initial setup, but there is still work needed to bring the performance of prompts, chains and agents up the level where they are reliable enough to be used in production.Over the past two months, we at LangChain', metadata={'description': 'Building reliable LLM applications can be challenging. LangChain simplifies the initial setup, but there is still work needed to bring the performance of prompts, chains and agents up the level where they are reliable enough to be used in production.', 'language': 'en', 'source': 'https://docs.smith.langchain.com/overview', 'title': 'LangSmith Overview and User Guide | ЁЯжЬя╕ПЁЯЫая╕П LangSmith'}),
  Document(page_content='LangSmith makes it easy to manually review and annotate runs through annotation queues.These queues allow you to select any runs based on criteria like model type or automatic evaluation scores, and queue them up for human review. As a reviewer, you can then quickly step through the runs, viewing the input, output, and any existing tags before adding your own feedback.We often use this for a couple of reasons:To assess subjective qualities that automatic evaluators struggle with, like', metadata={'description': 'Building reliable LLM applications can be challenging. LangChain simplifies the initial setup, but there is still work needed to bring the performance of prompts, chains and agents up the level where they are reliable enough to be used in production.', 'language': 'en', 'source': 'https://docs.smith.langchain.com/overview', 'title': 'LangSmith Overview and User Guide | ЁЯжЬя╕ПЁЯЫая╕П LangSmith'})],
 'answer': 'LangSmith simplifies the initial setup for building reliable LLM applications, but it acknowledges that there is still work needed to bring the performance of prompts, chains, and agents up to the level where they are reliable enough to be used in production. It also provides the capability to manually review and annotate runs through annotation queues, allowing you to select runs based on criteria like model type or automatic evaluation scores for human review. This feature is particularly useful for assessing subjective qualities that automatic evaluators struggle with.'}
```

рдЖрдк [рдЗрд╕ LangSmith рдЯреНрд░реЗрд╕](https://smith.langchain.com/public/bb329a3b-e92a-4063-ad78-43f720fbb5a2/r) рдХреА рдЬрд╛рдВрдЪ рдХрд░ рд╕рдХрддреЗ рд╣реИрдВ рддрд╛рдХрд┐ рдЖрдк рдЦреБрдж рджреЗрдЦ рд╕рдХреЗрдВ рдХрд┐ рдЖрдВрддрд░рд┐рдХ рдХреНрд╡реЗрд░реА рд░реВрдкрд╛рдВрддрд░рдг рдЪрд░рдг рдХреИрд╕рд╛ рджрд┐рдЦрддрд╛ рд╣реИред

## рд╕реНрдЯреНрд░реАрдорд┐рдВрдЧ

рдХреНрдпреЛрдВрдХрд┐ рдпрд╣ рд╢реНрд░реГрдВрдЦрд▓рд╛ LCEL рдХреЗ рд╕рд╛рде рдмрдирд╛рдИ рдЧрдИ рд╣реИ, рдЖрдк рдЗрд╕рдХреЗ рд╕рд╛рде рдкрд░рд┐рдЪрд┐рдд рддрд░реАрдХреЛрдВ рдЬреИрд╕реЗ `.stream()` рдХрд╛ рдЙрдкрдпреЛрдЧ рдХрд░ рд╕рдХрддреЗ рд╣реИрдВ:

```python
stream = conversational_retrieval_chain.stream(
    {
        "messages": [
            HumanMessage(content="Can LangSmith help test my LLM applications?"),
            AIMessage(
                content="Yes, LangSmith can help test and evaluate your LLM applications. It allows you to quickly edit examples and add them to datasets to expand the surface area of your evaluation sets or to fine-tune a model for improved quality or reduced costs. Additionally, LangSmith can be used to monitor your application, log all traces, visualize latency and token usage statistics, and troubleshoot specific issues as they arise."
            ),
            HumanMessage(content="Tell me more!"),
        ],
    }
)

for chunk in stream:
    print(chunk)
```

```output
{'messages': [HumanMessage(content='Can LangSmith help test my LLM applications?'), AIMessage(content='Yes, LangSmith can help test and evaluate your LLM applications. It allows you to quickly edit examples and add them to datasets to expand the surface area of your evaluation sets or to fine-tune a model for improved quality or reduced costs. Additionally, LangSmith can be used to monitor your application, log all traces, visualize latency and token usage statistics, and troubleshoot specific issues as they arise.'), HumanMessage(content='Tell me more!')]}
{'context': [Document(page_content='LangSmith Overview and User Guide | ЁЯжЬя╕ПЁЯЫая╕П LangSmith', metadata={'description': 'Building reliable LLM applications can be challenging. LangChain simplifies the initial setup, but there is still work needed to bring the performance of prompts, chains and agents up the level where they are reliable enough to be used in production.', 'language': 'en', 'source': 'https://docs.smith.langchain.com/overview', 'title': 'LangSmith Overview and User Guide | ЁЯжЬя╕ПЁЯЫая╕П LangSmith'}), Document(page_content='You can also quickly edit examples and add them to datasets to expand the surface area of your evaluation sets or to fine-tune a model for improved quality or reduced costs.Monitoring\u200bAfter all this, your app might finally ready to go in production. LangSmith can also be used to monitor your application in much the same way that you used for debugging. You can log all traces, visualize latency and token usage statistics, and troubleshoot specific issues as they arise. Each run can also be', metadata={'description': 'Building reliable LLM applications can be challenging. LangChain simplifies the initial setup, but there is still work needed to bring the performance of prompts, chains and agents up the level where they are reliable enough to be used in production.', 'language': 'en', 'source': 'https://docs.smith.langchain.com/overview', 'title': 'LangSmith Overview and User Guide | ЁЯжЬя╕ПЁЯЫая╕П LangSmith'}), Document(page_content='Skip to main contentЁЯжЬя╕ПЁЯЫая╕П LangSmith DocsPython DocsJS/TS DocsSearchGo to AppLangSmithOverviewTracingTesting & EvaluationOrganizationsHubLangSmith CookbookOverviewOn this pageLangSmith Overview and User GuideBuilding reliable LLM applications can be challenging. LangChain simplifies the initial setup, but there is still work needed to bring the performance of prompts, chains and agents up the level where they are reliable enough to be used in production.Over the past two months, we at LangChain', metadata={'description': 'Building reliable LLM applications can be challenging. LangChain simplifies the initial setup, but there is still work needed to bring the performance of prompts, chains and agents up the level where they are reliable enough to be used in production.', 'language': 'en', 'source': 'https://docs.smith.langchain.com/overview', 'title': 'LangSmith Overview and User Guide | ЁЯжЬя╕ПЁЯЫая╕П LangSmith'}), Document(page_content='LangSmith makes it easy to manually review and annotate runs through annotation queues.These queues allow you to select any runs based on criteria like model type or automatic evaluation scores, and queue them up for human review. As a reviewer, you can then quickly step through the runs, viewing the input, output, and any existing tags before adding your own feedback.We often use this for a couple of reasons:To assess subjective qualities that automatic evaluators struggle with, like', metadata={'description': 'Building reliable LLM applications can be challenging. LangChain simplifies the initial setup, but there is still work needed to bring the performance of prompts, chains and agents up the level where they are reliable enough to be used in production.', 'language': 'en', 'source': 'https://docs.smith.langchain.com/overview', 'title': 'LangSmith Overview and User Guide | ЁЯжЬя╕ПЁЯЫая╕П LangSmith'})]}
{'answer': ''}
{'answer': 'Lang'}
{'answer': 'Smith'}
{'answer': ' simpl'}
{'answer': 'ifies'}
{'answer': ' the'}
{'answer': ' initial'}
{'answer': ' setup'}
{'answer': ' for'}
{'answer': ' building'}
{'answer': ' reliable'}
{'answer': ' L'}
{'answer': 'LM'}
{'answer': ' applications'}
{'answer': '.'}
{'answer': ' It'}
{'answer': ' provides'}
{'answer': ' features'}
{'answer': ' for'}
{'answer': ' manually'}
{'answer': ' reviewing'}
{'answer': ' and'}
{'answer': ' annot'}
{'answer': 'ating'}
{'answer': ' runs'}
{'answer': ' through'}
{'answer': ' annotation'}
{'answer': ' queues'}
{'answer': ','}
{'answer': ' allowing'}
{'answer': ' you'}
{'answer': ' to'}
{'answer': ' select'}
{'answer': ' runs'}
{'answer': ' based'}
{'answer': ' on'}
{'answer': ' criteria'}
{'answer': ' like'}
{'answer': ' model'}
{'answer': ' type'}
{'answer': ' or'}
{'answer': ' automatic'}
{'answer': ' evaluation'}
{'answer': ' scores'}
{'answer': ','}
{'answer': ' and'}
{'answer': ' queue'}
{'answer': ' them'}
{'answer': ' up'}
{'answer': ' for'}
{'answer': ' human'}
{'answer': ' review'}
{'answer': '.'}
{'answer': ' As'}
{'answer': ' a'}
{'answer': ' reviewer'}
{'answer': ','}
{'answer': ' you'}
{'answer': ' can'}
{'answer': ' quickly'}
{'answer': ' step'}
{'answer': ' through'}
{'answer': ' the'}
{'answer': ' runs'}
{'answer': ','}
{'answer': ' view'}
{'answer': ' the'}
{'answer': ' input'}
{'answer': ','}
{'answer': ' output'}
{'answer': ','}
{'answer': ' and'}
{'answer': ' any'}
{'answer': ' existing'}
{'answer': ' tags'}
{'answer': ' before'}
{'answer': ' adding'}
{'answer': ' your'}
{'answer': ' own'}
{'answer': ' feedback'}
{'answer': '.'}
{'answer': ' This'}
{'answer': ' can'}
{'answer': ' be'}
{'answer': ' particularly'}
{'answer': ' useful'}
{'answer': ' for'}
{'answer': ' assessing'}
{'answer': ' subjective'}
{'answer': ' qualities'}
{'answer': ' that'}
{'answer': ' automatic'}
{'answer': ' evalu'}
{'answer': 'ators'}
{'answer': ' struggle'}
{'answer': ' with'}
{'answer': '.'}
{'answer': ''}
```

## рдФрд░ рдкрдврд╝рдиреЗ рдХреЗ рд▓рд┐рдП

рдпрд╣ рдЧрд╛рдЗрдб рдкреБрдирд░реНрдкреНрд░рд╛рдкреНрддрд┐ рддрдХрдиреАрдХреЛрдВ рдХрд╛ рдХреЗрд╡рд▓ рд╕рддрд╣реА рд╡рд┐рд╡рд░рдг рд╣реИред рд╡рд┐рднрд┐рдиреНрди рддрд░реАрдХреЛрдВ рдХреЗ рдмрд╛рд░реЗ рдореЗрдВ рдЕрдзрд┐рдХ рдЬрд╛рдирдХрд╛рд░реА рдХреЗ рд▓рд┐рдП рдЬреЛ рдбреЗрдЯрд╛ рдХреЛ рдЗрдВрдЧреЗрд╕реНрдЯ, рддреИрдпрд╛рд░ рдФрд░ рдкреБрдирд░реНрдкреНрд░рд╛рдкреНрдд рдХрд░рддреЗ рд╣реИрдВ, [рдЗрд╕ рдЦрдВрдб](/docs/modules/data_connection/) рдореЗрдВ рдкреНрд░рд▓реЗрдЦрди рджреЗрдЦреЗрдВред
