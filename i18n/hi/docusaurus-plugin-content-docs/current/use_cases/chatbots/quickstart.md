---
sidebar_position: 0
translated: true
---

# рддреНрд╡рд░рд┐рдд рд╢реБрд░реБрдЖрдд

[![](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/langchain-ai/langchain/blob/master/docs/docs/use_cases/chatbots.ipynb)

## рдЕрд╡рд▓реЛрдХрди

рд╣рдо рдПрдХ рдЙрджрд╛рд╣рд░рдг рдкрд░ рдЬрд╛рдПрдВрдЧреЗ рдХрд┐ рдХреИрд╕реЗ рдПрдХ рдПрд▓рдПрд▓рдПрдо-рд╕рдВрдЪрд╛рд▓рд┐рдд рдЪреИрдЯрдмреЙрдЯ рдХреЛ рдбрд┐рдЬрд╝рд╛рдЗрди рдФрд░ рдХрд╛рд░реНрдпрд╛рдиреНрд╡рд┐рдд рдХрд┐рдпрд╛ рдЬрд╛рдПред рдпрд╣рд╛рдБ рдХреБрдЫ рдЙрдЪреНрдЪ-рд╕реНрддрд░реАрдп рдШрдЯрдХ рд╣реИрдВ рдЬрд┐рдирдХреЗ рд╕рд╛рде рд╣рдо рдХрд╛рдо рдХрд░реЗрдВрдЧреЗ:

- `Chat Models`ред рдЪреИрдЯрдмреЙрдЯ рдЗрдВрдЯрд░рдлрд╝реЗрд╕ рд╕рдВрджреЗрд╢реЛрдВ рдХреЗ рдЗрд░реНрдж-рдЧрд┐рд░реНрдж рдЖрдзрд╛рд░рд┐рдд рд╣реИ рди рдХрд┐ рдХрдЪреНрдЪреЗ рдЯреЗрдХреНрд╕реНрдЯ рдкрд░, рдФрд░ рдЗрд╕рд▓рд┐рдП рдпрд╣ рдЯреЗрдХреНрд╕реНрдЯ рдПрд▓рдПрд▓рдПрдо рдХреА рдмрдЬрд╛рдп рдЪреИрдЯ рдореЙрдбрд▓реЛрдВ рдХреЗ рд▓рд┐рдП рд╕рдмрд╕реЗ рдЙрдкрдпреБрдХреНрдд рд╣реИред рдЪреИрдЯ рдореЙрдбрд▓ рдЗрдВрдЯреАрдЧреНрд░реЗрд╢рди рдХреА рд╕реВрдЪреА рдХреЗ рд▓рд┐рдП [рдпрд╣рд╛рдБ рджреЗрдЦреЗрдВ](/docs/integrations/chat) рдФрд░ рд▓реИрдВрдЧрдЪреЗрди рдореЗрдВ рдЪреИрдЯ рдореЙрдбрд▓ рдЗрдВрдЯрд░рдлреЗрд╕ рдкрд░ рджрд╕реНрддрд╛рд╡реЗрдЬрд╝ рдХреЗ рд▓рд┐рдП [рдпрд╣рд╛рдБ рджреЗрдЦреЗрдВ](/docs/modules/model_io/chat)ред рдЖрдк рдЪреИрдЯрдмреЙрдЯ рдХреЗ рд▓рд┐рдП `LLMs` (рджреЗрдЦреЗрдВ [рдпрд╣рд╛рдБ](/docs/modules/model_io/llms)) рдХрд╛ рднреА рдЙрдкрдпреЛрдЧ рдХрд░ рд╕рдХрддреЗ рд╣реИрдВ, рд▓реЗрдХрд┐рди рдЪреИрдЯ рдореЙрдбрд▓ рдореЗрдВ рдПрдХ рдЕрдзрд┐рдХ рд╕рдВрд╡рд╛рджрд╛рддреНрдордХ рд╕реНрд╡рд░ рд╣реЛрддрд╛ рд╣реИ рдФрд░ рд╡реЗ рд╕реНрд╡рд╛рднрд╛рд╡рд┐рдХ рд░реВрдк рд╕реЗ рдПрдХ рд╕рдВрджреЗрд╢ рдЗрдВрдЯрд░рдлрд╝реЗрд╕ рдХрд╛ рд╕рдорд░реНрдерди рдХрд░рддреЗ рд╣реИрдВред
- `Prompt Templates`, рдЬреЛ рдбрд┐рдлрд╝реЙрд▓реНрдЯ рд╕рдВрджреЗрд╢реЛрдВ, рдЙрдкрдпреЛрдЧрдХрд░реНрддрд╛ рдЗрдирдкреБрдЯ, рдЪреИрдЯ рдЗрддрд┐рд╣рд╛рд╕ рдФрд░ (рд╡реИрдХрд▓реНрдкрд┐рдХ рд░реВрдк рд╕реЗ) рдЕрддрд┐рд░рд┐рдХреНрдд рдкреБрдирдГ рдкреНрд░рд╛рдкреНрдд рд╕рдВрджрд░реНрднреЛрдВ рдХреЛ рд╕рдВрдпреЛрдЬрд┐рдд рдХрд░рдиреЗ рд╡рд╛рд▓реЗ рд╕рдВрдХреЗрддреЛрдВ рдХреЛ рдПрдХрддреНрд░ рдХрд░рдиреЗ рдХреА рдкреНрд░рдХреНрд░рд┐рдпрд╛ рдХреЛ рд╕рд░рд▓ рдмрдирд╛рддреЗ рд╣реИрдВред
- `Chat History`, рдЬреЛ рдПрдХ рдЪреИрдЯрдмреЙрдЯ рдХреЛ рдкрд┐рдЫрд▓реЗ рдЗрдВрдЯрд░реИрдХреНрд╢рди рдХреЛ "рдпрд╛рдж" рдХрд░рдиреЗ рдФрд░ рдЕрдиреБрд╡рд░реНрддреА рдкреНрд░рд╢реНрдиреЛрдВ рдХрд╛ рдЙрддреНрддрд░ рджреЗрддреЗ рд╕рдордп рдЙрдиреНрд╣реЗрдВ рдзреНрдпрд╛рди рдореЗрдВ рд░рдЦрдиреЗ рдХреА рдЕрдиреБрдорддрд┐ рджреЗрддрд╛ рд╣реИред рдЕрдзрд┐рдХ рдЬрд╛рдирдХрд╛рд░реА рдХреЗ рд▓рд┐рдП [рдпрд╣рд╛рдБ рджреЗрдЦреЗрдВ](/docs/modules/memory/chat_messages/)ред
- `Retrievers` (рд╡реИрдХрд▓реНрдкрд┐рдХ), рдЬреЛ рдЙрдкрдпреЛрдЧреА рд╣реЛрддреЗ рд╣реИрдВ рдпрджрд┐ рдЖрдк рдПрдХ рдРрд╕рд╛ рдЪреИрдЯрдмреЙрдЯ рдмрдирд╛рдирд╛ рдЪрд╛рд╣рддреЗ рд╣реИрдВ рдЬреЛ рдбреЛрдореЗрди-рд╡рд┐рд╢рд┐рд╖реНрдЯ, рдЕрджреНрдпрддрди рдЬреНрдЮрд╛рди рдХрд╛ рдЙрдкрдпреЛрдЧ рдХрд░рдХреЗ рдЕрдкрдиреА рдкреНрд░рддрд┐рдХреНрд░рд┐рдпрд╛рдУрдВ рдХреЛ рдмрдврд╝рд╛ рд╕рдХреЗред рдкреБрдирд░реНрдкреНрд░рд╛рдкреНрддрд┐ рдкреНрд░рдгрд╛рд▓рд┐рдпреЛрдВ рдкрд░ рдЧрд╣рди рджрд╕реНрддрд╛рд╡реЗрдЬрд╝ рдХреЗ рд▓рд┐рдП [рдпрд╣рд╛рдБ рджреЗрдЦреЗрдВ](/docs/modules/data_connection/retrievers)ред

рд╣рдо рдПрдХ рд╢рдХреНрддрд┐рд╢рд╛рд▓реА рд╕рдВрд╡рд╛рджрд╛рддреНрдордХ рдЪреИрдЯрдмреЙрдЯ рдмрдирд╛рдиреЗ рдХреЗ рд▓рд┐рдП рдЙрдкрд░реЛрдХреНрдд рдШрдЯрдХреЛрдВ рдХреЛ рдПрдХ рд╕рд╛рде рдХреИрд╕реЗ рдлрд┐рдЯ рдХрд░реЗрдВ, рдЗрд╕ рдкрд░ рдЪрд░реНрдЪрд╛ рдХрд░реЗрдВрдЧреЗред

## рддреНрд╡рд░рд┐рдд рд╢реБрд░реБрдЖрдд

рд╢реБрд░реВ рдХрд░рдиреЗ рдХреЗ рд▓рд┐рдП, рдЪрд▓рд┐рдП рдХреБрдЫ рдирд┐рд░реНрднрд░рддрд╛рдПрдБ рд╕реНрдерд╛рдкрд┐рдд рдХрд░рддреЗ рд╣реИрдВ рдФрд░ рдЖрд╡рд╢реНрдпрдХ рдХреНрд░реЗрдбреЗрдВрд╢рд┐рдпрд▓реНрд╕ рд╕реЗрдЯ рдХрд░рддреЗ рд╣реИрдВ:

```python
%pip install --upgrade --quiet langchain langchain-openai langchain-chroma

# Set env var OPENAI_API_KEY or load from a .env file:
import dotenv

dotenv.load_dotenv()
```

```output
[33mWARNING: You are using pip version 22.0.4; however, version 23.3.2 is available.
You should consider upgrading via the '/Users/jacoblee/.pyenv/versions/3.10.5/bin/python -m pip install --upgrade pip' command.[0m[33m
[0mNote: you may need to restart the kernel to use updated packages.
```

```output
True
```

рдЖрдЗрдП рдЪреИрдЯ рдореЙрдбрд▓ рдХреЛ рдЗрдирд┐рд╢рд┐рдпрд▓рд╛рдЗрдЬрд╝ рдХрд░реЗрдВ рдЬреЛ рдЪреИрдЯрдмреЙрдЯ рдХреЗ рдорд╕реНрддрд┐рд╖реНрдХ рдХреЗ рд░реВрдк рдореЗрдВ рдХрд╛рд░реНрдп рдХрд░реЗрдЧрд╛:

```python
from langchain_openai import ChatOpenAI

chat = ChatOpenAI(model="gpt-3.5-turbo-1106", temperature=0.2)
```

рдпрджрд┐ рд╣рдо рдЕрдкрдиреЗ рдЪреИрдЯ рдореЙрдбрд▓ рдХреЛ рдмреБрд▓рд╛рддреЗ рд╣реИрдВ, рддреЛ рдЖрдЙрдЯрдкреБрдЯ рдПрдХ `AIMessage` рд╣реЛрддрд╛ рд╣реИ:

```python
from langchain_core.messages import HumanMessage

chat.invoke(
    [
        HumanMessage(
            content="Translate this sentence from English to French: I love programming."
        )
    ]
)
```

```output
AIMessage(content="J'adore programmer.")
```

рдореЙрдбрд▓ рдЕрдкрдиреЗ рдЖрдк рдореЗрдВ рдХрд┐рд╕реА рднреА рд░рд╛рдЬреНрдп рдХреА рдЕрд╡рдзрд╛рд░рдгрд╛ рдирд╣реАрдВ рд░рдЦрддрд╛ рд╣реИред рдЙрджрд╛рд╣рд░рдг рдХреЗ рд▓рд┐рдП, рдпрджрд┐ рдЖрдк рдЕрдиреБрд╡рд░реНрддреА рдкреНрд░рд╢реНрди рдкреВрдЫрддреЗ рд╣реИрдВ:

```python
chat.invoke([HumanMessage(content="What did you just say?")])
```

```output
AIMessage(content='I said, "What did you just say?"')
```

рд╣рдо рджреЗрдЦ рд╕рдХрддреЗ рд╣реИрдВ рдХрд┐ рдпрд╣ рдкрд┐рдЫрд▓реЗ рд╡рд╛рд░реНрддрд╛рд▓рд╛рдк рдХреЛ рд╕рдВрджрд░реНрдн рдореЗрдВ рдирд╣реАрдВ рд▓реЗрддрд╛ рд╣реИ, рдФрд░ рдкреНрд░рд╢реНрди рдХрд╛ рдЙрддреНрддрд░ рдирд╣реАрдВ рджреЗ рд╕рдХрддрд╛ред

рдЗрд╕рд╕реЗ рдмрдЪрдиреЗ рдХреЗ рд▓рд┐рдП, рд╣рдореЗрдВ рдкреВрд░реА рдмрд╛рддрдЪреАрдд рдХрд╛ рдЗрддрд┐рд╣рд╛рд╕ рдореЙрдбрд▓ рдореЗрдВ рдкрд╛рд╕ рдХрд░рдиреЗ рдХреА рдЖрд╡рд╢реНрдпрдХрддрд╛ рд╣реИред рджреЗрдЦреЗрдВ рдХрд┐ рдЬрдм рд╣рдо рдРрд╕рд╛ рдХрд░рддреЗ рд╣реИрдВ рддреЛ рдХреНрдпрд╛ рд╣реЛрддрд╛ рд╣реИ:

```python
from langchain_core.messages import AIMessage

chat.invoke(
    [
        HumanMessage(
            content="Translate this sentence from English to French: I love programming."
        ),
        AIMessage(content="J'adore la programmation."),
        HumanMessage(content="What did you just say?"),
    ]
)
```

```output
AIMessage(content='I said "J\'adore la programmation," which means "I love programming" in French.')
```

рдФрд░ рдЕрдм рд╣рдо рджреЗрдЦ рд╕рдХрддреЗ рд╣реИрдВ рдХрд┐ рд╣рдореЗрдВ рдПрдХ рдЕрдЪреНрдЫрд╛ рдЙрддреНрддрд░ рдорд┐рд▓рд╛ рд╣реИ!

рдпрд╣ рдПрдХ рдЪреИрдЯрдмреЙрдЯ рдХреА рд╕рдВрд╡рд╛рджрд╛рддреНрдордХ рддрд░реАрдХреЗ рд╕реЗ рдмрд╛рддрдЪреАрдд рдХрд░рдиреЗ рдХреА рдХреНрд╖рдорддрд╛ рдХреА рдмреБрдирд┐рдпрд╛рджреА рдЕрд╡рдзрд╛рд░рдгрд╛ рд╣реИред

## рд╕рдВрдХреЗрдд рдЯреЗрдореНрдкрд▓реЗрдЯреНрд╕

рдлреЙрд░реНрдореЗрдЯрд┐рдВрдЧ рдХреЛ рдереЛрдбрд╝рд╛ рдЖрд╕рд╛рди рдмрдирд╛рдиреЗ рдХреЗ рд▓рд┐рдП рдЖрдЗрдП рдПрдХ рд╕рдВрдХреЗрдд рдЯреЗрдореНрдкрд▓реЗрдЯ рдХреЛ рдкрд░рд┐рднрд╛рд╖рд┐рдд рдХрд░реЗрдВред рд╣рдо рдЗрд╕реЗ рдореЙрдбрд▓ рдореЗрдВ рдкрд╛рдЗрдк рдХрд░рдХреЗ рдПрдХ рд╢реНрд░реГрдВрдЦрд▓рд╛ рдмрдирд╛ рд╕рдХрддреЗ рд╣реИрдВ:

```python
from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder

prompt = ChatPromptTemplate.from_messages(
    [
        (
            "system",
            "You are a helpful assistant. Answer all questions to the best of your ability.",
        ),
        MessagesPlaceholder(variable_name="messages"),
    ]
)

chain = prompt | chat
```

рдЙрдкрд░реЛрдХреНрдд `MessagesPlaceholder` рдЪреИрдЯ рд╕рдВрджреЗрд╢реЛрдВ рдХреЛ рд╢реНрд░реГрдВрдЦрд▓рд╛ рдХреЗ рдЗрдирдкреБрдЯ рдХреЗ рд░реВрдк рдореЗрдВ `chat_history` рдХреЗ рд░реВрдк рдореЗрдВ рд╕реАрдзреЗ рд╕рдВрдХреЗрдд рдореЗрдВ рд╕рдореНрдорд┐рд▓рд┐рдд рдХрд░рддрд╛ рд╣реИред рдлрд┐рд░, рд╣рдо рд╢реНрд░реГрдВрдЦрд▓рд╛ рдХреЛ рдЗрд╕ рддрд░рд╣ рдмреБрд▓рд╛ рд╕рдХрддреЗ рд╣реИрдВ:

```python
chain.invoke(
    {
        "messages": [
            HumanMessage(
                content="Translate this sentence from English to French: I love programming."
            ),
            AIMessage(content="J'adore la programmation."),
            HumanMessage(content="What did you just say?"),
        ],
    }
)
```

```output
AIMessage(content='I said "J\'adore la programmation," which means "I love programming" in French.')
```

## рд╕рдВрджреЗрд╢ рдЗрддрд┐рд╣рд╛рд╕

рдЪреИрдЯ рдЗрддрд┐рд╣рд╛рд╕ рдХреЛ рдкреНрд░рдмрдВрдзрд┐рдд рдХрд░рдиреЗ рдХреЗ рд▓рд┐рдП рдПрдХ рд╢реЙрд░реНрдЯрдХрдЯ рдХреЗ рд░реВрдк рдореЗрдВ, рд╣рдо рдПрдХ [`MessageHistory`](/docs/modules/memory/chat_messages/) рдХреНрд▓рд╛рд╕ рдХрд╛ рдЙрдкрдпреЛрдЧ рдХрд░ рд╕рдХрддреЗ рд╣реИрдВ, рдЬреЛ рдЪреИрдЯ рд╕рдВрджреЗрд╢реЛрдВ рдХреЛ рд╕рд╣реЗрдЬрдиреЗ рдФрд░ рд▓реЛрдб рдХрд░рдиреЗ рдХреЗ рд▓рд┐рдП рдЬрд┐рдореНрдореЗрджрд╛рд░ рд╣реИред рдХрдИ рдЕрдВрддрд░реНрдирд┐рд░реНрдорд┐рдд рд╕рдВрджреЗрд╢ рдЗрддрд┐рд╣рд╛рд╕ рдЗрдВрдЯреАрдЧреНрд░реЗрд╢рди рд╣реИрдВ рдЬреЛ рд╕рдВрджреЗрд╢реЛрдВ рдХреЛ рд╡рд┐рднрд┐рдиреНрди рдбреЗрдЯрд╛рдмреЗрд╕ рдореЗрдВ рд╕рд╣реЗрдЬрддреЗ рд╣реИрдВ, рд▓реЗрдХрд┐рди рдЗрд╕ рддреНрд╡рд░рд┐рдд рд╢реБрд░реБрдЖрдд рдХреЗ рд▓рд┐рдП рд╣рдо рдПрдХ рдЗрди-рдореЗрдореЛрд░реА, рдбреЗрдореЛ рд╕рдВрджреЗрд╢ рдЗрддрд┐рд╣рд╛рд╕ рдХрд╛ рдЙрдкрдпреЛрдЧ рдХрд░реЗрдВрдЧреЗ рдЬрд┐рд╕реЗ `ChatMessageHistory` рдХрд╣рд╛ рдЬрд╛рддрд╛ рд╣реИред

рдЗрд╕реЗ рд╕реАрдзреЗ рдЙрдкрдпреЛрдЧ рдХрд░рдиреЗ рдХрд╛ рдПрдХ рдЙрджрд╛рд╣рд░рдг рдпрд╣рд╛рдБ рд╣реИ:

```python
from langchain.memory import ChatMessageHistory

demo_ephemeral_chat_history = ChatMessageHistory()

demo_ephemeral_chat_history.add_user_message("hi!")

demo_ephemeral_chat_history.add_ai_message("whats up?")

demo_ephemeral_chat_history.messages
```

```output
[HumanMessage(content='hi!'), AIMessage(content='whats up?')]
```

рдПрдХ рдмрд╛рд░ рдЬрдм рд╣рдо рдРрд╕рд╛ рдХрд░ рд▓реЗрддреЗ рд╣реИрдВ, рддреЛ рд╣рдо рд╕рдВрдЧреНрд░рд╣реАрдд рд╕рдВрджреЗрд╢реЛрдВ рдХреЛ рд╕реАрдзреЗ рд╣рдорд╛рд░реЗ рд╢реНрд░реГрдВрдЦрд▓рд╛ рдореЗрдВ рдПрдХ рдкреИрд░рд╛рдореАрдЯрд░ рдХреЗ рд░реВрдк рдореЗрдВ рдкрд╛рд╕ рдХрд░ рд╕рдХрддреЗ рд╣реИрдВ:

```python
demo_ephemeral_chat_history.add_user_message(
    "Translate this sentence from English to French: I love programming."
)

response = chain.invoke({"messages": demo_ephemeral_chat_history.messages})

response
```

```output
AIMessage(content='The translation of "I love programming" in French is "J\'adore la programmation."')
```

```python
demo_ephemeral_chat_history.add_ai_message(response)

demo_ephemeral_chat_history.add_user_message("What did you just say?")

chain.invoke({"messages": demo_ephemeral_chat_history.messages})
```

```output
AIMessage(content='I said "J\'adore la programmation," which is the French translation for "I love programming."')
```

рдФрд░ рдЕрдм рд╣рдорд╛рд░реЗ рдкрд╛рд╕ рдПрдХ рдмреБрдирд┐рдпрд╛рджреА рдЪреИрдЯрдмреЙрдЯ рд╣реИ!

рдЬрдмрдХрд┐ рдпрд╣ рд╢реНрд░реГрдВрдЦрд▓рд╛ рдореЙрдбрд▓ рдХреЗ рдЖрдВрддрд░рд┐рдХ рдЬреНрдЮрд╛рди рдХреЗ рд╕рд╛рде рдЕрдкрдиреЗ рдЖрдк рдореЗрдВ рдПрдХ рдЙрдкрдпреЛрдЧреА рдЪреИрдЯрдмреЙрдЯ рдХреЗ рд░реВрдк рдореЗрдВ рдХрд╛рд░реНрдп рдХрд░ рд╕рдХрддреА рд╣реИ, рдпрд╣ рдЕрдХреНрд╕рд░ рд╣рдорд╛рд░реЗ рдЪреИрдЯрдмреЙрдЯ рдХреЛ рдЕрдзрд┐рдХ рдХреЗрдВрджреНрд░рд┐рдд рдмрдирд╛рдиреЗ рдХреЗ рд▓рд┐рдП рдбреЛрдореЗрди-рд╡рд┐рд╢рд┐рд╖реНрдЯ рдЬреНрдЮрд╛рди рдкрд░ `retrieval-augmented generation`, рдпрд╛ рд╕рдВрдХреНрд╖реЗрдк рдореЗрдВ RAG, рдХрд╛ рдХреБрдЫ рд░реВрдк рдкреЗрд╢ рдХрд░рдирд╛ рдЙрдкрдпреЛрдЧреА рд╣реЛрддрд╛ рд╣реИред рд╣рдо рдЗрд╕реЗ рдЕрдЧрд▓реЗ рдХрд╡рд░ рдХрд░реЗрдВрдЧреЗред

## рдкреБрдирд░реНрдкреНрд░рд╛рдкреНрддрд┐

рд╣рдо рдЕрдкрдиреЗ рдЪреИрдЯрдмреЙрдЯ рдХреЗ рд▓рд┐рдП рдбреЛрдореЗрди-рд╡рд┐рд╢рд┐рд╖реНрдЯ рдЬреНрдЮрд╛рди рдкреНрд░рд╛рдкреНрдд рдХрд░рдиреЗ рдХреЗ рд▓рд┐рдП рдПрдХ [`Retriever`](/docs/modules/data_connection/retrievers/) рд╕реЗрдЯ рдЕрдк рдФрд░ рдЙрдкрдпреЛрдЧ рдХрд░ рд╕рдХрддреЗ рд╣реИрдВред рдЗрд╕реЗ рджрд┐рдЦрд╛рдиреЗ рдХреЗ рд▓рд┐рдП, рдЪрд▓рд┐рдП рдКрдкрд░ рдмрдирд╛рдП рдЧрдП рд╕рд╛рдзрд╛рд░рдг рдЪреИрдЯрдмреЙрдЯ рдХрд╛ рд╡рд┐рд╕реНрддрд╛рд░ рдХрд░рддреЗ рд╣реИрдВ рддрд╛рдХрд┐ рдпрд╣ рд▓реИрдВрдЧрд╕реНрдорд┐рде рдХреЗ рдмрд╛рд░реЗ рдореЗрдВ рдкреНрд░рд╢реНрдиреЛрдВ рдХрд╛ рдЙрддреНрддрд░ рджреЗ рд╕рдХреЗред

рд╣рдо [рд▓реИрдВрдЧрд╕реНрдорд┐рде рджрд╕реНрддрд╛рд╡реЗрдЬрд╝реАрдХрд░рдг](https://docs.smith.langchain.com/overview) рдХреЛ рд╕реНрд░реЛрдд рд╕рд╛рдордЧреНрд░реА рдХреЗ рд░реВрдк рдореЗрдВ рдЙрдкрдпреЛрдЧ рдХрд░реЗрдВрдЧреЗ рдФрд░ рдЗрд╕реЗ рдмрд╛рдж рдореЗрдВ рдкреБрдирд░реНрдкреНрд░рд╛рдкреНрддрд┐ рдХреЗ рд▓рд┐рдП рдПрдХ рд╡реЗрдХреНрдЯрд░рд╕реНрдЯреЛрд░ рдореЗрдВ рд╕рдВрдЧреНрд░рд╣реАрдд рдХрд░реЗрдВрдЧреЗред рдзреНрдпрд╛рди рджреЗрдВ рдХрд┐ рдпрд╣ рдЙрджрд╛рд╣рд░рдг рдбреЗрдЯрд╛ рд╕реНрд░реЛрдд рдХреЛ рдкрд╛рд░реНрд╕рд┐рдВрдЧ рдФрд░ рд╕реНрдЯреЛрд░рд┐рдВрдЧ рдХреЗ рдЖрд╕рдкрд╛рд╕ рдХреЗ рдХреБрдЫ рд╡рд┐рд╢реЗрд╖рддрд╛рдУрдВ рдХреЛ рдЫреЛрдбрд╝ рджреЗрдЧрд╛ - рдЖрдк [рдкреБрдирд░реНрдкреНрд░рд╛рдкреНрддрд┐ рдкреНрд░рдгрд╛рд▓рд┐рдпреЛрдВ рдХреЛ рдмрдирд╛рдиреЗ рдкрд░ рдЧрд╣рди рджрд╕реНрддрд╛рд╡реЗрдЬрд╝ рдпрд╣рд╛рдБ рджреЗрдЦ рд╕рдХрддреЗ рд╣реИрдВ](/docs/use_cases/question_answering/)ред

рдЪрд▓рд┐рдП рдЕрдкрдиреЗ рдкреБрдирд░реНрдкреНрд░рд╛рдкреНрддрд┐ рдХреЛ рд╕реЗрдЯ рдХрд░рддреЗ рд╣реИрдВред рдкрд╣рд▓реЗ, рдХреБрдЫ рдЖрд╡рд╢реНрдпрдХ рдирд┐рд░реНрднрд░рддрд╛рдПрдБ рд╕реНрдерд╛рдкрд┐рдд рдХрд░реЗрдВ:

```python
%pip install --upgrade --quiet langchain-chroma beautifulsoup4
```

```output
[33mWARNING: You are using pip version 22.0.4; however, version 23.3.2 is available.
You should consider upgrading via the '/Users/jacoblee/.pyenv/versions/3.10.5/bin/python -m pip install --upgrade pip' command.[0m[33m
[0mNote: you may need to restart the kernel to use updated packages.
```

рдЕрдЧрд▓рд╛, рд╣рдо рдПрдХ рджрд╕реНрддрд╛рд╡реЗрдЬрд╝ рд▓реЛрдбрд░ рдХрд╛ рдЙрдкрдпреЛрдЧ рдХрд░рдХреЗ рд╡реЗрдмрдкреЗрдЬ рд╕реЗ рдбреЗрдЯрд╛ рдЦреАрдВрдЪреЗрдВрдЧреЗ:

```python
from langchain_community.document_loaders import WebBaseLoader

loader = WebBaseLoader("https://docs.smith.langchain.com/overview")
data = loader.load()
```

рдЕрдЧрд▓рд╛, рд╣рдо рдЗрд╕реЗ рдЫреЛрдЯреЗ рдЯреБрдХрдбрд╝реЛрдВ рдореЗрдВ рд╡рд┐рднрд╛рдЬрд┐рдд рдХрд░реЗрдВрдЧреЗ рдЬрд┐рдиреНрд╣реЗрдВ LLM рдХрд╛ рд╕рдВрджрд░реНрдн рд╡рд┐рдВрдбреЛ рд╕рдВрднрд╛рд▓ рд╕рдХрддрд╛ рд╣реИ рдФрд░ рдЗрд╕реЗ рдПрдХ рд╡реЗрдХреНрдЯрд░ рдбреЗрдЯрд╛рдмреЗрд╕ рдореЗрдВ рд╕рдВрдЧреНрд░рд╣реАрдд рдХрд░реЗрдВрдЧреЗ:

```python
from langchain_text_splitters import RecursiveCharacterTextSplitter

text_splitter = RecursiveCharacterTextSplitter(chunk_size=500, chunk_overlap=0)
all_splits = text_splitter.split_documents(data)
```

рдлрд┐рд░ рд╣рдо рдЙрди рдЯреБрдХрдбрд╝реЛрдВ рдХреЛ рдПрдореНрдмреЗрдб рдФрд░ рдПрдХ рд╡реЗрдХреНрдЯрд░ рдбреЗрдЯрд╛рдмреЗрд╕ рдореЗрдВ рд╕рдВрдЧреНрд░рд╣реАрдд рдХрд░реЗрдВрдЧреЗ:

```python
from langchain_chroma import Chroma
from langchain_openai import OpenAIEmbeddings

vectorstore = Chroma.from_documents(documents=all_splits, embedding=OpenAIEmbeddings())
```

рдФрд░ рдЕрдВрдд рдореЗрдВ, рдЪрд▓рд┐рдП рд╣рдорд╛рд░реЗ рдЗрдирд┐рд╢рд┐рдпрд▓рд╛рдЗрдЬрд╝реНрдб рд╡реЗрдХреНрдЯрд░рд╕реНрдЯреЛрд░ рд╕реЗ рдПрдХ рдкреБрдирд░реНрдкреНрд░рд╛рдкреНрддрд┐ рдмрдирд╛рдПрдБ:

```python
# k is the number of chunks to retrieve
retriever = vectorstore.as_retriever(k=4)

docs = retriever.invoke("how can langsmith help with testing?")

docs
```

```output
[Document(page_content='You can also quickly edit examples and add them to datasets to expand the surface area of your evaluation sets or to fine-tune a model for improved quality or reduced costs.Monitoring\u200bAfter all this, your app might finally ready to go in production. LangSmith can also be used to monitor your application in much the same way that you used for debugging. You can log all traces, visualize latency and token usage statistics, and troubleshoot specific issues as they arise. Each run can also be', metadata={'description': 'Building reliable LLM applications can be challenging. LangChain simplifies the initial setup, but there is still work needed to bring the performance of prompts, chains and agents up the level where they are reliable enough to be used in production.', 'language': 'en', 'source': 'https://docs.smith.langchain.com/overview', 'title': 'LangSmith Overview and User Guide | ЁЯжЬя╕ПЁЯЫая╕П LangSmith'}),
 Document(page_content='inputs, and see what happens. At some point though, our application is performing\nwell and we want to be more rigorous about testing changes. We can use a dataset\nthat weтАЩve constructed along the way (see above). Alternatively, we could spend some\ntime constructing a small dataset by hand. For these situations, LangSmith simplifies', metadata={'description': 'Building reliable LLM applications can be challenging. LangChain simplifies the initial setup, but there is still work needed to bring the performance of prompts, chains and agents up the level where they are reliable enough to be used in production.', 'language': 'en', 'source': 'https://docs.smith.langchain.com/overview', 'title': 'LangSmith Overview and User Guide | ЁЯжЬя╕ПЁЯЫая╕П LangSmith'}),
 Document(page_content='Skip to main contentЁЯжЬя╕ПЁЯЫая╕П LangSmith DocsPython DocsJS/TS DocsSearchGo to AppLangSmithOverviewTracingTesting & EvaluationOrganizationsHubLangSmith CookbookOverviewOn this pageLangSmith Overview and User GuideBuilding reliable LLM applications can be challenging. LangChain simplifies the initial setup, but there is still work needed to bring the performance of prompts, chains and agents up the level where they are reliable enough to be used in production.Over the past two months, we at LangChain', metadata={'description': 'Building reliable LLM applications can be challenging. LangChain simplifies the initial setup, but there is still work needed to bring the performance of prompts, chains and agents up the level where they are reliable enough to be used in production.', 'language': 'en', 'source': 'https://docs.smith.langchain.com/overview', 'title': 'LangSmith Overview and User Guide | ЁЯжЬя╕ПЁЯЫая╕П LangSmith'}),
 Document(page_content='have been building and using LangSmith with the goal of bridging this gap. This is our tactical user guide to outline effective ways to use LangSmith and maximize its benefits.On by default\u200bAt LangChain, all of us have LangSmithтАЩs tracing running in the background by default. On the Python side, this is achieved by setting environment variables, which we establish whenever we launch a virtual environment or open our bash shell and leave them set. The same principle applies to most JavaScript', metadata={'description': 'Building reliable LLM applications can be challenging. LangChain simplifies the initial setup, but there is still work needed to bring the performance of prompts, chains and agents up the level where they are reliable enough to be used in production.', 'language': 'en', 'source': 'https://docs.smith.langchain.com/overview', 'title': 'LangSmith Overview and User Guide | ЁЯжЬя╕ПЁЯЫая╕П LangSmith'})]
```

рд╣рдо рджреЗрдЦ рд╕рдХрддреЗ рд╣реИрдВ рдХрд┐ рдКрдкрд░ рджрд┐рдпрд╛ рдЧрдпрд╛ рдкреБрдирд░реНрдкреНрд░рд╛рдкреНрддрд┐ рд▓реИрдВрдЧрд╕реНрдорд┐рде рджрд╕реНрддрд╛рд╡реЗрдЬрд╝ рдХреЗ рдХреБрдЫ рд╣рд┐рд╕реНрд╕реЛрдВ рдХреЛ рд▓реМрдЯрд╛ рд░рд╣рд╛ рд╣реИ рдЬрд┐рд╕рдореЗрдВ рд╣рдорд╛рд░реЗ рдЪреИрдЯрдмреЙрдЯ рдХреЗ рдкреНрд░рд╢реНрдиреЛрдВ рдХрд╛ рдЙрддреНрддрд░ рджреЗрдиреЗ рдХреЗ рд▓рд┐рдП рдкрд░реАрдХреНрд╖рдг рдХреЗ рдмрд╛рд░реЗ рдореЗрдВ рдЬрд╛рдирдХрд╛рд░реА рд╣реИред

### рджрд╕реНрддрд╛рд╡реЗрдЬрд╝реЛрдВ рдХреЛ рд╕рдВрднрд╛рд▓рдирд╛

рдЪрд▓реЛ рдЕрдкрдиреЗ рдкрд┐рдЫрд▓реЗ рд╕рдВрдХреЗрдд рдХреЛ рджрд╕реНрддрд╛рд╡реЗрдЬрд╝реЛрдВ рдХреЛ рд╕рдВрджрд░реНрдн рдХреЗ рд░реВрдк рдореЗрдВ рд╕реНрд╡реАрдХрд╛рд░ рдХрд░рдиреЗ рдХреЗ рд▓рд┐рдП рд╕рдВрд╢реЛрдзрд┐рдд рдХрд░рддреЗ рд╣реИрдВред рд╣рдо рдПрдХ [`create_stuff_documents_chain`](https://api.python.langchain.com/en/latest/chains/langchain.chains.combine_documents.stuff.create_stuff_documents_chain.html#langchain.chains.combine_documents.stuff.create_stuff_documents_chain) рд╣реЗрд▓реНрдкрд░ рдлрд╝рдВрдХреНрд╢рди рдХрд╛ рдЙрдкрдпреЛрдЧ рдХрд░реЗрдВрдЧреЗ рдЬреЛ рд╕рднреА рдЗрдирдкреБрдЯ рджрд╕реНрддрд╛рд╡реЗрдЬрд╝реЛрдВ рдХреЛ рд╕рдВрдХреЗрдд рдореЗрдВ "рднрд░" рджреЗрдЧрд╛, рдЬреЛ рдХрд┐ рдлреЙрд░реНрдореЗрдЯрд┐рдВрдЧ рдХреЛ рд╕рдВрднрд╛рд▓рдиреЗ рдХреЗ рд▓рд┐рдП рднреА рд╕реБрд╡рд┐рдзрд╛рдЬрдирдХ рд╣реИред рд╣рдо [`ChatPromptTemplate.from_messages`](/docs/modules/model_io/prompts/quick_start#chatprompttemplate) рд╡рд┐рдзрд┐ рдХрд╛ рдЙрдкрдпреЛрдЧ рдХрд░реЗрдВрдЧреЗ рддрд╛рдХрд┐ рд╣рдо рдореЙрдбрд▓ рдХреЛ рдкрд╛рд╕ рдХрд░рдиреЗ рдХреЗ рд▓рд┐рдП рд╕рдВрджреЗрд╢ рдЗрдирдкреБрдЯ рдХреЛ рдлреЙрд░реНрдореЗрдЯ рдХрд░ рд╕рдХреЗрдВ, рдЬрд┐рд╕рдореЗрдВ рдПрдХ [`MessagesPlaceholder`](/docs/modules/model_io/prompts/quick_start#messagesplaceholder) рд╢рд╛рдорд┐рд▓ рд╣реЛрдЧрд╛ рдЬрд╣рд╛рдБ рдЪреИрдЯ рдЗрддрд┐рд╣рд╛рд╕ рд╕рдВрджреЗрд╢ рд╕реАрдзреЗ рдЗрдВрдЬреЗрдХреНрдЯ рдХрд┐рдП рдЬрд╛рдПрдВрдЧреЗ:

```python
from langchain.chains.combine_documents import create_stuff_documents_chain

chat = ChatOpenAI(model="gpt-3.5-turbo-1106")

question_answering_prompt = ChatPromptTemplate.from_messages(
    [
        (
            "system",
            "Answer the user's questions based on the below context:\n\n{context}",
        ),
        MessagesPlaceholder(variable_name="messages"),
    ]
)

document_chain = create_stuff_documents_chain(chat, question_answering_prompt)
```

рд╣рдо рдКрдкрд░ рдкреБрдирд░реНрдкреНрд░рд╛рдкреНрдд рдХрд┐рдП рдЧрдП рдХрдЪреНрдЪреЗ рджрд╕реНрддрд╛рд╡реЗрдЬрд╝реЛрдВ рдХреЗ рд╕рд╛рде рдЗрд╕ `document_chain` рдХреЛ рдмреБрд▓рд╛ рд╕рдХрддреЗ рд╣реИрдВ:

```python
from langchain.memory import ChatMessageHistory

demo_ephemeral_chat_history = ChatMessageHistory()

demo_ephemeral_chat_history.add_user_message("how can langsmith help with testing?")

document_chain.invoke(
    {
        "messages": demo_ephemeral_chat_history.messages,
        "context": docs,
    }
)
```

```output
'LangSmith can assist with testing by providing the capability to quickly edit examples and add them to datasets. This allows for the expansion of evaluation sets or fine-tuning of a model for improved quality or reduced costs. Additionally, LangSmith simplifies the construction of small datasets by hand, providing a convenient way to rigorously test changes in the application.'
```

рдмрд╣реБрдд рдмрдврд╝рд┐рдпрд╛! рд╣рдо рдЗрдирдкреБрдЯ рджрд╕реНрддрд╛рд╡реЗрдЬрд╝реЛрдВ рдореЗрдВ рдЬрд╛рдирдХрд╛рд░реА рд╕реЗ рд╕рдВрдХрд▓рд┐рдд рдПрдХ рдЙрддреНрддрд░ рджреЗрдЦ рд╕рдХрддреЗ рд╣реИрдВред

### рдПрдХ рдкреБрдирд░реНрдкреНрд░рд╛рдкреНрддрд┐ рд╢реНрд░реГрдВрдЦрд▓рд╛ рдмрдирд╛рдирд╛

рдЕрдЧрд▓рд╛, рдЪрд▓рд┐рдП рдЕрдкрдиреЗ рдкреБрдирд░реНрдкреНрд░рд╛рдкреНрддрд┐ рдХреЛ рд╢реНрд░реГрдВрдЦрд▓рд╛ рдореЗрдВ рдЗрдВрдЯреАрдЧреНрд░реЗрдЯ рдХрд░рддреЗ рд╣реИрдВред рд╣рдорд╛рд░рд╛ рдкреБрдирд░реНрдкреНрд░рд╛рдкреНрддрд┐ рдЙрдкрдпреЛрдЧрдХрд░реНрддрд╛ рд╕реЗ рдкрд╛рд╕ рдХрд┐рдП рдЧрдП рдЕрдВрддрд┐рдо рд╕рдВрджреЗрд╢ рд╕реЗ рдкреНрд░рд╛рд╕рдВрдЧрд┐рдХ рдЬрд╛рдирдХрд╛рд░реА рдкреБрдирд░реНрдкреНрд░рд╛рдкреНрдд рдХрд░реЗрдЧрд╛, рдЗрд╕рд▓рд┐рдП рд╣рдо рдЗрд╕реЗ рдирд┐рдХрд╛рд▓рддреЗ рд╣реИрдВ рдФрд░ рдкреНрд░рд╛рд╕рдВрдЧрд┐рдХ рджрд╕реНрддрд╛рд╡реЗрдЬрд╝реЛрдВ рдХреЛ рдкреБрдирд░реНрдкреНрд░рд╛рдкреНрдд рдХрд░рдиреЗ рдХреЗ рд▓рд┐рдП рдЗрдирдкреБрдЯ рдХреЗ рд░реВрдк рдореЗрдВ рдЙрдкрдпреЛрдЧ рдХрд░рддреЗ рд╣реИрдВ, рдЬрд┐рдиреНрд╣реЗрдВ рд╣рдо рд╡рд░реНрддрдорд╛рди рд╢реНрд░реГрдВрдЦрд▓рд╛ рдореЗрдВ `context` рдХреЗ рд░реВрдк рдореЗрдВ рдЬреЛрдбрд╝рддреЗ рд╣реИрдВред рд╣рдо `context` рдФрд░ рдкрд┐рдЫрд▓реЗ `messages` рдХреЛ рдЕрдкрдиреЗ рджрд╕реНрддрд╛рд╡реЗрдЬрд╝ рд╢реНрд░реГрдВрдЦрд▓рд╛ рдореЗрдВ рдЕрдВрддрд┐рдо рдЙрддреНрддрд░ рдЙрддреНрдкрдиреНрди рдХрд░рдиреЗ рдХреЗ рд▓рд┐рдП рдкрд╛рд╕ рдХрд░рддреЗ рд╣реИрдВред

рд╣рдо рдкреНрд░рддреНрдпреЗрдХ рдХреЙрд▓ рдкрд░ рдордзреНрдпрд╡рд░реНрддреА рдЪрд░рдгреЛрдВ рдХреЛ рдкрд╛рд╕ рдХрд░рдиреЗ рдХреЗ рд▓рд┐рдП [`RunnablePassthrough.assign()`](/docs/expression_language/primitives/assign) рд╡рд┐рдзрд┐ рдХрд╛ рднреА рдЙрдкрдпреЛрдЧ рдХрд░рддреЗ рд╣реИрдВред рдпрд╣ рдЗрд╕ рдкреНрд░рдХрд╛рд░ рджрд┐рдЦрддрд╛ рд╣реИ:

```python
from typing import Dict

from langchain_core.runnables import RunnablePassthrough


def parse_retriever_input(params: Dict):
    return params["messages"][-1].content


retrieval_chain = RunnablePassthrough.assign(
    context=parse_retriever_input | retriever,
).assign(
    answer=document_chain,
)
```

```python
response = retrieval_chain.invoke(
    {
        "messages": demo_ephemeral_chat_history.messages,
    }
)

response
```

```output
{'messages': [HumanMessage(content='how can langsmith help with testing?')],
 'context': [Document(page_content='You can also quickly edit examples and add them to datasets to expand the surface area of your evaluation sets or to fine-tune a model for improved quality or reduced costs.Monitoring\u200bAfter all this, your app might finally ready to go in production. LangSmith can also be used to monitor your application in much the same way that you used for debugging. You can log all traces, visualize latency and token usage statistics, and troubleshoot specific issues as they arise. Each run can also be', metadata={'description': 'Building reliable LLM applications can be challenging. LangChain simplifies the initial setup, but there is still work needed to bring the performance of prompts, chains and agents up the level where they are reliable enough to be used in production.', 'language': 'en', 'source': 'https://docs.smith.langchain.com/overview', 'title': 'LangSmith Overview and User Guide | ЁЯжЬя╕ПЁЯЫая╕П LangSmith'}),
  Document(page_content='inputs, and see what happens. At some point though, our application is performing\nwell and we want to be more rigorous about testing changes. We can use a dataset\nthat weтАЩve constructed along the way (see above). Alternatively, we could spend some\ntime constructing a small dataset by hand. For these situations, LangSmith simplifies', metadata={'description': 'Building reliable LLM applications can be challenging. LangChain simplifies the initial setup, but there is still work needed to bring the performance of prompts, chains and agents up the level where they are reliable enough to be used in production.', 'language': 'en', 'source': 'https://docs.smith.langchain.com/overview', 'title': 'LangSmith Overview and User Guide | ЁЯжЬя╕ПЁЯЫая╕П LangSmith'}),
  Document(page_content='Skip to main contentЁЯжЬя╕ПЁЯЫая╕П LangSmith DocsPython DocsJS/TS DocsSearchGo to AppLangSmithOverviewTracingTesting & EvaluationOrganizationsHubLangSmith CookbookOverviewOn this pageLangSmith Overview and User GuideBuilding reliable LLM applications can be challenging. LangChain simplifies the initial setup, but there is still work needed to bring the performance of prompts, chains and agents up the level where they are reliable enough to be used in production.Over the past two months, we at LangChain', metadata={'description': 'Building reliable LLM applications can be challenging. LangChain simplifies the initial setup, but there is still work needed to bring the performance of prompts, chains and agents up the level where they are reliable enough to be used in production.', 'language': 'en', 'source': 'https://docs.smith.langchain.com/overview', 'title': 'LangSmith Overview and User Guide | ЁЯжЬя╕ПЁЯЫая╕П LangSmith'}),
  Document(page_content='have been building and using LangSmith with the goal of bridging this gap. This is our tactical user guide to outline effective ways to use LangSmith and maximize its benefits.On by default\u200bAt LangChain, all of us have LangSmithтАЩs tracing running in the background by default. On the Python side, this is achieved by setting environment variables, which we establish whenever we launch a virtual environment or open our bash shell and leave them set. The same principle applies to most JavaScript', metadata={'description': 'Building reliable LLM applications can be challenging. LangChain simplifies the initial setup, but there is still work needed to bring the performance of prompts, chains and agents up the level where they are reliable enough to be used in production.', 'language': 'en', 'source': 'https://docs.smith.langchain.com/overview', 'title': 'LangSmith Overview and User Guide | ЁЯжЬя╕ПЁЯЫая╕П LangSmith'})],
 'answer': 'LangSmith can help with testing in several ways:\n\n1. Dataset Expansion: LangSmith enables quick editing of examples and adding them to datasets, which expands the surface area of evaluation sets. This allows for more comprehensive testing of models and applications.\n\n2. Fine-Tuning Models: LangSmith facilitates the fine-tuning of models for improved quality or reduced costs. This is beneficial for optimizing the performance of models during testing.\n\n3. Monitoring: LangSmith can be used to monitor applications, log traces, visualize latency and token usage statistics, and troubleshoot specific issues as they arise during testing. This monitoring helps in ensuring the reliability and performance of the application during testing phases.\n\nOverall, LangSmith helps in making testing more rigorous and comprehensive, whether by expanding datasets, fine-tuning models, or monitoring application performance.'}
```

```python
demo_ephemeral_chat_history.add_ai_message(response["answer"])

demo_ephemeral_chat_history.add_user_message("tell me more about that!")

retrieval_chain.invoke(
    {
        "messages": demo_ephemeral_chat_history.messages,
    },
)
```

```output
{'messages': [HumanMessage(content='how can langsmith help with testing?'),
  AIMessage(content='LangSmith can help with testing in several ways:\n\n1. Dataset Expansion: LangSmith enables quick editing of examples and adding them to datasets, which expands the surface area of evaluation sets. This allows for more comprehensive testing of models and applications.\n\n2. Fine-Tuning Models: LangSmith facilitates the fine-tuning of models for improved quality or reduced costs. This is beneficial for optimizing the performance of models during testing.\n\n3. Monitoring: LangSmith can be used to monitor applications, log traces, visualize latency and token usage statistics, and troubleshoot specific issues as they arise during testing. This monitoring helps in ensuring the reliability and performance of the application during testing phases.\n\nOverall, LangSmith helps in making testing more rigorous and comprehensive, whether by expanding datasets, fine-tuning models, or monitoring application performance.'),
  HumanMessage(content='tell me more about that!')],
 'context': [Document(page_content='however, there is still no complete substitute for human review to get the utmost quality and reliability from your application.', metadata={'description': 'Building reliable LLM applications can be challenging. LangChain simplifies the initial setup, but there is still work needed to bring the performance of prompts, chains and agents up the level where they are reliable enough to be used in production.', 'language': 'en', 'source': 'https://docs.smith.langchain.com/overview', 'title': 'LangSmith Overview and User Guide | ЁЯжЬя╕ПЁЯЫая╕П LangSmith'}),
  Document(page_content='You can also quickly edit examples and add them to datasets to expand the surface area of your evaluation sets or to fine-tune a model for improved quality or reduced costs.Monitoring\u200bAfter all this, your app might finally ready to go in production. LangSmith can also be used to monitor your application in much the same way that you used for debugging. You can log all traces, visualize latency and token usage statistics, and troubleshoot specific issues as they arise. Each run can also be', metadata={'description': 'Building reliable LLM applications can be challenging. LangChain simplifies the initial setup, but there is still work needed to bring the performance of prompts, chains and agents up the level where they are reliable enough to be used in production.', 'language': 'en', 'source': 'https://docs.smith.langchain.com/overview', 'title': 'LangSmith Overview and User Guide | ЁЯжЬя╕ПЁЯЫая╕П LangSmith'}),
  Document(page_content="against these known issues.Why is this so impactful? When building LLM applications, itтАЩs often common to start without a dataset of any kind. This is part of the power of LLMs! They are amazing zero-shot learners, making it possible to get started as easily as possible. But this can also be a curse -- as you adjust the prompt, you're wandering blind. You donтАЩt have any examples to benchmark your changes against.LangSmith addresses this problem by including an тАЬAdd to DatasetтАЭ button for each", metadata={'description': 'Building reliable LLM applications can be challenging. LangChain simplifies the initial setup, but there is still work needed to bring the performance of prompts, chains and agents up the level where they are reliable enough to be used in production.', 'language': 'en', 'source': 'https://docs.smith.langchain.com/overview', 'title': 'LangSmith Overview and User Guide | ЁЯжЬя╕ПЁЯЫая╕П LangSmith'}),
  Document(page_content='playground. Here, you can modify the prompt and re-run it to observe the resulting changes to the output - as many times as needed!Currently, this feature supports only OpenAI and Anthropic models and works for LLM and Chat Model calls. We plan to extend its functionality to more LLM types, chains, agents, and retrievers in the future.What is the exact sequence of events?\u200bIn complicated chains and agents, it can often be hard to understand what is going on under the hood. What calls are being', metadata={'description': 'Building reliable LLM applications can be challenging. LangChain simplifies the initial setup, but there is still work needed to bring the performance of prompts, chains and agents up the level where they are reliable enough to be used in production.', 'language': 'en', 'source': 'https://docs.smith.langchain.com/overview', 'title': 'LangSmith Overview and User Guide | ЁЯжЬя╕ПЁЯЫая╕П LangSmith'})],
 'answer': 'Certainly! LangSmith offers the following capabilities to aid in testing:\n\n1. Dataset Expansion: By allowing quick editing of examples and adding them to datasets, LangSmith enables the expansion of evaluation sets. This is crucial for thorough testing of models and applications, as it broadens the range of scenarios and inputs that can be used to assess performance.\n\n2. Fine-Tuning Models: LangSmith supports the fine-tuning of models to enhance their quality and reduce operational costs. This capability is valuable during testing as it enables the optimization of model performance based on specific testing requirements and objectives.\n\n3. Monitoring: LangSmith provides monitoring features that allow for the logging of traces, visualization of latency and token usage statistics, and troubleshooting of issues as they occur during testing. This real-time monitoring helps in identifying and addressing any issues that may impact the reliability and performance of the application during testing.\n\nBy leveraging these features, LangSmith enhances the testing process by enabling comprehensive dataset expansion, model fine-tuning, and real-time monitoring to ensure the quality and reliability of applications and models.'}
```

рдЕрдЪреНрдЫрд╛! рдЕрдм рд╣рдорд╛рд░рд╛ рдЪреИрдЯрдмреЙрдЯ рдбреЛрдореЗрди-рд╡рд┐рд╢рд┐рд╖реНрдЯ рдкреНрд░рд╢реНрдиреЛрдВ рдХрд╛ рд╕рдВрд╡рд╛рджрд╛рддреНрдордХ рддрд░реАрдХреЗ рд╕реЗ рдЙрддреНрддрд░ рджреЗ рд╕рдХрддрд╛ рд╣реИред

рдПрдХ рдУрд░, рдпрджрд┐ рдЖрдк рд╕рднреА рдордзреНрдпрд╡рд░реНрддреА рдЪрд░рдгреЛрдВ рдХреЛ рд╡рд╛рдкрд╕ рдирд╣реАрдВ рдХрд░рдирд╛ рдЪрд╛рд╣рддреЗ рд╣реИрдВ, рддреЛ рдЖрдк рдЕрдВрддрд┐рдо `.assign()` рдХреЙрд▓ рдХреА рдмрдЬрд╛рдп рджрд╕реНрддрд╛рд╡реЗрдЬрд╝ рд╢реНрд░реГрдВрдЦрд▓рд╛ рдореЗрдВ рд╕реАрдзреЗ рдкрд╛рдЗрдк рдХрд╛ рдЙрдкрдпреЛрдЧ рдХрд░рдХреЗ рдЕрдкрдиреА рдкреБрдирд░реНрдкреНрд░рд╛рдкреНрддрд┐ рд╢реНрд░реГрдВрдЦрд▓рд╛ рдХреЛ рдЗрд╕ рдкреНрд░рдХрд╛рд░ рдкрд░рд┐рднрд╛рд╖рд┐рдд рдХрд░ рд╕рдХрддреЗ рд╣реИрдВ:

```python
retrieval_chain_with_only_answer = (
    RunnablePassthrough.assign(
        context=parse_retriever_input | retriever,
    )
    | document_chain
)

retrieval_chain_with_only_answer.invoke(
    {
        "messages": demo_ephemeral_chat_history.messages,
    },
)
```

```output
"LangSmith offers the capability to quickly edit examples and add them to datasets, thereby enhancing the scope of evaluation sets. This feature is particularly valuable for testing as it allows for a more thorough assessment of model performance and application behavior.\n\nFurthermore, LangSmith enables the fine-tuning of models to enhance quality and reduce costs, which can significantly impact testing outcomes. By adjusting and refining models, developers can ensure that they are thoroughly tested and optimized for various scenarios and use cases.\n\nAdditionally, LangSmith provides monitoring functionality, allowing users to log traces, visualize latency and token usage statistics, and troubleshoot specific issues as they encounter them during testing. This real-time monitoring and troubleshooting capability contribute to the overall effectiveness and reliability of the testing process.\n\nIn essence, LangSmith's features are designed to improve the quality and reliability of testing by expanding evaluation sets, fine-tuning models, and providing comprehensive monitoring capabilities. These aspects collectively contribute to a more robust and thorough testing process for applications and models."
```

## рдкреНрд░рд╢реНрди рдкрд░рд┐рд╡рд░реНрддрди

рдпрд╣рд╛рдБ рдПрдХ рдФрд░ рдСрдкреНрдЯрд┐рдорд╛рдЗрдЬрд╝реЗрд╢рди рд╣реИ рдЬрд┐рд╕реЗ рд╣рдо рдХрд╡рд░ рдХрд░реЗрдВрдЧреЗ - рдКрдкрд░ рдХреЗ рдЙрджрд╛рд╣рд░рдг рдореЗрдВ, рдЬрдм рд╣рдордиреЗ рдПрдХ рдЕрдиреБрд╡рд░реНрддреА рдкреНрд░рд╢реНрди рдкреВрдЫрд╛, `рдЗрд╕рдХреЗ рдмрд╛рд░реЗ рдореЗрдВ рдФрд░ рдмрддрд╛рдУ!`, рддреЛ рдЖрдкрдХреЛ рдпрд╣ рдзреНрдпрд╛рди рдореЗрдВ рдЖ рд╕рдХрддрд╛ рд╣реИ рдХрд┐ рдкреБрдирд░реНрдкреНрд░рд╛рдкреНрдд рджрд╕реНрддрд╛рд╡реЗрдЬрд╝ рд╕реАрдзреЗ рдкрд░реАрдХреНрд╖рдг рдХреЗ рдмрд╛рд░реЗ рдореЗрдВ рдЬрд╛рдирдХрд╛рд░реА рд╢рд╛рдорд┐рд▓ рдирд╣реАрдВ рдХрд░рддреЗ рд╣реИрдВред рдРрд╕рд╛ рдЗрд╕рд▓рд┐рдП рд╣реИ рдХреНрдпреЛрдВрдХрд┐ рд╣рдо рдкреБрдирд░реНрдкреНрд░рд╛рдкреНрддрд┐ рдХреЛ рдПрдХ рдХреНрд╡реЗрд░реА рдХреЗ рд░реВрдк рдореЗрдВ `рдЗрд╕рдХреЗ рдмрд╛рд░реЗ рдореЗрдВ рдФрд░ рдмрддрд╛рдУ!` рдХреЛ рд╢рдмреНрджрд╢рдГ рдкрд╛рд╕ рдХрд░ рд░рд╣реЗ рд╣реИрдВред рдкреБрдирд░реНрдкреНрд░рд╛рдкреНрддрд┐ рд╢реНрд░реГрдВрдЦрд▓рд╛ рдХрд╛ рдЖрдЙрдЯрдкреБрдЯ рдЕрднреА рднреА рдареАрдХ рд╣реИ рдХреНрдпреЛрдВрдХрд┐ рджрд╕реНрддрд╛рд╡реЗрдЬрд╝ рд╢реНрд░реГрдВрдЦрд▓рд╛ рдкреБрдирд░реНрдкреНрд░рд╛рдкреНрддрд┐ рд╢реНрд░реГрдВрдЦрд▓рд╛ рдЪреИрдЯ рдЗрддрд┐рд╣рд╛рд╕ рдХреЗ рдЖрдзрд╛рд░ рдкрд░ рдЙрддреНрддрд░ рдЙрддреНрдкрдиреНрди рдХрд░ рд╕рдХрддреА рд╣реИ, рд▓реЗрдХрд┐рди рд╣рдо рдЕрдзрд┐рдХ рд╕рдореГрджреНрдз рдФрд░ рд╕реВрдЪрдирд╛рддреНрдордХ рджрд╕реНрддрд╛рд╡реЗрдЬрд╝ рдкреБрдирд░реНрдкреНрд░рд╛рдкреНрдд рдХрд░ рд╕рдХрддреЗ рдереЗ:

```python
retriever.invoke("how can langsmith help with testing?")
```

```output
[Document(page_content='You can also quickly edit examples and add them to datasets to expand the surface area of your evaluation sets or to fine-tune a model for improved quality or reduced costs.Monitoring\u200bAfter all this, your app might finally ready to go in production. LangSmith can also be used to monitor your application in much the same way that you used for debugging. You can log all traces, visualize latency and token usage statistics, and troubleshoot specific issues as they arise. Each run can also be', metadata={'description': 'Building reliable LLM applications can be challenging. LangChain simplifies the initial setup, but there is still work needed to bring the performance of prompts, chains and agents up the level where they are reliable enough to be used in production.', 'language': 'en', 'source': 'https://docs.smith.langchain.com/overview', 'title': 'LangSmith Overview and User Guide | ЁЯжЬя╕ПЁЯЫая╕П LangSmith'}),
 Document(page_content='inputs, and see what happens. At some point though, our application is performing\nwell and we want to be more rigorous about testing changes. We can use a dataset\nthat weтАЩve constructed along the way (see above). Alternatively, we could spend some\ntime constructing a small dataset by hand. For these situations, LangSmith simplifies', metadata={'description': 'Building reliable LLM applications can be challenging. LangChain simplifies the initial setup, but there is still work needed to bring the performance of prompts, chains and agents up the level where they are reliable enough to be used in production.', 'language': 'en', 'source': 'https://docs.smith.langchain.com/overview', 'title': 'LangSmith Overview and User Guide | ЁЯжЬя╕ПЁЯЫая╕П LangSmith'}),
 Document(page_content='Skip to main contentЁЯжЬя╕ПЁЯЫая╕П LangSmith DocsPython DocsJS/TS DocsSearchGo to AppLangSmithOverviewTracingTesting & EvaluationOrganizationsHubLangSmith CookbookOverviewOn this pageLangSmith Overview and User GuideBuilding reliable LLM applications can be challenging. LangChain simplifies the initial setup, but there is still work needed to bring the performance of prompts, chains and agents up the level where they are reliable enough to be used in production.Over the past two months, we at LangChain', metadata={'description': 'Building reliable LLM applications can be challenging. LangChain simplifies the initial setup, but there is still work needed to bring the performance of prompts, chains and agents up the level where they are reliable enough to be used in production.', 'language': 'en', 'source': 'https://docs.smith.langchain.com/overview', 'title': 'LangSmith Overview and User Guide | ЁЯжЬя╕ПЁЯЫая╕П LangSmith'}),
 Document(page_content='have been building and using LangSmith with the goal of bridging this gap. This is our tactical user guide to outline effective ways to use LangSmith and maximize its benefits.On by default\u200bAt LangChain, all of us have LangSmithтАЩs tracing running in the background by default. On the Python side, this is achieved by setting environment variables, which we establish whenever we launch a virtual environment or open our bash shell and leave them set. The same principle applies to most JavaScript', metadata={'description': 'Building reliable LLM applications can be challenging. LangChain simplifies the initial setup, but there is still work needed to bring the performance of prompts, chains and agents up the level where they are reliable enough to be used in production.', 'language': 'en', 'source': 'https://docs.smith.langchain.com/overview', 'title': 'LangSmith Overview and User Guide | ЁЯжЬя╕ПЁЯЫая╕П LangSmith'})]
```

```python
retriever.invoke("tell me more about that!")
```

```output
[Document(page_content='however, there is still no complete substitute for human review to get the utmost quality and reliability from your application.', metadata={'description': 'Building reliable LLM applications can be challenging. LangChain simplifies the initial setup, but there is still work needed to bring the performance of prompts, chains and agents up the level where they are reliable enough to be used in production.', 'language': 'en', 'source': 'https://docs.smith.langchain.com/overview', 'title': 'LangSmith Overview and User Guide | ЁЯжЬя╕ПЁЯЫая╕П LangSmith'}),
 Document(page_content='You can also quickly edit examples and add them to datasets to expand the surface area of your evaluation sets or to fine-tune a model for improved quality or reduced costs.Monitoring\u200bAfter all this, your app might finally ready to go in production. LangSmith can also be used to monitor your application in much the same way that you used for debugging. You can log all traces, visualize latency and token usage statistics, and troubleshoot specific issues as they arise. Each run can also be', metadata={'description': 'Building reliable LLM applications can be challenging. LangChain simplifies the initial setup, but there is still work needed to bring the performance of prompts, chains and agents up the level where they are reliable enough to be used in production.', 'language': 'en', 'source': 'https://docs.smith.langchain.com/overview', 'title': 'LangSmith Overview and User Guide | ЁЯжЬя╕ПЁЯЫая╕П LangSmith'}),
 Document(page_content="against these known issues.Why is this so impactful? When building LLM applications, itтАЩs often common to start without a dataset of any kind. This is part of the power of LLMs! They are amazing zero-shot learners, making it possible to get started as easily as possible. But this can also be a curse -- as you adjust the prompt, you're wandering blind. You donтАЩt have any examples to benchmark your changes against.LangSmith addresses this problem by including an тАЬAdd to DatasetтАЭ button for each", metadata={'description': 'Building reliable LLM applications can be challenging. LangChain simplifies the initial setup, but there is still work needed to bring the performance of prompts, chains and agents up the level where they are reliable enough to be used in production.', 'language': 'en', 'source': 'https://docs.smith.langchain.com/overview', 'title': 'LangSmith Overview and User Guide | ЁЯжЬя╕ПЁЯЫая╕П LangSmith'}),
 Document(page_content='playground. Here, you can modify the prompt and re-run it to observe the resulting changes to the output - as many times as needed!Currently, this feature supports only OpenAI and Anthropic models and works for LLM and Chat Model calls. We plan to extend its functionality to more LLM types, chains, agents, and retrievers in the future.What is the exact sequence of events?\u200bIn complicated chains and agents, it can often be hard to understand what is going on under the hood. What calls are being', metadata={'description': 'Building reliable LLM applications can be challenging. LangChain simplifies the initial setup, but there is still work needed to bring the performance of prompts, chains and agents up the level where they are reliable enough to be used in production.', 'language': 'en', 'source': 'https://docs.smith.langchain.com/overview', 'title': 'LangSmith Overview and User Guide | ЁЯжЬя╕ПЁЯЫая╕П LangSmith'})]
```

рдЗрд╕ рд╕рд╛рдорд╛рдиреНрдп рд╕рдорд╕реНрдпрд╛ рд╕реЗ рдмрдЪрдиреЗ рдХреЗ рд▓рд┐рдП, рдЪрд▓рд┐рдП рдПрдХ `query transformation` рдЪрд░рдг рдЬреЛрдбрд╝рддреЗ рд╣реИрдВ рдЬреЛ рдЗрдирдкреБрдЯ рд╕реЗ рд╕рдВрджрд░реНрднреЛрдВ рдХреЛ рд╣рдЯрд╛ рджреЗрддрд╛ рд╣реИред рд╣рдо рдЕрдкрдиреЗ рдкреБрд░рд╛рдиреЗ рдкреБрдирд░реНрдкреНрд░рд╛рдкреНрддрд┐ рдХреЛ рдЗрд╕ рдкреНрд░рдХрд╛рд░ рд░реИрдк рдХрд░реЗрдВрдЧреЗ:

```python
from langchain_core.output_parsers import StrOutputParser
from langchain_core.runnables import RunnableBranch

# We need a prompt that we can pass into an LLM to generate a transformed search query

chat = ChatOpenAI(model="gpt-3.5-turbo-1106", temperature=0.2)

query_transform_prompt = ChatPromptTemplate.from_messages(
    [
        MessagesPlaceholder(variable_name="messages"),
        (
            "user",
            "Given the above conversation, generate a search query to look up in order to get information relevant to the conversation. Only respond with the query, nothing else.",
        ),
    ]
)

query_transforming_retriever_chain = RunnableBranch(
    (
        lambda x: len(x.get("messages", [])) == 1,
        # If only one message, then we just pass that message's content to retriever
        (lambda x: x["messages"][-1].content) | retriever,
    ),
    # If messages, then we pass inputs to LLM chain to transform the query, then pass to retriever
    query_transform_prompt | chat | StrOutputParser() | retriever,
).with_config(run_name="chat_retriever_chain")
```

рдЕрдм рд╣рдо рдЗрд╕ рдирдП `query_transforming_retriever_chain` рдХреЗ рд╕рд╛рде рдЕрдкрдиреА рдкрд┐рдЫрд▓реА рд╢реНрд░реГрдВрдЦрд▓рд╛ рдХреЛ рдкреБрдирдГ рдмрдирд╛рдПрдБред рдзреНрдпрд╛рди рджреЗрдВ рдХрд┐ рдпрд╣ рдирдИ рд╢реНрд░реГрдВрдЦрд▓рд╛ рдЗрдирдкреБрдЯ рдХреЗ рд░реВрдк рдореЗрдВ рдПрдХ рдбрд┐рдХреНрдЯ рд╕реНрд╡реАрдХрд╛рд░ рдХрд░рддреА рд╣реИ рдФрд░ рдкреБрдирд░реНрдкреНрд░рд╛рдкреНрддрд┐ рдХреЛ рдкрд╛рд╕ рдХрд░рдиреЗ рдХреЗ рд▓рд┐рдП рдПрдХ рд╕реНрдЯреНрд░рд┐рдВрдЧ рдХреЛ рдкрд╛рд░реНрд╕ рдХрд░рддреА рд╣реИ, рдЗрд╕рд▓рд┐рдП рд╣рдореЗрдВ рд╢реАрд░реНрд╖ рд╕реНрддрд░ рдкрд░ рдЕрддрд┐рд░рд┐рдХреНрдд рдкрд╛рд░реНрд╕рд┐рдВрдЧ рдХрд░рдиреЗ рдХреА рдЖрд╡рд╢реНрдпрдХрддрд╛ рдирд╣реАрдВ рд╣реИ:

```python
document_chain = create_stuff_documents_chain(chat, question_answering_prompt)

conversational_retrieval_chain = RunnablePassthrough.assign(
    context=query_transforming_retriever_chain,
).assign(
    answer=document_chain,
)

demo_ephemeral_chat_history = ChatMessageHistory()
```

рдФрд░ рдЕрдВрдд рдореЗрдВ, рдЗрд╕реЗ рдмреБрд▓рд╛рддреЗ рд╣реИрдВ!

```python
demo_ephemeral_chat_history.add_user_message("how can langsmith help with testing?")

response = conversational_retrieval_chain.invoke(
    {"messages": demo_ephemeral_chat_history.messages},
)

demo_ephemeral_chat_history.add_ai_message(response["answer"])

response
```

```output
{'messages': [HumanMessage(content='how can langsmith help with testing?'),
  AIMessage(content='LangSmith can assist with testing in several ways. It allows you to quickly edit examples and add them to datasets, expanding the range of evaluation sets. This can help in fine-tuning a model for improved quality or reduced costs. Additionally, LangSmith simplifies the construction of small datasets by hand, providing a convenient way to rigorously test changes in your application. Furthermore, it enables monitoring of your application by logging all traces, visualizing latency and token usage statistics, and troubleshooting specific issues as they arise.')],
 'context': [Document(page_content='You can also quickly edit examples and add them to datasets to expand the surface area of your evaluation sets or to fine-tune a model for improved quality or reduced costs.Monitoring\u200bAfter all this, your app might finally ready to go in production. LangSmith can also be used to monitor your application in much the same way that you used for debugging. You can log all traces, visualize latency and token usage statistics, and troubleshoot specific issues as they arise. Each run can also be', metadata={'description': 'Building reliable LLM applications can be challenging. LangChain simplifies the initial setup, but there is still work needed to bring the performance of prompts, chains and agents up the level where they are reliable enough to be used in production.', 'language': 'en', 'source': 'https://docs.smith.langchain.com/overview', 'title': 'LangSmith Overview and User Guide | ЁЯжЬя╕ПЁЯЫая╕П LangSmith'}),
  Document(page_content='inputs, and see what happens. At some point though, our application is performing\nwell and we want to be more rigorous about testing changes. We can use a dataset\nthat weтАЩve constructed along the way (see above). Alternatively, we could spend some\ntime constructing a small dataset by hand. For these situations, LangSmith simplifies', metadata={'description': 'Building reliable LLM applications can be challenging. LangChain simplifies the initial setup, but there is still work needed to bring the performance of prompts, chains and agents up the level where they are reliable enough to be used in production.', 'language': 'en', 'source': 'https://docs.smith.langchain.com/overview', 'title': 'LangSmith Overview and User Guide | ЁЯжЬя╕ПЁЯЫая╕П LangSmith'}),
  Document(page_content='Skip to main contentЁЯжЬя╕ПЁЯЫая╕П LangSmith DocsPython DocsJS/TS DocsSearchGo to AppLangSmithOverviewTracingTesting & EvaluationOrganizationsHubLangSmith CookbookOverviewOn this pageLangSmith Overview and User GuideBuilding reliable LLM applications can be challenging. LangChain simplifies the initial setup, but there is still work needed to bring the performance of prompts, chains and agents up the level where they are reliable enough to be used in production.Over the past two months, we at LangChain', metadata={'description': 'Building reliable LLM applications can be challenging. LangChain simplifies the initial setup, but there is still work needed to bring the performance of prompts, chains and agents up the level where they are reliable enough to be used in production.', 'language': 'en', 'source': 'https://docs.smith.langchain.com/overview', 'title': 'LangSmith Overview and User Guide | ЁЯжЬя╕ПЁЯЫая╕П LangSmith'}),
  Document(page_content='have been building and using LangSmith with the goal of bridging this gap. This is our tactical user guide to outline effective ways to use LangSmith and maximize its benefits.On by default\u200bAt LangChain, all of us have LangSmithтАЩs tracing running in the background by default. On the Python side, this is achieved by setting environment variables, which we establish whenever we launch a virtual environment or open our bash shell and leave them set. The same principle applies to most JavaScript', metadata={'description': 'Building reliable LLM applications can be challenging. LangChain simplifies the initial setup, but there is still work needed to bring the performance of prompts, chains and agents up the level where they are reliable enough to be used in production.', 'language': 'en', 'source': 'https://docs.smith.langchain.com/overview', 'title': 'LangSmith Overview and User Guide | ЁЯжЬя╕ПЁЯЫая╕П LangSmith'})],
 'answer': 'LangSmith can assist with testing in several ways. It allows you to quickly edit examples and add them to datasets, expanding the range of evaluation sets. This can help in fine-tuning a model for improved quality or reduced costs. Additionally, LangSmith simplifies the construction of small datasets by hand, providing a convenient way to rigorously test changes in your application. Furthermore, it enables monitoring of your application by logging all traces, visualizing latency and token usage statistics, and troubleshooting specific issues as they arise.'}
```

```python
demo_ephemeral_chat_history.add_user_message("tell me more about that!")

conversational_retrieval_chain.invoke(
    {"messages": demo_ephemeral_chat_history.messages}
)
```

```output
{'messages': [HumanMessage(content='how can langsmith help with testing?'),
  AIMessage(content='LangSmith can assist with testing in several ways. It allows you to quickly edit examples and add them to datasets, expanding the range of evaluation sets. This can help in fine-tuning a model for improved quality or reduced costs. Additionally, LangSmith simplifies the construction of small datasets by hand, providing a convenient way to rigorously test changes in your application. Furthermore, it enables monitoring of your application by logging all traces, visualizing latency and token usage statistics, and troubleshooting specific issues as they arise.'),
  HumanMessage(content='tell me more about that!')],
 'context': [Document(page_content='LangSmith Overview and User Guide | ЁЯжЬя╕ПЁЯЫая╕П LangSmith', metadata={'description': 'Building reliable LLM applications can be challenging. LangChain simplifies the initial setup, but there is still work needed to bring the performance of prompts, chains and agents up the level where they are reliable enough to be used in production.', 'language': 'en', 'source': 'https://docs.smith.langchain.com/overview', 'title': 'LangSmith Overview and User Guide | ЁЯжЬя╕ПЁЯЫая╕П LangSmith'}),
  Document(page_content='You can also quickly edit examples and add them to datasets to expand the surface area of your evaluation sets or to fine-tune a model for improved quality or reduced costs.Monitoring\u200bAfter all this, your app might finally ready to go in production. LangSmith can also be used to monitor your application in much the same way that you used for debugging. You can log all traces, visualize latency and token usage statistics, and troubleshoot specific issues as they arise. Each run can also be', metadata={'description': 'Building reliable LLM applications can be challenging. LangChain simplifies the initial setup, but there is still work needed to bring the performance of prompts, chains and agents up the level where they are reliable enough to be used in production.', 'language': 'en', 'source': 'https://docs.smith.langchain.com/overview', 'title': 'LangSmith Overview and User Guide | ЁЯжЬя╕ПЁЯЫая╕П LangSmith'}),
  Document(page_content='Skip to main contentЁЯжЬя╕ПЁЯЫая╕П LangSmith DocsPython DocsJS/TS DocsSearchGo to AppLangSmithOverviewTracingTesting & EvaluationOrganizationsHubLangSmith CookbookOverviewOn this pageLangSmith Overview and User GuideBuilding reliable LLM applications can be challenging. LangChain simplifies the initial setup, but there is still work needed to bring the performance of prompts, chains and agents up the level where they are reliable enough to be used in production.Over the past two months, we at LangChain', metadata={'description': 'Building reliable LLM applications can be challenging. LangChain simplifies the initial setup, but there is still work needed to bring the performance of prompts, chains and agents up the level where they are reliable enough to be used in production.', 'language': 'en', 'source': 'https://docs.smith.langchain.com/overview', 'title': 'LangSmith Overview and User Guide | ЁЯжЬя╕ПЁЯЫая╕П LangSmith'}),
  Document(page_content='inputs, and see what happens. At some point though, our application is performing\nwell and we want to be more rigorous about testing changes. We can use a dataset\nthat weтАЩve constructed along the way (see above). Alternatively, we could spend some\ntime constructing a small dataset by hand. For these situations, LangSmith simplifies', metadata={'description': 'Building reliable LLM applications can be challenging. LangChain simplifies the initial setup, but there is still work needed to bring the performance of prompts, chains and agents up the level where they are reliable enough to be used in production.', 'language': 'en', 'source': 'https://docs.smith.langchain.com/overview', 'title': 'LangSmith Overview and User Guide | ЁЯжЬя╕ПЁЯЫая╕П LangSmith'})],
 'answer': 'Certainly! LangSmith simplifies the process of constructing and editing datasets, which is essential for testing and fine-tuning models. By quickly editing examples and adding them to datasets, you can expand the surface area of your evaluation sets, leading to improved model quality and potentially reduced costs. Additionally, LangSmith provides monitoring capabilities for your application, allowing you to log all traces, visualize latency and token usage statistics, and troubleshoot specific issues as they arise. This comprehensive monitoring functionality helps ensure the reliability and performance of your application in production.'}
```

рдЖрдкрдХреЛ рдпрд╣ рд╕рдордЭрдиреЗ рдореЗрдВ рдорджрдж рдХрд░рдиреЗ рдХреЗ рд▓рд┐рдП рдХрд┐ рдЖрдВрддрд░рд┐рдХ рд░реВрдк рд╕реЗ рдХреНрдпрд╛ рд╣реЛ рд░рд╣рд╛ рд╣реИ, [рдпрд╣ рд▓реИрдВрдЧрд╕реНрдорд┐рде рдЯреНрд░реЗрд╕](https://smith.langchain.com/public/42f8993b-7d19-42d3-990a-6608a73c5824/r) рдкрд╣рд▓реЗ рдХреЙрд▓ рдХреЛ рджрд┐рдЦрд╛рддрд╛ рд╣реИред рдЖрдк рджреЗрдЦ рд╕рдХрддреЗ рд╣реИрдВ рдХрд┐ рдЙрдкрдпреЛрдЧрдХрд░реНрддрд╛ рдХреА рдкреНрд░рд╛рд░рдВрднрд┐рдХ рдХреНрд╡реЗрд░реА рдХреЛ рд╕реАрдзреЗ рдкреБрдирд░реНрдкреНрд░рд╛рдкреНрддрд┐ рдХреЛ рдкрд╛рд╕ рдХрд┐рдпрд╛ рдЧрдпрд╛ рд╣реИ, рдЬреЛ рдЙрдкрдпреБрдХреНрдд рджрд╕реНрддрд╛рд╡реЗрдЬрд╝ рд▓реМрдЯрд╛рддрд╛ рд╣реИред

рдЕрдиреБрд╡рд░реНрддреА рдкреНрд░рд╢реНрди рдХреЗ рд▓рд┐рдП рдХреЙрд▓, [рдЗрд╕ рд▓реИрдВрдЧрд╕реНрдорд┐рде рдЯреНрд░реЗрд╕ рджреНрд╡рд╛рд░рд╛ рдЪрд┐рддреНрд░рд┐рдд](https://smith.langchain.com/public/7b463791-868b-42bd-8035-17b471e9c7cd/r) рдЙрдкрдпреЛрдЧрдХрд░реНрддрд╛ рдХреЗ рдкреНрд░рд╛рд░рдВрднрд┐рдХ рдкреНрд░рд╢реНрди рдХреЛ рд▓реИрдВрдЧрд╕реНрдорд┐рде рдХреЗ рд╕рд╛рде рдкрд░реАрдХреНрд╖рдг рдХреЗ рд▓рд┐рдП рдЕрдзрд┐рдХ рдкреНрд░рд╛рд╕рдВрдЧрд┐рдХ рдХреБрдЫ рдореЗрдВ рдкреБрди: рд╡рд╛рдХреНрдпрд╛рдВрд╢рд┐рдд рдХрд░рддрд╛ рд╣реИ, рдЬрд┐рд╕рдХреЗ рдкрд░рд┐рдгрд╛рдорд╕реНрд╡рд░реВрдк рдЙрдЪреНрдЪ рдЧреБрдгрд╡рддреНрддрд╛ рд╡рд╛рд▓реЗ рджрд╕реНрддрд╛рд╡реЗрдЬрд╝ рд╣реЛрддреЗ рд╣реИрдВред

рдФрд░ рдЕрдм рд╣рдорд╛рд░реЗ рдкрд╛рд╕ рдПрдХ рдЪреИрдЯрдмреЙрдЯ рд╣реИ рдЬреЛ рд╕рдВрд╡рд╛рджрд╛рддреНрдордХ рдкреБрдирд░реНрдкреНрд░рд╛рдкреНрддрд┐ рдореЗрдВ рд╕рдХреНрд╖рдо рд╣реИ!

## рдЕрдЧрд▓реЗ рдХрджрдо

рдЕрдм рдЖрдк рдЬрд╛рдирддреЗ рд╣реИрдВ рдХрд┐ рдХреИрд╕реЗ рдПрдХ рд╕рдВрд╡рд╛рджрд╛рддреНрдордХ рдЪреИрдЯрдмреЙрдЯ рдмрдирд╛рдирд╛ рд╣реИ рдЬреЛ рдкрд┐рдЫрд▓реЗ рд╕рдВрджреЗрд╢реЛрдВ рдФрд░ рдбреЛрдореЗрди-рд╡рд┐рд╢рд┐рд╖реНрдЯ рдЬреНрдЮрд╛рди рдХреЛ рдЕрдкрдиреА рдЬреЗрдирд░реЗрд╢рди рдореЗрдВ рдПрдХреАрдХреГрдд рдХрд░ рд╕рдХрддрд╛ рд╣реИред рдЗрд╕рдХреЗ рдЪрд╛рд░реЛрдВ рдУрд░ рдЖрдк рдХрдИ рдЕрдиреНрдп рдЕрдиреБрдХреВрд▓рди рдХрд░ рд╕рдХрддреЗ рд╣реИрдВ - рдЕрдзрд┐рдХ рдЬрд╛рдирдХрд╛рд░реА рдХреЗ рд▓рд┐рдП рдирд┐рдореНрдирд▓рд┐рдЦрд┐рдд рдкреГрд╖реНрда рджреЗрдЦреЗрдВ:

- [Memory management](/docs/use_cases/chatbots/memory_management): рдЗрд╕рдореЗрдВ рдЪреИрдЯ рдЗрддрд┐рд╣рд╛рд╕ рдХреЛ рд╕реНрд╡рдЪрд╛рд▓рд┐рдд рд░реВрдк рд╕реЗ рдЕрдкрдбреЗрдЯ рдХрд░рдиреЗ рдХреЗ рд╕рд╛рде-рд╕рд╛рде рд▓рдВрдмреА рдмрд╛рддрдЪреАрдд рдХреЛ рдЯреНрд░рд┐рдо, рд╕рд╛рд░рд╛рдВрд╢рд┐рдд рдпрд╛ рдЕрдиреНрдпрдерд╛ рд╕рдВрд╢реЛрдзрд┐рдд рдХрд░рдиреЗ рдХреЗ рд▓рд┐рдП рдПрдХ рдЧрд╛рдЗрдб рд╢рд╛рдорд┐рд▓ рд╣реИ рддрд╛рдХрд┐ рдЖрдкрдХрд╛ рдмреЙрдЯ рдХреЗрдВрджреНрд░рд┐рдд рд░рд╣реЗред
- [Retrieval](/docs/use_cases/chatbots/retrieval): рдЖрдкрдХреЗ рдЪреИрдЯрдмреЙрдЯ рдХреЗ рд╕рд╛рде рд╡рд┐рднрд┐рдиреНрди рдкреНрд░рдХрд╛рд░ рдХреА рдкреБрдирд░реНрдкреНрд░рд╛рдкреНрддрд┐ рдХрд╛ рдЙрдкрдпреЛрдЧ рдХрд░рдиреЗ рдкрд░ рдПрдХ рдЧрд╣рди рдЕрд╡рд▓реЛрдХрди
- [Tool usage](/docs/use_cases/chatbots/tool_usage): рдпрд╣ рдХреИрд╕реЗ рдЖрдкрдХреЗ рдЪреИрдЯрдмреЙрдЯреНрд╕ рдХреЛ рдЕрдиреНрдп API рдФрд░ рд╕рд┐рд╕реНрдЯрдо рдХреЗ рд╕рд╛рде рдЗрдВрдЯрд░реИрдХреНрдЯ рдХрд░рдиреЗ рд╡рд╛рд▓реЗ рдЯреВрд▓ рдХрд╛ рдЙрдкрдпреЛрдЧ рдХрд░рдиреЗ рдХреА рдЕрдиреБрдорддрд┐ рджреЗрддрд╛ рд╣реИред
