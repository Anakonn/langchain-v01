---
sidebar_position: 0
title: Quickstart
translated: true
---

‡§Ø‡§π ‡§§‡•ç‡§µ‡§∞‡§ø‡§§ ‡§™‡•ç‡§∞‡§æ‡§∞‡§Ç‡§≠ ‡§π‡•à, ‡§π‡§Æ [‡§ö‡•à‡§ü ‡§Æ‡•â‡§°‡§≤](/docs/modules/model_io/chat/) ‡§ï‡§æ ‡§â‡§™‡§Ø‡•ã‡§ó ‡§ï‡§∞‡•á‡§Ç‡§ó‡•á ‡§ú‡•ã **‡§ï‡§æ‡§∞‡•ç‡§Ø/‡§â‡§™‡§ï‡§∞‡§£ ‡§ï‡•â‡§≤‡§ø‡§Ç‡§ó** ‡§Æ‡•á‡§Ç ‡§∏‡§ï‡•ç‡§∑‡§Æ ‡§π‡•à‡§Ç ‡§§‡§æ‡§ï‡§ø ‡§™‡§æ‡§† ‡§∏‡•á ‡§ú‡§æ‡§®‡§ï‡§æ‡§∞‡•Ä ‡§®‡§ø‡§ï‡§æ‡§≤‡•Ä ‡§ú‡§æ ‡§∏‡§ï‡•á‡•§

:::important
**‡§ï‡§æ‡§∞‡•ç‡§Ø/‡§â‡§™‡§ï‡§∞‡§£ ‡§ï‡•â‡§≤‡§ø‡§Ç‡§ó** ‡§ï‡§æ ‡§â‡§™‡§Ø‡•ã‡§ó ‡§ï‡§∞‡§ï‡•á ‡§®‡§ø‡§ï‡§æ‡§≤‡§®‡§æ ‡§ï‡•á‡§µ‡§≤ [**‡§ï‡§æ‡§∞‡•ç‡§Ø/‡§â‡§™‡§ï‡§∞‡§£ ‡§ï‡•â‡§≤‡§ø‡§Ç‡§ó** ‡§∏‡§Æ‡§∞‡•ç‡§•‡§® ‡§ï‡§∞‡§®‡•á ‡§µ‡§æ‡§≤‡•á ‡§Æ‡•â‡§°‡§≤](/docs/modules/model_io/chat/function_calling) ‡§ï‡•á ‡§∏‡§æ‡§• ‡§ï‡§æ‡§Æ ‡§ï‡§∞‡§§‡§æ ‡§π‡•à‡•§
:::

## ‡§∏‡•á‡§ü ‡§Ö‡§™ ‡§ï‡§∞‡§®‡§æ

‡§π‡§Æ [‡§∏‡§Ç‡§∞‡§ö‡§ø‡§§ ‡§Ü‡§â‡§ü‡§™‡•Å‡§ü](/docs/modules/model_io/chat/structured_output) ‡§µ‡§ø‡§ß‡§ø ‡§ï‡§æ ‡§â‡§™‡§Ø‡•ã‡§ó ‡§ï‡§∞‡•á‡§Ç‡§ó‡•á ‡§ú‡•ã **‡§ï‡§æ‡§∞‡•ç‡§Ø/‡§â‡§™‡§ï‡§∞‡§£ ‡§ï‡•â‡§≤‡§ø‡§Ç‡§ó** ‡§Æ‡•á‡§Ç ‡§∏‡§ï‡•ç‡§∑‡§Æ ‡§è‡§≤‡§è‡§≤‡§è‡§Æ ‡§™‡§∞ ‡§â‡§™‡§≤‡§¨‡•ç‡§ß ‡§π‡•à‡•§

‡§è‡§ï ‡§Æ‡•â‡§°‡§≤ ‡§ï‡§æ ‡§ö‡§Ø‡§® ‡§ï‡§∞‡•á‡§Ç, ‡§á‡§∏‡§ï‡•á ‡§≤‡§ø‡§è ‡§®‡§ø‡§∞‡•ç‡§≠‡§∞‡§§‡§æ‡§ì‡§Ç ‡§ï‡•ã ‡§∏‡•ç‡§•‡§æ‡§™‡§ø‡§§ ‡§ï‡§∞‡•á‡§Ç ‡§î‡§∞ API ‡§ï‡•Å‡§Ç‡§ú‡§ø‡§Ø‡§æ‡§Ç ‡§∏‡•á‡§ü ‡§ï‡§∞‡•á‡§Ç!

```python
!pip install langchain

# Install a model capable of tool calling
# pip install langchain-openai
# pip install langchain-mistralai
# pip install langchain-fireworks

# Set env vars for the relevant model or load from a .env file:
# import dotenv
# dotenv.load_dotenv()
```

## ‡§∏‡•ç‡§ï‡•Ä‡§Æ‡§æ

‡§™‡§π‡§≤‡•á, ‡§π‡§Æ‡•á‡§Ç ‡§Ø‡§π ‡§¨‡§§‡§æ‡§®‡§æ ‡§π‡•ã‡§ó‡§æ ‡§ï‡§ø ‡§π‡§Æ ‡§™‡§æ‡§† ‡§∏‡•á ‡§ï‡•å‡§® ‡§∏‡•Ä ‡§ú‡§æ‡§®‡§ï‡§æ‡§∞‡•Ä ‡§®‡§ø‡§ï‡§æ‡§≤‡§®‡§æ ‡§ö‡§æ‡§π‡§§‡•á ‡§π‡•à‡§Ç‡•§

‡§π‡§Æ ‡§µ‡•ç‡§Ø‡§ï‡•ç‡§§‡§ø‡§ó‡§§ ‡§ú‡§æ‡§®‡§ï‡§æ‡§∞‡•Ä ‡§®‡§ø‡§ï‡§æ‡§≤‡§®‡•á ‡§ï‡•á ‡§≤‡§ø‡§è ‡§è‡§ï ‡§â‡§¶‡§æ‡§π‡§∞‡§£ ‡§∏‡•ç‡§ï‡•Ä‡§Æ‡§æ ‡§™‡§∞‡§ø‡§≠‡§æ‡§∑‡§ø‡§§ ‡§ï‡§∞‡§®‡•á ‡§ï‡•á ‡§≤‡§ø‡§è Pydantic ‡§ï‡§æ ‡§â‡§™‡§Ø‡•ã‡§ó ‡§ï‡§∞‡•á‡§Ç‡§ó‡•á‡•§

```python
from typing import Optional

from langchain_core.pydantic_v1 import BaseModel, Field


class Person(BaseModel):
    """Information about a person."""

    # ^ Doc-string for the entity Person.
    # This doc-string is sent to the LLM as the description of the schema Person,
    # and it can help to improve extraction results.

    # Note that:
    # 1. Each field is an `optional` -- this allows the model to decline to extract it!
    # 2. Each field has a `description` -- this description is used by the LLM.
    # Having a good description can help improve extraction results.
    name: Optional[str] = Field(default=None, description="The name of the person")
    hair_color: Optional[str] = Field(
        default=None, description="The color of the peron's hair if known"
    )
    height_in_meters: Optional[str] = Field(
        default=None, description="Height measured in meters"
    )
```

‡§∏‡•ç‡§ï‡•Ä‡§Æ‡§æ ‡§ï‡•ã ‡§™‡§∞‡§ø‡§≠‡§æ‡§∑‡§ø‡§§ ‡§ï‡§∞‡§§‡•á ‡§∏‡§Æ‡§Ø ‡§¶‡•ã ‡§∏‡§∞‡•ç‡§µ‡§∂‡•ç‡§∞‡•á‡§∑‡•ç‡§† ‡§™‡•ç‡§∞‡§•‡§æ‡§è‡§Ç ‡§π‡•à‡§Ç:

1. **‡§ó‡•Å‡§£** ‡§î‡§∞ **‡§∏‡•ç‡§ï‡•Ä‡§Æ‡§æ** ‡§ï‡•ã ‡§¶‡§∏‡•ç‡§§‡§æ‡§µ‡•á‡§ú‡§º‡•Ä‡§ï‡•É‡§§ ‡§ï‡§∞‡•á‡§Ç: ‡§Ø‡§π ‡§ú‡§æ‡§®‡§ï‡§æ‡§∞‡•Ä ‡§è‡§≤‡§è‡§≤‡§è‡§Æ ‡§ï‡•ã ‡§≠‡•á‡§ú‡•Ä ‡§ú‡§æ‡§§‡•Ä ‡§π‡•à ‡§î‡§∞ ‡§ú‡§æ‡§®‡§ï‡§æ‡§∞‡•Ä ‡§®‡§ø‡§ï‡§æ‡§≤‡§®‡•á ‡§ï‡•Ä ‡§ó‡•Å‡§£‡§µ‡§§‡•ç‡§§‡§æ ‡§Æ‡•á‡§Ç ‡§∏‡•Å‡§ß‡§æ‡§∞ ‡§ï‡§∞‡§®‡•á ‡§Æ‡•á‡§Ç ‡§â‡§™‡§Ø‡•ã‡§ó ‡§ï‡•Ä ‡§ú‡§æ‡§§‡•Ä ‡§π‡•à‡•§
2. ‡§è‡§≤‡§è‡§≤‡§è‡§Æ ‡§ï‡•ã ‡§ú‡§æ‡§®‡§ï‡§æ‡§∞‡•Ä ‡§¨‡§®‡§æ‡§®‡•á ‡§ï‡•á ‡§≤‡§ø‡§è ‡§Æ‡§ú‡§¨‡•Ç‡§∞ ‡§® ‡§ï‡§∞‡•á‡§Ç! ‡§ä‡§™‡§∞ ‡§π‡§Æ‡§®‡•á ‡§ó‡•Å‡§£‡•ã‡§Ç ‡§ï‡•á ‡§≤‡§ø‡§è `Optional` ‡§ï‡§æ ‡§â‡§™‡§Ø‡•ã‡§ó ‡§ï‡§ø‡§Ø‡§æ ‡§§‡§æ‡§ï‡§ø ‡§è‡§≤‡§è‡§≤‡§è‡§Æ `None` ‡§Ü‡§â‡§ü‡§™‡•Å‡§ü ‡§ï‡§∞ ‡§∏‡§ï‡•á ‡§Ø‡§¶‡§ø ‡§â‡§∏‡•á ‡§â‡§§‡•ç‡§§‡§∞ ‡§®‡§π‡•Ä‡§Ç ‡§™‡§§‡§æ ‡§π‡•à‡•§

:::important
‡§¨‡•á‡§π‡§§‡§∞ ‡§™‡•ç‡§∞‡§¶‡§∞‡•ç‡§∂‡§® ‡§ï‡•á ‡§≤‡§ø‡§è, ‡§∏‡•ç‡§ï‡•Ä‡§Æ‡§æ ‡§ï‡•ã ‡§Ö‡§ö‡•ç‡§õ‡•Ä ‡§§‡§∞‡§π ‡§∏‡•á ‡§¶‡§∏‡•ç‡§§‡§æ‡§µ‡•á‡§ú‡§º‡•Ä‡§ï‡•É‡§§ ‡§ï‡§∞‡•á‡§Ç ‡§î‡§∞ ‡§∏‡•Å‡§®‡§ø‡§∂‡•ç‡§ö‡§ø‡§§ ‡§ï‡§∞‡•á‡§Ç ‡§ï‡§ø ‡§Æ‡•â‡§°‡§≤ ‡§ï‡•ã ‡§™‡§æ‡§† ‡§Æ‡•á‡§Ç ‡§ï‡•ã‡§à ‡§ú‡§æ‡§®‡§ï‡§æ‡§∞‡•Ä ‡§®‡§ø‡§ï‡§æ‡§≤‡§®‡•á ‡§ï‡•á ‡§≤‡§ø‡§è ‡§®‡§π‡•Ä‡§Ç ‡§Æ‡§ú‡§¨‡•Ç‡§∞ ‡§ï‡§ø‡§Ø‡§æ ‡§ú‡§æ‡§§‡§æ ‡§π‡•à‡•§
:::

## ‡§è‡§ï‡•ç‡§∏‡§ü‡•ç‡§∞‡•à‡§ï‡•ç‡§ü‡§∞

‡§Ü‡§á‡§è ‡§â‡§∏ ‡§∏‡•ç‡§ï‡•Ä‡§Æ‡§æ ‡§ï‡§æ ‡§â‡§™‡§Ø‡•ã‡§ó ‡§ï‡§∞‡§ï‡•á ‡§è‡§ï ‡§ú‡§æ‡§®‡§ï‡§æ‡§∞‡•Ä ‡§è‡§ï‡•ç‡§∏‡§ü‡•ç‡§∞‡•à‡§ï‡•ç‡§ü‡§∞ ‡§¨‡§®‡§æ‡§§‡•á ‡§π‡•à‡§Ç ‡§ú‡§ø‡§∏‡•á ‡§π‡§Æ‡§®‡•á ‡§™‡§∞‡§ø‡§≠‡§æ‡§∑‡§ø‡§§ ‡§ï‡§ø‡§Ø‡§æ ‡§π‡•à‡•§

```python
from typing import Optional

from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder
from langchain_core.pydantic_v1 import BaseModel, Field
from langchain_openai import ChatOpenAI

# Define a custom prompt to provide instructions and any additional context.
# 1) You can add examples into the prompt template to improve extraction quality
# 2) Introduce additional parameters to take context into account (e.g., include metadata
#    about the document from which the text was extracted.)
prompt = ChatPromptTemplate.from_messages(
    [
        (
            "system",
            "You are an expert extraction algorithm. "
            "Only extract relevant information from the text. "
            "If you do not know the value of an attribute asked to extract, "
            "return null for the attribute's value.",
        ),
        # Please see the how-to about improving performance with
        # reference examples.
        # MessagesPlaceholder('examples'),
        ("human", "{text}"),
    ]
)
```

‡§π‡§Æ‡•á‡§Ç **‡§ï‡§æ‡§∞‡•ç‡§Ø/‡§â‡§™‡§ï‡§∞‡§£ ‡§ï‡•â‡§≤‡§ø‡§Ç‡§ó** ‡§∏‡§Æ‡§∞‡•ç‡§•‡§® ‡§ï‡§∞‡§®‡•á ‡§µ‡§æ‡§≤‡•á ‡§è‡§ï ‡§Æ‡•â‡§°‡§≤ ‡§ï‡§æ ‡§â‡§™‡§Ø‡•ã‡§ó ‡§ï‡§∞‡§®‡§æ ‡§π‡•ã‡§ó‡§æ‡•§

[‡§∏‡§Ç‡§∞‡§ö‡§ø‡§§ ‡§Ü‡§â‡§ü‡§™‡•Å‡§ü](/docs/modules/model_io/chat/structured_output) ‡§™‡§∞ ‡§∏‡§Æ‡•Ä‡§ï‡•ç‡§∑‡§æ ‡§ï‡§∞‡•á‡§Ç ‡§ï‡§ø ‡§á‡§∏ API ‡§ï‡•á ‡§∏‡§æ‡§• ‡§â‡§™‡§Ø‡•ã‡§ó ‡§ï‡§ø‡§è ‡§ú‡§æ ‡§∏‡§ï‡§®‡•á ‡§µ‡§æ‡§≤‡•á ‡§ï‡•Å‡§õ ‡§Æ‡•â‡§°‡§≤ ‡§ï‡•å‡§® ‡§∏‡•á ‡§π‡•à‡§Ç‡•§

```python
from langchain_mistralai import ChatMistralAI

llm = ChatMistralAI(model="mistral-large-latest", temperature=0)

runnable = prompt | llm.with_structured_output(schema=Person)
```

‡§ö‡§≤‡•ã ‡§á‡§∏‡•á ‡§Ü‡§ú‡§º‡§Æ‡§æ‡§§‡•á ‡§π‡•à‡§Ç

```python
text = "Alan Smith is 6 feet tall and has blond hair."
runnable.invoke({"text": text})
```

```output
Person(name='Alan Smith', hair_color='blond', height_in_meters='1.8288')
```

:::important

‡§®‡§ø‡§ï‡§æ‡§≤‡§®‡§æ ‡§ú‡§®‡§∞‡•á‡§ü‡§ø‡§µ ‡§π‡•à ü§Ø

‡§è‡§≤‡§è‡§≤‡§è‡§Æ ‡§ú‡§®‡§∞‡•á‡§ü‡§ø‡§µ ‡§Æ‡•â‡§°‡§≤ ‡§π‡•à‡§Ç, ‡§á‡§∏‡§≤‡§ø‡§è ‡§µ‡•á ‡§ï‡•Å‡§õ ‡§ï‡§æ‡§´‡•Ä ‡§∂‡§æ‡§®‡§¶‡§æ‡§∞ ‡§ï‡§æ‡§Æ ‡§ï‡§∞ ‡§∏‡§ï‡§§‡•á ‡§π‡•à‡§Ç ‡§ú‡•à‡§∏‡•á ‡§ï‡§ø ‡§µ‡•ç‡§Ø‡§ï‡•ç‡§§‡§ø ‡§ï‡•Ä ‡§ä‡§Ç‡§ö‡§æ‡§à ‡§ï‡•ã ‡§´‡•Ä‡§ü ‡§Æ‡•á‡§Ç ‡§¶‡§ø‡§è ‡§ú‡§æ‡§®‡•á ‡§ï‡•á ‡§¨‡§æ‡§µ‡§ú‡•Ç‡§¶ ‡§Æ‡•Ä‡§ü‡§∞ ‡§Æ‡•á‡§Ç ‡§∏‡§π‡•Ä ‡§¢‡§Ç‡§ó ‡§∏‡•á ‡§®‡§ø‡§ï‡§æ‡§≤‡§®‡§æ!
:::

## ‡§è‡§ï‡§æ‡§ß‡§ø‡§ï ‡§á‡§ï‡§æ‡§á‡§Ø‡§æ‡§Ç

**‡§Ö‡§ß‡§ø‡§ï‡§§‡§∞ ‡§Æ‡§æ‡§Æ‡§≤‡•ã‡§Ç** ‡§Æ‡•á‡§Ç, ‡§Ü‡§™‡§ï‡•ã ‡§è‡§ï ‡§á‡§ï‡§æ‡§à ‡§ï‡•á ‡§¨‡§ú‡§æ‡§Ø ‡§á‡§ï‡§æ‡§á‡§Ø‡•ã‡§Ç ‡§ï‡•Ä ‡§è‡§ï ‡§∏‡•Ç‡§ö‡•Ä ‡§®‡§ø‡§ï‡§æ‡§≤‡§®‡•Ä ‡§ö‡§æ‡§π‡§ø‡§è‡•§

‡§á‡§∏‡•á ‡§™‡§æ‡§Ø‡§°‡•à‡§Ç‡§ü‡§ø‡§ï ‡§ï‡§æ ‡§â‡§™‡§Ø‡•ã‡§ó ‡§ï‡§∞‡§ï‡•á ‡§è‡§ï ‡§¶‡•Ç‡§∏‡§∞‡•á ‡§ï‡•á ‡§≠‡•Ä‡§§‡§∞ ‡§Æ‡•â‡§°‡§≤ ‡§ï‡•ã ‡§®‡•á‡§∏‡•ç‡§ü‡•á‡§° ‡§ï‡§∞‡§ï‡•á ‡§Ü‡§∏‡§æ‡§®‡•Ä ‡§∏‡•á ‡§™‡•ç‡§∞‡§æ‡§™‡•ç‡§§ ‡§ï‡§ø‡§Ø‡§æ ‡§ú‡§æ ‡§∏‡§ï‡§§‡§æ ‡§π‡•à‡•§

```python
from typing import List, Optional

from langchain_core.pydantic_v1 import BaseModel, Field


class Person(BaseModel):
    """Information about a person."""

    # ^ Doc-string for the entity Person.
    # This doc-string is sent to the LLM as the description of the schema Person,
    # and it can help to improve extraction results.

    # Note that:
    # 1. Each field is an `optional` -- this allows the model to decline to extract it!
    # 2. Each field has a `description` -- this description is used by the LLM.
    # Having a good description can help improve extraction results.
    name: Optional[str] = Field(default=None, description="The name of the person")
    hair_color: Optional[str] = Field(
        default=None, description="The color of the peron's hair if known"
    )
    height_in_meters: Optional[str] = Field(
        default=None, description="Height measured in meters"
    )


class Data(BaseModel):
    """Extracted data about people."""

    # Creates a model so that we can extract multiple entities.
    people: List[Person]
```

:::important
‡§®‡§ø‡§ï‡§æ‡§≤‡§®‡§æ ‡§Ø‡§π‡§æ‡§Ç ‡§™‡•Ç‡§∞‡•Ä ‡§§‡§∞‡§π ‡§∏‡•á ‡§∏‡§π‡•Ä ‡§®‡§π‡•Ä‡§Ç ‡§π‡•ã ‡§∏‡§ï‡§§‡§æ ‡§π‡•à‡•§ ‡§ï‡•É‡§™‡§Ø‡§æ **‡§∏‡§Ç‡§¶‡§∞‡•ç‡§≠ ‡§â‡§¶‡§æ‡§π‡§∞‡§£** ‡§ï‡§æ ‡§â‡§™‡§Ø‡•ã‡§ó ‡§ï‡§∞‡§ï‡•á ‡§®‡§ø‡§ï‡§æ‡§≤‡§®‡•á ‡§ï‡•Ä ‡§ó‡•Å‡§£‡§µ‡§§‡•ç‡§§‡§æ ‡§Æ‡•á‡§Ç ‡§∏‡•Å‡§ß‡§æ‡§∞ ‡§ï‡§∞‡§®‡•á ‡§î‡§∞ **‡§¶‡§ø‡§∂‡§æ‡§®‡§ø‡§∞‡•ç‡§¶‡•á‡§∂** ‡§ñ‡§Ç‡§° ‡§¶‡•á‡§ñ‡§®‡•á ‡§ï‡§æ ‡§ú‡§æ‡§∞‡•Ä ‡§∞‡§ñ‡•á‡§Ç!
:::

```python
runnable = prompt | llm.with_structured_output(schema=Data)
text = "My name is Jeff, my hair is black and i am 6 feet tall. Anna has the same color hair as me."
runnable.invoke({"text": text})
```

```output
Data(people=[Person(name='Jeff', hair_color=None, height_in_meters=None), Person(name='Anna', hair_color=None, height_in_meters=None)])
```

:::tip
‡§ú‡§¨ ‡§∏‡•ç‡§ï‡•Ä‡§Æ‡§æ **‡§è‡§ï‡§æ‡§ß‡§ø‡§ï ‡§á‡§ï‡§æ‡§á‡§Ø‡•ã‡§Ç** ‡§ï‡•á ‡§®‡§ø‡§ï‡§æ‡§≤‡§®‡•á ‡§∏‡§Æ‡§æ‡§Ø‡•ã‡§ú‡§ø‡§§ ‡§ï‡§∞‡§§‡•Ä ‡§π‡•à, ‡§§‡•ã ‡§Ø‡§π ‡§Æ‡•â‡§°‡§≤ ‡§ï‡•ã ‡§™‡§æ‡§† ‡§Æ‡•á‡§Ç ‡§ï‡•ã‡§à ‡§™‡•ç‡§∞‡§æ‡§∏‡§Ç‡§ó‡§ø‡§ï ‡§ú‡§æ‡§®‡§ï‡§æ‡§∞‡•Ä ‡§®‡§π‡•Ä‡§Ç ‡§π‡•ã‡§®‡•á ‡§™‡§∞ **‡§ï‡•ã‡§à ‡§á‡§ï‡§æ‡§á‡§Ø‡§æ‡§Ç ‡§®‡§π‡•Ä‡§Ç** ‡§®‡§ø‡§ï‡§æ‡§≤‡§®‡•á ‡§ï‡•Ä ‡§≠‡•Ä ‡§Ö‡§®‡•Å‡§Æ‡§§‡§ø ‡§¶‡•á‡§§‡•Ä ‡§π‡•à ‡§¶‡•ç‡§µ‡§æ‡§∞‡§æ ‡§è‡§ï ‡§ñ‡§æ‡§≤‡•Ä ‡§∏‡•Ç‡§ö‡•Ä ‡§™‡•ç‡§∞‡§¶‡§æ‡§® ‡§ï‡§∞‡§ï‡•á‡•§

‡§Ø‡§π ‡§Ü‡§Æ‡§§‡•å‡§∞ ‡§™‡§∞ ‡§è‡§ï **‡§Ö‡§ö‡•ç‡§õ‡•Ä** ‡§¨‡§æ‡§§ ‡§π‡•à! ‡§Ø‡§π ‡§è‡§ï ‡§á‡§ï‡§æ‡§à ‡§™‡§∞ **‡§Ü‡§µ‡§∂‡•ç‡§Ø‡§ï** ‡§ó‡•Å‡§£‡•ã‡§Ç ‡§ï‡•ã ‡§®‡§ø‡§∞‡•ç‡§¶‡§ø‡§∑‡•ç‡§ü ‡§ï‡§∞‡§®‡•á ‡§ï‡•Ä ‡§Ö‡§®‡•Å‡§Æ‡§§‡§ø ‡§¶‡•á‡§§‡§æ ‡§π‡•à ‡§¨‡§ø‡§®‡§æ ‡§á‡§∏ ‡§á‡§ï‡§æ‡§à ‡§ï‡§æ ‡§™‡§§‡§æ ‡§≤‡§ó‡§æ‡§®‡•á ‡§ï‡•á ‡§≤‡§ø‡§è ‡§Æ‡•â‡§°‡§≤ ‡§ï‡•ã ‡§Æ‡§ú‡§¨‡•Ç‡§∞ ‡§ï‡§∞‡§®‡•á ‡§ï‡•Ä ‡§Ü‡§µ‡§∂‡•ç‡§Ø‡§ï‡§§‡§æ‡•§
:::

## ‡§Ö‡§ó‡§≤‡•á ‡§ï‡§¶‡§Æ

‡§Ö‡§¨ ‡§ú‡§¨ ‡§Ü‡§™ ‡§è‡§ï‡•ç‡§∏‡§ü‡•ç‡§∞‡•à‡§ï‡•ç‡§∂‡§® ‡§ï‡•á ‡§∏‡§æ‡§• LangChain ‡§ï‡•á ‡§Æ‡•Ç‡§≤ ‡§¨‡§æ‡§§‡•ã‡§Ç ‡§ï‡•ã ‡§∏‡§Æ‡§ù ‡§ö‡•Å‡§ï‡•á ‡§π‡•à‡§Ç, ‡§§‡•ã ‡§Ü‡§™ ‡§ï‡•à‡§∏‡•á-‡§ï‡•à‡§∏‡•á ‡§ó‡§æ‡§á‡§° ‡§ï‡•á ‡§∂‡•á‡§∑ ‡§≠‡§æ‡§ó ‡§™‡§∞ ‡§Ü‡§ó‡•á ‡§¨‡§¢‡§º‡§®‡•á ‡§ï‡•á ‡§≤‡§ø‡§è ‡§§‡•à‡§Ø‡§æ‡§∞ ‡§π‡•à‡§Ç:

- [‡§â‡§¶‡§æ‡§π‡§∞‡§£ ‡§ú‡•ã‡§°‡§º‡•á‡§Ç](/docs/use_cases/extraction/how_to/examples): **‡§∏‡§Ç‡§¶‡§∞‡•ç‡§≠ ‡§â‡§¶‡§æ‡§π‡§∞‡§£‡•ã‡§Ç** ‡§ï‡§æ ‡§â‡§™‡§Ø‡•ã‡§ó ‡§ï‡§∞‡§ï‡•á ‡§™‡•ç‡§∞‡§¶‡§∞‡•ç‡§∂‡§® ‡§Æ‡•á‡§Ç ‡§∏‡•Å‡§ß‡§æ‡§∞ ‡§ï‡§∞‡§®‡§æ ‡§∏‡•Ä‡§ñ‡•á‡§Ç‡•§
- [‡§≤‡§Ç‡§¨‡•á ‡§™‡§æ‡§† ‡§ï‡•ã ‡§∏‡§Ç‡§≠‡§æ‡§≤‡§®‡§æ](/docs/use_cases/extraction/how_to/handle_long_text): ‡§Ü‡§™ ‡§ï‡•ç‡§Ø‡§æ ‡§ï‡§∞‡•á‡§Ç ‡§Ø‡§¶‡§ø ‡§™‡§æ‡§† ‡§è‡§≤‡§è‡§≤‡§è‡§Æ ‡§ï‡•á ‡§∏‡§Ç‡§¶‡§∞‡•ç‡§≠ ‡§µ‡§ø‡§Ç‡§°‡•ã ‡§Æ‡•á‡§Ç ‡§®‡§π‡•Ä‡§Ç ‡§´‡§ø‡§ü ‡§π‡•ã‡§§‡§æ ‡§π‡•à?
- [‡§´‡§º‡§æ‡§á‡§≤‡•ã‡§Ç ‡§ï‡•ã ‡§∏‡§Ç‡§≠‡§æ‡§≤‡§®‡§æ](/docs/use_cases/extraction/how_to/handle_files): PDF ‡§ú‡•à‡§∏‡•Ä ‡§´‡§º‡§æ‡§á‡§≤‡•ã‡§Ç ‡§∏‡•á ‡§®‡§ø‡§ï‡§æ‡§≤‡§®‡•á ‡§ï‡•á ‡§≤‡§ø‡§è LangChain ‡§¶‡§∏‡•ç‡§§‡§æ‡§µ‡•á‡§ú‡§º ‡§≤‡•ã‡§°‡§∞ ‡§î‡§∞ ‡§™‡§æ‡§∞‡•ç‡§∏‡§∞ ‡§ï‡§æ ‡§â‡§™‡§Ø‡•ã‡§ó ‡§ï‡§∞‡§®‡•á ‡§ï‡•á ‡§â‡§¶‡§æ‡§π‡§∞‡§£‡•§
- [‡§™‡§æ‡§∞‡•ç‡§∏‡§ø‡§Ç‡§ó ‡§¶‡•É‡§∑‡•ç‡§ü‡§ø‡§ï‡•ã‡§£ ‡§ï‡§æ ‡§â‡§™‡§Ø‡•ã‡§ó ‡§ï‡§∞‡•á‡§Ç](/docs/use_cases/extraction/how_to/parse): **‡§â‡§™‡§ï‡§∞‡§£/‡§ï‡§æ‡§∞‡•ç‡§Ø ‡§ï‡•â‡§≤‡§ø‡§Ç‡§ó** ‡§ï‡§æ ‡§∏‡§Æ‡§∞‡•ç‡§•‡§® ‡§®‡§π‡•Ä‡§Ç ‡§ï‡§∞‡§®‡•á ‡§µ‡§æ‡§≤‡•á ‡§Æ‡•â‡§°‡§≤ ‡§ï‡•á ‡§∏‡§æ‡§• ‡§®‡§ø‡§ï‡§æ‡§≤‡§®‡•á ‡§ï‡•á ‡§≤‡§ø‡§è ‡§™‡•ç‡§∞‡•ã‡§Æ‡•ç‡§™‡•ç‡§ü-‡§Ü‡§ß‡§æ‡§∞‡§ø‡§§ ‡§¶‡•É‡§∑‡•ç‡§ü‡§ø‡§ï‡•ã‡§£ ‡§ï‡§æ ‡§â‡§™‡§Ø‡•ã‡§ó ‡§ï‡§∞‡•á‡§Ç‡•§
- [‡§¶‡§ø‡§∂‡§æ‡§®‡§ø‡§∞‡•ç‡§¶‡•á‡§∂](/docs/use_cases/extraction/guidelines): ‡§®‡§ø‡§ï‡§æ‡§≤‡§®‡•á ‡§ï‡•á ‡§ï‡§æ‡§∞‡•ç‡§Ø‡•ã‡§Ç ‡§™‡§∞ ‡§Ö‡§ö‡•ç‡§õ‡§æ ‡§™‡•ç‡§∞‡§¶‡§∞‡•ç‡§∂‡§® ‡§™‡•ç‡§∞‡§æ‡§™‡•ç‡§§ ‡§ï‡§∞‡§®‡•á ‡§ï‡•á ‡§≤‡§ø‡§è ‡§¶‡§ø‡§∂‡§æ‡§®‡§ø‡§∞‡•ç‡§¶‡•á‡§∂‡•§
