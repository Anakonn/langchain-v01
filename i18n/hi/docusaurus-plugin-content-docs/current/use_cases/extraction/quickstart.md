---
sidebar_position: 0
title: Quickstart
translated: true
---

рдпрд╣ рддреНрд╡рд░рд┐рдд рдкреНрд░рд╛рд░рдВрдн рд╣реИ, рд╣рдо [рдЪреИрдЯ рдореЙрдбрд▓](/docs/modules/model_io/chat/) рдХрд╛ рдЙрдкрдпреЛрдЧ рдХрд░реЗрдВрдЧреЗ рдЬреЛ **рдХрд╛рд░реНрдп/рдЙрдкрдХрд░рдг рдХреЙрд▓рд┐рдВрдЧ** рдореЗрдВ рд╕рдХреНрд╖рдо рд╣реИрдВ рддрд╛рдХрд┐ рдкрд╛рда рд╕реЗ рдЬрд╛рдирдХрд╛рд░реА рдирд┐рдХрд╛рд▓реА рдЬрд╛ рд╕рдХреЗред

:::important
**рдХрд╛рд░реНрдп/рдЙрдкрдХрд░рдг рдХреЙрд▓рд┐рдВрдЧ** рдХрд╛ рдЙрдкрдпреЛрдЧ рдХрд░рдХреЗ рдирд┐рдХрд╛рд▓рдирд╛ рдХреЗрд╡рд▓ [**рдХрд╛рд░реНрдп/рдЙрдкрдХрд░рдг рдХреЙрд▓рд┐рдВрдЧ** рд╕рдорд░реНрдерди рдХрд░рдиреЗ рд╡рд╛рд▓реЗ рдореЙрдбрд▓](/docs/modules/model_io/chat/function_calling) рдХреЗ рд╕рд╛рде рдХрд╛рдо рдХрд░рддрд╛ рд╣реИред
:::

## рд╕реЗрдЯ рдЕрдк рдХрд░рдирд╛

рд╣рдо [рд╕рдВрд░рдЪрд┐рдд рдЖрдЙрдЯрдкреБрдЯ](/docs/modules/model_io/chat/structured_output) рд╡рд┐рдзрд┐ рдХрд╛ рдЙрдкрдпреЛрдЧ рдХрд░реЗрдВрдЧреЗ рдЬреЛ **рдХрд╛рд░реНрдп/рдЙрдкрдХрд░рдг рдХреЙрд▓рд┐рдВрдЧ** рдореЗрдВ рд╕рдХреНрд╖рдо рдПрд▓рдПрд▓рдПрдо рдкрд░ рдЙрдкрд▓рдмреНрдз рд╣реИред

рдПрдХ рдореЙрдбрд▓ рдХрд╛ рдЪрдпрди рдХрд░реЗрдВ, рдЗрд╕рдХреЗ рд▓рд┐рдП рдирд┐рд░реНрднрд░рддрд╛рдУрдВ рдХреЛ рд╕реНрдерд╛рдкрд┐рдд рдХрд░реЗрдВ рдФрд░ API рдХреБрдВрдЬрд┐рдпрд╛рдВ рд╕реЗрдЯ рдХрд░реЗрдВ!

```python
!pip install langchain

# Install a model capable of tool calling
# pip install langchain-openai
# pip install langchain-mistralai
# pip install langchain-fireworks

# Set env vars for the relevant model or load from a .env file:
# import dotenv
# dotenv.load_dotenv()
```

## рд╕реНрдХреАрдорд╛

рдкрд╣рд▓реЗ, рд╣рдореЗрдВ рдпрд╣ рдмрддрд╛рдирд╛ рд╣реЛрдЧрд╛ рдХрд┐ рд╣рдо рдкрд╛рда рд╕реЗ рдХреМрди рд╕реА рдЬрд╛рдирдХрд╛рд░реА рдирд┐рдХрд╛рд▓рдирд╛ рдЪрд╛рд╣рддреЗ рд╣реИрдВред

рд╣рдо рд╡реНрдпрдХреНрддрд┐рдЧрдд рдЬрд╛рдирдХрд╛рд░реА рдирд┐рдХрд╛рд▓рдиреЗ рдХреЗ рд▓рд┐рдП рдПрдХ рдЙрджрд╛рд╣рд░рдг рд╕реНрдХреАрдорд╛ рдкрд░рд┐рднрд╛рд╖рд┐рдд рдХрд░рдиреЗ рдХреЗ рд▓рд┐рдП Pydantic рдХрд╛ рдЙрдкрдпреЛрдЧ рдХрд░реЗрдВрдЧреЗред

```python
from typing import Optional

from langchain_core.pydantic_v1 import BaseModel, Field


class Person(BaseModel):
    """Information about a person."""

    # ^ Doc-string for the entity Person.
    # This doc-string is sent to the LLM as the description of the schema Person,
    # and it can help to improve extraction results.

    # Note that:
    # 1. Each field is an `optional` -- this allows the model to decline to extract it!
    # 2. Each field has a `description` -- this description is used by the LLM.
    # Having a good description can help improve extraction results.
    name: Optional[str] = Field(default=None, description="The name of the person")
    hair_color: Optional[str] = Field(
        default=None, description="The color of the peron's hair if known"
    )
    height_in_meters: Optional[str] = Field(
        default=None, description="Height measured in meters"
    )
```

рд╕реНрдХреАрдорд╛ рдХреЛ рдкрд░рд┐рднрд╛рд╖рд┐рдд рдХрд░рддреЗ рд╕рдордп рджреЛ рд╕рд░реНрд╡рд╢реНрд░реЗрд╖реНрда рдкреНрд░рдерд╛рдПрдВ рд╣реИрдВ:

1. **рдЧреБрдг** рдФрд░ **рд╕реНрдХреАрдорд╛** рдХреЛ рджрд╕реНрддрд╛рд╡реЗрдЬрд╝реАрдХреГрдд рдХрд░реЗрдВ: рдпрд╣ рдЬрд╛рдирдХрд╛рд░реА рдПрд▓рдПрд▓рдПрдо рдХреЛ рднреЗрдЬреА рдЬрд╛рддреА рд╣реИ рдФрд░ рдЬрд╛рдирдХрд╛рд░реА рдирд┐рдХрд╛рд▓рдиреЗ рдХреА рдЧреБрдгрд╡рддреНрддрд╛ рдореЗрдВ рд╕реБрдзрд╛рд░ рдХрд░рдиреЗ рдореЗрдВ рдЙрдкрдпреЛрдЧ рдХреА рдЬрд╛рддреА рд╣реИред
2. рдПрд▓рдПрд▓рдПрдо рдХреЛ рдЬрд╛рдирдХрд╛рд░реА рдмрдирд╛рдиреЗ рдХреЗ рд▓рд┐рдП рдордЬрдмреВрд░ рди рдХрд░реЗрдВ! рдКрдкрд░ рд╣рдордиреЗ рдЧреБрдгреЛрдВ рдХреЗ рд▓рд┐рдП `Optional` рдХрд╛ рдЙрдкрдпреЛрдЧ рдХрд┐рдпрд╛ рддрд╛рдХрд┐ рдПрд▓рдПрд▓рдПрдо `None` рдЖрдЙрдЯрдкреБрдЯ рдХрд░ рд╕рдХреЗ рдпрджрд┐ рдЙрд╕реЗ рдЙрддреНрддрд░ рдирд╣реАрдВ рдкрддрд╛ рд╣реИред

:::important
рдмреЗрд╣рддрд░ рдкреНрд░рджрд░реНрд╢рди рдХреЗ рд▓рд┐рдП, рд╕реНрдХреАрдорд╛ рдХреЛ рдЕрдЪреНрдЫреА рддрд░рд╣ рд╕реЗ рджрд╕реНрддрд╛рд╡реЗрдЬрд╝реАрдХреГрдд рдХрд░реЗрдВ рдФрд░ рд╕реБрдирд┐рд╢реНрдЪрд┐рдд рдХрд░реЗрдВ рдХрд┐ рдореЙрдбрд▓ рдХреЛ рдкрд╛рда рдореЗрдВ рдХреЛрдИ рдЬрд╛рдирдХрд╛рд░реА рдирд┐рдХрд╛рд▓рдиреЗ рдХреЗ рд▓рд┐рдП рдирд╣реАрдВ рдордЬрдмреВрд░ рдХрд┐рдпрд╛ рдЬрд╛рддрд╛ рд╣реИред
:::

## рдПрдХреНрд╕рдЯреНрд░реИрдХреНрдЯрд░

рдЖрдЗрдП рдЙрд╕ рд╕реНрдХреАрдорд╛ рдХрд╛ рдЙрдкрдпреЛрдЧ рдХрд░рдХреЗ рдПрдХ рдЬрд╛рдирдХрд╛рд░реА рдПрдХреНрд╕рдЯреНрд░реИрдХреНрдЯрд░ рдмрдирд╛рддреЗ рд╣реИрдВ рдЬрд┐рд╕реЗ рд╣рдордиреЗ рдкрд░рд┐рднрд╛рд╖рд┐рдд рдХрд┐рдпрд╛ рд╣реИред

```python
from typing import Optional

from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder
from langchain_core.pydantic_v1 import BaseModel, Field
from langchain_openai import ChatOpenAI

# Define a custom prompt to provide instructions and any additional context.
# 1) You can add examples into the prompt template to improve extraction quality
# 2) Introduce additional parameters to take context into account (e.g., include metadata
#    about the document from which the text was extracted.)
prompt = ChatPromptTemplate.from_messages(
    [
        (
            "system",
            "You are an expert extraction algorithm. "
            "Only extract relevant information from the text. "
            "If you do not know the value of an attribute asked to extract, "
            "return null for the attribute's value.",
        ),
        # Please see the how-to about improving performance with
        # reference examples.
        # MessagesPlaceholder('examples'),
        ("human", "{text}"),
    ]
)
```

рд╣рдореЗрдВ **рдХрд╛рд░реНрдп/рдЙрдкрдХрд░рдг рдХреЙрд▓рд┐рдВрдЧ** рд╕рдорд░реНрдерди рдХрд░рдиреЗ рд╡рд╛рд▓реЗ рдПрдХ рдореЙрдбрд▓ рдХрд╛ рдЙрдкрдпреЛрдЧ рдХрд░рдирд╛ рд╣реЛрдЧрд╛ред

[рд╕рдВрд░рдЪрд┐рдд рдЖрдЙрдЯрдкреБрдЯ](/docs/modules/model_io/chat/structured_output) рдкрд░ рд╕рдореАрдХреНрд╖рд╛ рдХрд░реЗрдВ рдХрд┐ рдЗрд╕ API рдХреЗ рд╕рд╛рде рдЙрдкрдпреЛрдЧ рдХрд┐рдП рдЬрд╛ рд╕рдХрдиреЗ рд╡рд╛рд▓реЗ рдХреБрдЫ рдореЙрдбрд▓ рдХреМрди рд╕реЗ рд╣реИрдВред

```python
from langchain_mistralai import ChatMistralAI

llm = ChatMistralAI(model="mistral-large-latest", temperature=0)

runnable = prompt | llm.with_structured_output(schema=Person)
```

рдЪрд▓реЛ рдЗрд╕реЗ рдЖрдЬрд╝рдорд╛рддреЗ рд╣реИрдВ

```python
text = "Alan Smith is 6 feet tall and has blond hair."
runnable.invoke({"text": text})
```

```output
Person(name='Alan Smith', hair_color='blond', height_in_meters='1.8288')
```

:::important

рдирд┐рдХрд╛рд▓рдирд╛ рдЬрдирд░реЗрдЯрд┐рд╡ рд╣реИ ЁЯдп

рдПрд▓рдПрд▓рдПрдо рдЬрдирд░реЗрдЯрд┐рд╡ рдореЙрдбрд▓ рд╣реИрдВ, рдЗрд╕рд▓рд┐рдП рд╡реЗ рдХреБрдЫ рдХрд╛рдлреА рд╢рд╛рдирджрд╛рд░ рдХрд╛рдо рдХрд░ рд╕рдХрддреЗ рд╣реИрдВ рдЬреИрд╕реЗ рдХрд┐ рд╡реНрдпрдХреНрддрд┐ рдХреА рдКрдВрдЪрд╛рдИ рдХреЛ рдлреАрдЯ рдореЗрдВ рджрд┐рдП рдЬрд╛рдиреЗ рдХреЗ рдмрд╛рд╡рдЬреВрдж рдореАрдЯрд░ рдореЗрдВ рд╕рд╣реА рдврдВрдЧ рд╕реЗ рдирд┐рдХрд╛рд▓рдирд╛!
:::

## рдПрдХрд╛рдзрд┐рдХ рдЗрдХрд╛рдЗрдпрд╛рдВ

**рдЕрдзрд┐рдХрддрд░ рдорд╛рдорд▓реЛрдВ** рдореЗрдВ, рдЖрдкрдХреЛ рдПрдХ рдЗрдХрд╛рдИ рдХреЗ рдмрдЬрд╛рдп рдЗрдХрд╛рдЗрдпреЛрдВ рдХреА рдПрдХ рд╕реВрдЪреА рдирд┐рдХрд╛рд▓рдиреА рдЪрд╛рд╣рд┐рдПред

рдЗрд╕реЗ рдкрд╛рдпрдбреИрдВрдЯрд┐рдХ рдХрд╛ рдЙрдкрдпреЛрдЧ рдХрд░рдХреЗ рдПрдХ рджреВрд╕рд░реЗ рдХреЗ рднреАрддрд░ рдореЙрдбрд▓ рдХреЛ рдиреЗрд╕реНрдЯреЗрдб рдХрд░рдХреЗ рдЖрд╕рд╛рдиреА рд╕реЗ рдкреНрд░рд╛рдкреНрдд рдХрд┐рдпрд╛ рдЬрд╛ рд╕рдХрддрд╛ рд╣реИред

```python
from typing import List, Optional

from langchain_core.pydantic_v1 import BaseModel, Field


class Person(BaseModel):
    """Information about a person."""

    # ^ Doc-string for the entity Person.
    # This doc-string is sent to the LLM as the description of the schema Person,
    # and it can help to improve extraction results.

    # Note that:
    # 1. Each field is an `optional` -- this allows the model to decline to extract it!
    # 2. Each field has a `description` -- this description is used by the LLM.
    # Having a good description can help improve extraction results.
    name: Optional[str] = Field(default=None, description="The name of the person")
    hair_color: Optional[str] = Field(
        default=None, description="The color of the peron's hair if known"
    )
    height_in_meters: Optional[str] = Field(
        default=None, description="Height measured in meters"
    )


class Data(BaseModel):
    """Extracted data about people."""

    # Creates a model so that we can extract multiple entities.
    people: List[Person]
```

:::important
рдирд┐рдХрд╛рд▓рдирд╛ рдпрд╣рд╛рдВ рдкреВрд░реА рддрд░рд╣ рд╕реЗ рд╕рд╣реА рдирд╣реАрдВ рд╣реЛ рд╕рдХрддрд╛ рд╣реИред рдХреГрдкрдпрд╛ **рд╕рдВрджрд░реНрдн рдЙрджрд╛рд╣рд░рдг** рдХрд╛ рдЙрдкрдпреЛрдЧ рдХрд░рдХреЗ рдирд┐рдХрд╛рд▓рдиреЗ рдХреА рдЧреБрдгрд╡рддреНрддрд╛ рдореЗрдВ рд╕реБрдзрд╛рд░ рдХрд░рдиреЗ рдФрд░ **рджрд┐рд╢рд╛рдирд┐рд░реНрджреЗрд╢** рдЦрдВрдб рджреЗрдЦрдиреЗ рдХрд╛ рдЬрд╛рд░реА рд░рдЦреЗрдВ!
:::

```python
runnable = prompt | llm.with_structured_output(schema=Data)
text = "My name is Jeff, my hair is black and i am 6 feet tall. Anna has the same color hair as me."
runnable.invoke({"text": text})
```

```output
Data(people=[Person(name='Jeff', hair_color=None, height_in_meters=None), Person(name='Anna', hair_color=None, height_in_meters=None)])
```

:::tip
рдЬрдм рд╕реНрдХреАрдорд╛ **рдПрдХрд╛рдзрд┐рдХ рдЗрдХрд╛рдЗрдпреЛрдВ** рдХреЗ рдирд┐рдХрд╛рд▓рдиреЗ рд╕рдорд╛рдпреЛрдЬрд┐рдд рдХрд░рддреА рд╣реИ, рддреЛ рдпрд╣ рдореЙрдбрд▓ рдХреЛ рдкрд╛рда рдореЗрдВ рдХреЛрдИ рдкреНрд░рд╛рд╕рдВрдЧрд┐рдХ рдЬрд╛рдирдХрд╛рд░реА рдирд╣реАрдВ рд╣реЛрдиреЗ рдкрд░ **рдХреЛрдИ рдЗрдХрд╛рдЗрдпрд╛рдВ рдирд╣реАрдВ** рдирд┐рдХрд╛рд▓рдиреЗ рдХреА рднреА рдЕрдиреБрдорддрд┐ рджреЗрддреА рд╣реИ рджреНрд╡рд╛рд░рд╛ рдПрдХ рдЦрд╛рд▓реА рд╕реВрдЪреА рдкреНрд░рджрд╛рди рдХрд░рдХреЗред

рдпрд╣ рдЖрдорддреМрд░ рдкрд░ рдПрдХ **рдЕрдЪреНрдЫреА** рдмрд╛рдд рд╣реИ! рдпрд╣ рдПрдХ рдЗрдХрд╛рдИ рдкрд░ **рдЖрд╡рд╢реНрдпрдХ** рдЧреБрдгреЛрдВ рдХреЛ рдирд┐рд░реНрджрд┐рд╖реНрдЯ рдХрд░рдиреЗ рдХреА рдЕрдиреБрдорддрд┐ рджреЗрддрд╛ рд╣реИ рдмрд┐рдирд╛ рдЗрд╕ рдЗрдХрд╛рдИ рдХрд╛ рдкрддрд╛ рд▓рдЧрд╛рдиреЗ рдХреЗ рд▓рд┐рдП рдореЙрдбрд▓ рдХреЛ рдордЬрдмреВрд░ рдХрд░рдиреЗ рдХреА рдЖрд╡рд╢реНрдпрдХрддрд╛ред
:::

## рдЕрдЧрд▓реЗ рдХрджрдо

рдЕрдм рдЬрдм рдЖрдк рдПрдХреНрд╕рдЯреНрд░реИрдХреНрд╢рди рдХреЗ рд╕рд╛рде LangChain рдХреЗ рдореВрд▓ рдмрд╛рддреЛрдВ рдХреЛ рд╕рдордЭ рдЪреБрдХреЗ рд╣реИрдВ, рддреЛ рдЖрдк рдХреИрд╕реЗ-рдХреИрд╕реЗ рдЧрд╛рдЗрдб рдХреЗ рд╢реЗрд╖ рднрд╛рдЧ рдкрд░ рдЖрдЧреЗ рдмрдврд╝рдиреЗ рдХреЗ рд▓рд┐рдП рддреИрдпрд╛рд░ рд╣реИрдВ:

- [рдЙрджрд╛рд╣рд░рдг рдЬреЛрдбрд╝реЗрдВ](/docs/use_cases/extraction/how_to/examples): **рд╕рдВрджрд░реНрдн рдЙрджрд╛рд╣рд░рдгреЛрдВ** рдХрд╛ рдЙрдкрдпреЛрдЧ рдХрд░рдХреЗ рдкреНрд░рджрд░реНрд╢рди рдореЗрдВ рд╕реБрдзрд╛рд░ рдХрд░рдирд╛ рд╕реАрдЦреЗрдВред
- [рд▓рдВрдмреЗ рдкрд╛рда рдХреЛ рд╕рдВрднрд╛рд▓рдирд╛](/docs/use_cases/extraction/how_to/handle_long_text): рдЖрдк рдХреНрдпрд╛ рдХрд░реЗрдВ рдпрджрд┐ рдкрд╛рда рдПрд▓рдПрд▓рдПрдо рдХреЗ рд╕рдВрджрд░реНрдн рд╡рд┐рдВрдбреЛ рдореЗрдВ рдирд╣реАрдВ рдлрд┐рдЯ рд╣реЛрддрд╛ рд╣реИ?
- [рдлрд╝рд╛рдЗрд▓реЛрдВ рдХреЛ рд╕рдВрднрд╛рд▓рдирд╛](/docs/use_cases/extraction/how_to/handle_files): PDF рдЬреИрд╕реА рдлрд╝рд╛рдЗрд▓реЛрдВ рд╕реЗ рдирд┐рдХрд╛рд▓рдиреЗ рдХреЗ рд▓рд┐рдП LangChain рджрд╕реНрддрд╛рд╡реЗрдЬрд╝ рд▓реЛрдбрд░ рдФрд░ рдкрд╛рд░реНрд╕рд░ рдХрд╛ рдЙрдкрдпреЛрдЧ рдХрд░рдиреЗ рдХреЗ рдЙрджрд╛рд╣рд░рдгред
- [рдкрд╛рд░реНрд╕рд┐рдВрдЧ рджреГрд╖реНрдЯрд┐рдХреЛрдг рдХрд╛ рдЙрдкрдпреЛрдЧ рдХрд░реЗрдВ](/docs/use_cases/extraction/how_to/parse): **рдЙрдкрдХрд░рдг/рдХрд╛рд░реНрдп рдХреЙрд▓рд┐рдВрдЧ** рдХрд╛ рд╕рдорд░реНрдерди рдирд╣реАрдВ рдХрд░рдиреЗ рд╡рд╛рд▓реЗ рдореЙрдбрд▓ рдХреЗ рд╕рд╛рде рдирд┐рдХрд╛рд▓рдиреЗ рдХреЗ рд▓рд┐рдП рдкреНрд░реЛрдореНрдкреНрдЯ-рдЖрдзрд╛рд░рд┐рдд рджреГрд╖реНрдЯрд┐рдХреЛрдг рдХрд╛ рдЙрдкрдпреЛрдЧ рдХрд░реЗрдВред
- [рджрд┐рд╢рд╛рдирд┐рд░реНрджреЗрд╢](/docs/use_cases/extraction/guidelines): рдирд┐рдХрд╛рд▓рдиреЗ рдХреЗ рдХрд╛рд░реНрдпреЛрдВ рдкрд░ рдЕрдЪреНрдЫрд╛ рдкреНрд░рджрд░реНрд╢рди рдкреНрд░рд╛рдкреНрдд рдХрд░рдиреЗ рдХреЗ рд▓рд┐рдП рджрд┐рд╢рд╛рдирд┐рд░реНрджреЗрд╢ред
