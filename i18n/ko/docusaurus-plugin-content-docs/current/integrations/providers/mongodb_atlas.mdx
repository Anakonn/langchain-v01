---
translated: true
---

# MongoDB Atlas

>[MongoDB Atlas](https://www.mongodb.com/docs/atlas/) 는 AWS, Azure, GCP에서 사용할 수 있는 완전 관리형 클라우드 데이터베이스입니다. 이제 MongoDB 문서 데이터에 대한 기본 벡터 검색을 지원합니다.

## 설치 및 설정

[자세한 구성 지침](/docs/integrations/vectorstores/mongodb_atlas)을 참조하세요.

`langchain-mongodb` Python 패키지를 설치해야 합니다.

```bash
pip install langchain-mongodb
```

## 벡터 스토어

[사용 예제](/docs/integrations/vectorstores/mongodb_atlas)를 참조하세요.

```python
<!--IMPORTS:[{"imported": "MongoDBAtlasVectorSearch", "source": "langchain_mongodb", "docs": "https://api.python.langchain.com/en/latest/vectorstores/langchain_mongodb.vectorstores.MongoDBAtlasVectorSearch.html", "title": "MongoDB Atlas"}]-->
from langchain_mongodb import MongoDBAtlasVectorSearch
```

## LLM 캐시

### MongoDBCache

MongoDB에 간단한 캐시를 저장하는 추상화입니다. 이것은 시맨틱 캐싱을 사용하지 않으며 생성 전에 컬렉션에 인덱스를 만들 필요가 없습니다.

이 캐시를 가져오려면:

```python
<!--IMPORTS:[{"imported": "MongoDBCache", "source": "langchain_mongodb.cache", "docs": "https://api.python.langchain.com/en/latest/cache/langchain_mongodb.cache.MongoDBCache.html", "title": "MongoDB Atlas"}]-->
from langchain_mongodb.cache import MongoDBCache
```

LLM에서 이 캐시를 사용하려면:

```python
<!--IMPORTS:[{"imported": "set_llm_cache", "source": "langchain_core.globals", "docs": "https://api.python.langchain.com/en/latest/globals/langchain_core.globals.set_llm_cache.html", "title": "MongoDB Atlas"}]-->
from langchain_core.globals import set_llm_cache

# use any embedding provider...
from tests.integration_tests.vectorstores.fake_embeddings import FakeEmbeddings

mongodb_atlas_uri = "<YOUR_CONNECTION_STRING>"
COLLECTION_NAME="<YOUR_CACHE_COLLECTION_NAME>"
DATABASE_NAME="<YOUR_DATABASE_NAME>"

set_llm_cache(MongoDBCache(
    connection_string=mongodb_atlas_uri,
    collection_name=COLLECTION_NAME,
    database_name=DATABASE_NAME,
))
```

### MongoDBAtlasSemanticCache

시맨틱 캐싱을 사용하면 사용자 입력과 이전에 캐시된 결과 간의 시맨틱 유사성을 기반으로 캐시된 프롬프트를 검색할 수 있습니다. 내부적으로 MongoDB Atlas를 캐시와 벡터 스토어로 모두 사용합니다.
MongoDBAtlasSemanticCache는 `MongoDBAtlasVectorSearch`를 상속하며 작동하려면 Atlas Vector Search 인덱스가 정의되어 있어야 합니다. 인덱스 설정 방법은 [사용 예제](/docs/integrations/vectorstores/mongodb_atlas)를 참조하세요.

이 캐시를 가져오려면:

```python
<!--IMPORTS:[{"imported": "MongoDBAtlasSemanticCache", "source": "langchain_mongodb.cache", "docs": "https://api.python.langchain.com/en/latest/cache/langchain_mongodb.cache.MongoDBAtlasSemanticCache.html", "title": "MongoDB Atlas"}]-->
from langchain_mongodb.cache import MongoDBAtlasSemanticCache
```

LLM에서 이 캐시를 사용하려면:

```python
<!--IMPORTS:[{"imported": "set_llm_cache", "source": "langchain_core.globals", "docs": "https://api.python.langchain.com/en/latest/globals/langchain_core.globals.set_llm_cache.html", "title": "MongoDB Atlas"}]-->
from langchain_core.globals import set_llm_cache

# use any embedding provider...
from tests.integration_tests.vectorstores.fake_embeddings import FakeEmbeddings

mongodb_atlas_uri = "<YOUR_CONNECTION_STRING>"
COLLECTION_NAME="<YOUR_CACHE_COLLECTION_NAME>"
DATABASE_NAME="<YOUR_DATABASE_NAME>"

set_llm_cache(MongoDBAtlasSemanticCache(
    embedding=FakeEmbeddings(),
    connection_string=mongodb_atlas_uri,
    collection_name=COLLECTION_NAME,
    database_name=DATABASE_NAME,
))
```

``
