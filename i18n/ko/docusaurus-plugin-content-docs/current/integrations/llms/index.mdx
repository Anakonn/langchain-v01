---
keywords:
- compatibility
sidebar_class_name: hidden
sidebar_position: 1
translated: true
---

# LLMs

## 기능 (네이티브 지원)

모든 LLM은 Runnable 인터페이스를 구현하며, 이는 모든 메서드의 기본 구현을 포함합니다. 예를 들어 `ainvoke`, `batch`, `abatch`, `stream`, `astream` 등이 있습니다. 이는 모든 LLM이 기본적으로 비동기, 스트리밍 및 배치를 지원하도록 하며, 기본 구현은 아래와 같습니다:
- *비동기* 지원은 asyncio의 기본 스레드 풀 실행자에서 해당 동기 메서드를 호출하는 것으로 기본 설정됩니다. 이를 통해 LLM이 실행되는 동안 애플리케이션의 다른 비동기 함수가 진행될 수 있도록 이 호출을 백그라운드 스레드로 이동시킵니다.
- *스트리밍* 지원은 단일 값, 즉 기본 LLM 제공자가 반환한 최종 결과의 `Iterator` (비동기 스트리밍의 경우 `AsyncIterator`)를 반환하는 것으로 기본 설정됩니다. 이는 토큰별 스트리밍을 제공하지 않지만, 토큰의 반복자를 기대하는 코드가 모든 LLM 통합에서 작동할 수 있도록 합니다.
- *배치* 지원은 입력마다 스레드 풀 실행자(동기 배치의 경우)를 사용하거나 `asyncio.gather`(비동기 배치의 경우)를 사용하여 병렬로 기본 LLM을 호출하는 것으로 기본 설정됩니다. 동시성은 `RunnableConfig`의 `max_concurrency` 키로 제어할 수 있습니다.

각 LLM 통합은 비동기, 스트리밍 또는 배치에 대해 네이티브 구현을 선택적으로 제공할 수 있으며, 이를 지원하는 제공자의 경우 더 효율적일 수 있습니다. 표는 각 통합에 대해 네이티브 지원 기능이 구현된 항목을 보여줍니다.

Model|Invoke|Async invoke|Stream|Async stream|Batch|Async batch
:-|:-:|:-:|:-:|:-:|:-:|:-:
AI21|✅|❌|❌|❌|❌|❌
AlephAlpha|✅|❌|❌|❌|❌|❌
AmazonAPIGateway|✅|❌|❌|❌|❌|❌
Anthropic|✅|✅|✅|✅|❌|❌
Anyscale|✅|✅|✅|✅|✅|✅
Aphrodite|✅|❌|❌|❌|✅|❌
Arcee|✅|❌|❌|❌|❌|❌
Aviary|✅|❌|❌|❌|❌|❌
AzureMLOnlineEndpoint|✅|❌|❌|❌|✅|❌
AzureOpenAI|✅|✅|✅|✅|✅|✅
BaichuanLLM|✅|❌|❌|❌|❌|❌
Banana|✅|❌|❌|❌|❌|❌
Baseten|✅|❌|❌|❌|❌|❌
Beam|✅|❌|❌|❌|❌|❌
Bedrock|✅|✅|✅|✅|❌|❌
CTransformers|✅|✅|❌|❌|❌|❌
CTranslate2|✅|❌|❌|❌|✅|❌
CerebriumAI|✅|❌|❌|❌|❌|❌
ChatGLM|✅|❌|❌|❌|❌|❌
Clarifai|✅|❌|❌|❌|❌|❌
Cohere|✅|✅|❌|❌|❌|❌
Databricks|✅|❌|❌|❌|❌|❌
DeepInfra|✅|✅|✅|✅|❌|❌
DeepSparse|✅|✅|✅|✅|❌|❌
EdenAI|✅|✅|❌|❌|❌|❌
Fireworks|✅|✅|✅|✅|✅|✅
ForefrontAI|✅|❌|❌|❌|❌|❌
Friendli|✅|✅|✅|✅|❌|❌
GPT4All|✅|❌|❌|❌|❌|❌
GigaChat|✅|✅|✅|✅|✅|✅
GooglePalm|✅|❌|✅|❌|✅|❌
GooseAI|✅|❌|❌|❌|❌|❌
GradientLLM|✅|✅|❌|❌|✅|✅
HuggingFaceEndpoint|✅|✅|✅|✅|❌|❌
HuggingFaceHub|✅|❌|❌|❌|❌|❌
HuggingFacePipeline|✅|❌|❌|❌|✅|❌
HuggingFaceTextGenInference|✅|✅|✅|✅|❌|❌
HumanInputLLM|✅|❌|❌|❌|❌|❌
IpexLLM|✅|❌|❌|❌|❌|❌
JavelinAIGateway|✅|✅|❌|❌|❌|❌
KoboldApiLLM|✅|❌|❌|❌|❌|❌
Konko|✅|✅|❌|❌|❌|❌
LlamaCpp|✅|❌|✅|❌|❌|❌
Llamafile|✅|❌|✅|❌|❌|❌
MLXPipeline|✅|❌|✅|❌|❌|❌
ManifestWrapper|✅|❌|❌|❌|❌|❌
Minimax|✅|❌|❌|❌|❌|❌
Mlflow|✅|❌|❌|❌|❌|❌
MlflowAIGateway|✅|❌|❌|❌|❌|❌
Modal|✅|❌|❌|❌|❌|❌
MosaicML|✅|❌|❌|❌|❌|❌
NIBittensorLLM|✅|❌|❌|❌|❌|❌
NLPCloud|✅|❌|❌|❌|❌|❌
Nebula|✅|❌|❌|❌|❌|❌
OCIGenAI|✅|❌|❌|❌|❌|❌
OCIModelDeploymentTGI|✅|❌|❌|❌|❌|❌
OCIModelDeploymentVLLM|✅|❌|❌|❌|❌|❌
OctoAIEndpoint|✅|✅|✅|✅|✅|✅
Ollama|✅|❌|❌|❌|❌|❌
OpaquePrompts|✅|❌|❌|❌|❌|❌
OpenAI|✅|✅|✅|✅|✅|✅
OpenLLM|✅|✅|❌|❌|❌|❌
OpenLM|✅|✅|✅|✅|✅|✅
PaiEasEndpoint|✅|❌|✅|❌|❌|❌
Petals|✅|❌|❌|❌|❌|❌
PipelineAI|✅|❌|❌|❌|❌|❌
Predibase|✅|❌|❌|❌|❌|❌
PredictionGuard|✅|❌|❌|❌|❌|❌
PromptLayerOpenAI|✅|❌|❌|❌|❌|❌
QianfanLLMEndpoint|✅|✅|✅|✅|❌|❌
RWKV|✅|❌|❌|❌|❌|❌
Replicate|✅|❌|✅|❌|❌|❌
SagemakerEndpoint|✅|❌|❌|❌|❌|❌
SambaStudio|✅|❌|✅|❌|❌|❌
Sambaverse|✅|❌|✅|❌|❌|❌
SelfHostedHuggingFaceLLM|✅|❌|❌|❌|❌|❌
SelfHostedPipeline|✅|❌|❌|❌|❌|❌
SparkLLM|✅|❌|✅|❌|❌|❌
StochasticAI|✅|❌|❌|❌|❌|❌
TextGen|✅|❌|❌|❌|❌|❌
TitanTakeoff|✅|❌|✅|❌|❌|❌
TitanTakeoffPro|✅|❌|✅|❌|❌|❌
Together|✅|✅|❌|❌|❌|❌
Tongyi|✅|✅|✅|✅|✅|✅
VLLM|✅|❌|❌|❌|✅|❌
VLLMOpenAI|✅|✅|✅|✅|✅|✅
VertexAI|✅|✅|✅|❌|✅|✅
VertexAIModelGarden|✅|✅|❌|❌|✅|✅
VolcEngineMaasLLM|✅|❌|✅|❌|❌|❌
WatsonxLLM|✅|❌|✅|❌|✅|❌
WeightOnlyQuantPipeline|✅|❌|❌|❌|❌|❌
Writer|✅|❌|❌|❌|❌|❌
Xinference|✅|❌|❌|❌|❌|❌
YandexGPT|✅|✅|❌|❌|❌|❌
Yuan2|✅|❌|❌|❌|❌|❌
