---
translated: true
---

# Oracle AI 벡터 검색: 임베딩 생성

Oracle AI 벡터 검색은 키워드가 아닌 의미에 기반하여 데이터를 쿼리할 수 있는 인공 지능(AI) 워크로드를 위해 설계되었습니다. Oracle AI 벡터 검색의 가장 큰 장점 중 하나는 비정형 데이터에 대한 의미 검색을 하나의 시스템에서 비즈니스 데이터에 대한 관계형 검색과 결합할 수 있다는 것입니다. 이는 강력할 뿐만 아니라 여러 시스템 간의 데이터 분절화 문제를 해결할 수 있어 훨씬 더 효과적입니다.

이 가이드는 Oracle AI 벡터 검색의 임베딩 기능을 사용하여 문서에 대한 임베딩을 생성하는 방법을 보여줍니다.

### 전제 조건

Oracle Python Client 드라이버를 설치하여 Oracle AI 벡터 검색과 함께 Langchain을 사용하세요.

```python
# pip install oracledb
```

### Oracle 데이터베이스에 연결하기

다음 샘플 코드는 Oracle 데이터베이스에 연결하는 방법을 보여줍니다.

```python
import sys

import oracledb

# please update with your username, password, hostname and service_name
username = "<username>"
password = "<password>"
dsn = "<hostname>/<service_name>"

try:
    conn = oracledb.connect(user=username, password=password, dsn=dsn)
    print("Connection successful!")
except Exception as e:
    print("Connection failed!")
    sys.exit(1)
```

임베딩을 위해 사용자는 데이터베이스, ocigenai, huggingface, openai 등의 타사 공급자와 같은 여러 공급자 옵션을 선택할 수 있습니다. 사용자가 타사 공급자를 선택하는 경우 해당 인증 정보로 자격 증명을 생성해야 합니다. 반면에 사용자가 '데이터베이스'를 공급자로 선택하는 경우 임베딩을 위해 Oracle 데이터베이스에 ONNX 모델을 로드해야 합니다.

### ONNX 모델 로드하기

임베딩을 생성하기 위해 Oracle은 사용자가 선택할 수 있는 여러 공급자 옵션을 제공합니다. 사용자는 '데이터베이스' 공급자 또는 OCIGENAI, HuggingFace 등의 일부 타사 공급자를 선택할 수 있습니다.

***참고*** 사용자가 데이터베이스 옵션을 선택하는 경우 Oracle 데이터베이스에 ONNX 모델을 로드해야 합니다. 사용자가 타사 공급자를 선택하여 임베딩을 생성하는 경우에는 Oracle 데이터베이스에 ONNX 모델을 로드할 필요가 없습니다.

ONNX 모델을 사용하는 핵심 이점 중 하나는 사용자가 데이터를 타사에 전송할 필요가 없다는 것입니다. 또한 네트워크 또는 REST API 호출이 필요 없기 때문에 성능이 더 좋을 수 있습니다.

Oracle 데이터베이스에 ONNX 모델을 로드하는 샘플 코드는 다음과 같습니다:

```python
from langchain_community.embeddings.oracleai import OracleEmbeddings

# please update with your related information
# make sure that you have onnx file in the system
onnx_dir = "DEMO_DIR"
onnx_file = "tinybert.onnx"
model_name = "demo_model"

try:
    OracleEmbeddings.load_onnx_model(conn, onnx_dir, onnx_file, model_name)
    print("ONNX model loaded.")
except Exception as e:
    print("ONNX model loading failed!")
    sys.exit(1)
```

### 자격 증명 생성하기

한편, 사용자가 타사 공급자를 사용하여 임베딩을 생성하려는 경우 타사 공급자의 엔드포인트에 액세스할 수 있는 자격 증명을 생성해야 합니다.

***참고:*** 사용자가 '데이터베이스' 공급자를 선택하여 임베딩을 생성하는 경우 자격 증명을 생성할 필요가 없습니다. 사용자가 타사 공급자를 선택하는 경우 사용하려는 타사 공급자에 대한 자격 증명을 생성해야 합니다.

다음은 샘플 예제입니다:

```python
try:
    cursor = conn.cursor()
    cursor.execute(
        """
       declare
           jo json_object_t;
       begin
           -- HuggingFace
           dbms_vector_chain.drop_credential(credential_name  => 'HF_CRED');
           jo := json_object_t();
           jo.put('access_token', '<access_token>');
           dbms_vector_chain.create_credential(
               credential_name   =>  'HF_CRED',
               params            => json(jo.to_string));

           -- OCIGENAI
           dbms_vector_chain.drop_credential(credential_name  => 'OCI_CRED');
           jo := json_object_t();
           jo.put('user_ocid','<user_ocid>');
           jo.put('tenancy_ocid','<tenancy_ocid>');
           jo.put('compartment_ocid','<compartment_ocid>');
           jo.put('private_key','<private_key>');
           jo.put('fingerprint','<fingerprint>');
           dbms_vector_chain.create_credential(
               credential_name   => 'OCI_CRED',
               params            => json(jo.to_string));
       end;
       """
    )
    cursor.close()
    print("Credentials created.")
except Exception as ex:
    cursor.close()
    raise
```

### 임베딩 생성하기

Oracle AI 벡터 검색은 임베딩을 생성하는 여러 가지 방법을 제공합니다. 사용자는 Oracle 데이터베이스에 ONNX 임베딩 모델을 로드하고 이를 사용하여 임베딩을 생성하거나 일부 타사 API 엔드포인트를 사용하여 임베딩을 생성할 수 있습니다. 이러한 매개변수에 대한 전체 정보는 Oracle AI 벡터 검색 가이드북을 참조하세요.

***참고:*** 사용자가 '데이터베이스' 공급자(ONNX 모델 사용)가 아닌 일부 타사 임베딩 생성 공급자를 사용하려는 경우 프록시를 설정해야 할 수 있습니다.

```python
# proxy to be used when we instantiate summary and embedder object
proxy = "<proxy>"
```

다음 샘플 코드는 임베딩을 생성하는 방법을 보여줍니다:

```python
from langchain_community.embeddings.oracleai import OracleEmbeddings
from langchain_core.documents import Document

"""
# using ocigenai
embedder_params = {
    "provider": "ocigenai",
    "credential_name": "OCI_CRED",
    "url": "https://inference.generativeai.us-chicago-1.oci.oraclecloud.com/20231130/actions/embedText",
    "model": "cohere.embed-english-light-v3.0",
}

# using huggingface
embedder_params = {
    "provider": "huggingface",
    "credential_name": "HF_CRED",
    "url": "https://api-inference.huggingface.co/pipeline/feature-extraction/",
    "model": "sentence-transformers/all-MiniLM-L6-v2",
    "wait_for_model": "true"
}
"""

# using ONNX model loaded to Oracle Database
embedder_params = {"provider": "database", "model": "demo_model"}

# Remove proxy if not required
embedder = OracleEmbeddings(conn=conn, params=embedder_params, proxy=proxy)
embed = embedder.embed_query("Hello World!")

""" verify """
print(f"Embedding generated by OracleEmbeddings: {embed}")
```

### 엔드 투 엔드 데모

Oracle AI 벡터 검색을 사용하여 엔드 투 엔드 RAG 파이프라인을 구축하는 방법은 [Oracle AI 벡터 검색 엔드 투 엔드 데모 가이드](https://github.com/langchain-ai/langchain/tree/master/cookbook/oracleai_demo.md)를 참조하세요.
