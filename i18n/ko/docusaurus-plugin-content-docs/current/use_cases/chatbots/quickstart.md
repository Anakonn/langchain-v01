---
sidebar_position: 0
translated: true
---

# ë¹ ë¥¸ ì‹œì‘

[![](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/langchain-ai/langchain/blob/master/docs/docs/use_cases/chatbots.ipynb)

## ê°œìš”

LLM ê¸°ë°˜ ì±—ë´‡ì„ ì„¤ê³„í•˜ê³  êµ¬í˜„í•˜ëŠ” ë°©ë²•ì— ëŒ€í•œ ì˜ˆì œë¥¼ ì‚´í´ë³´ê² ìŠµë‹ˆë‹¤. ì—¬ê¸°ì—ì„œ ë‹¤ë£° ì£¼ìš” êµ¬ì„± ìš”ì†ŒëŠ” ë‹¤ìŒê³¼ ê°™ìŠµë‹ˆë‹¤:

- `ì±„íŒ… ëª¨ë¸(Chat Models)`: ì±—ë´‡ ì¸í„°í˜ì´ìŠ¤ëŠ” ì›ì‹œ í…ìŠ¤íŠ¸ë³´ë‹¤ëŠ” ë©”ì‹œì§€ ê¸°ë°˜ì´ê¸° ë•Œë¬¸ì— í…ìŠ¤íŠ¸ LLMë³´ë‹¤ëŠ” ì±„íŒ… ëª¨ë¸ì— ë” ì í•©í•©ë‹ˆë‹¤. [ì—¬ê¸°](https://docs.langchain.com/docs/integrations/chat)ì—ì„œ ì±„íŒ… ëª¨ë¸ í†µí•© ëª©ë¡ì„ í™•ì¸í•˜ê³ , LangChainì˜ ì±„íŒ… ëª¨ë¸ ì¸í„°í˜ì´ìŠ¤ì— ëŒ€í•œ ë¬¸ì„œëŠ” [ì—¬ê¸°](https://docs.langchain.com/docs/modules/model_io/chat)ì—ì„œ í™•ì¸í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤. `LLMs`(ìì„¸í•œ ë‚´ìš©ì€ [ì—¬ê¸°](https://docs.langchain.com/docs/modules/model_io/llms) ì°¸ì¡°)ë¥¼ ì±—ë´‡ì— ì‚¬ìš©í•  ìˆ˜ë„ ìˆì§€ë§Œ, ì±„íŒ… ëª¨ë¸ì€ ë” ëŒ€í™”í˜• í†¤ì„ ê°€ì§€ê³  ìˆìœ¼ë©° ë©”ì‹œì§€ ì¸í„°í˜ì´ìŠ¤ë¥¼ ë„¤ì´í‹°ë¸Œë¡œ ì§€ì›í•©ë‹ˆë‹¤.
- `í”„ë¡¬í”„íŠ¸ í…œí”Œë¦¿(Prompt Templates)`: ê¸°ë³¸ ë©”ì‹œì§€, ì‚¬ìš©ì ì…ë ¥, ì±„íŒ… ê¸°ë¡ ë° (ì„ íƒì ìœ¼ë¡œ) ì¶”ê°€ ê²€ìƒ‰ëœ ì»¨í…ìŠ¤íŠ¸ë¥¼ ê²°í•©í•˜ëŠ” í”„ë¡¬í”„íŠ¸ë¥¼ êµ¬ì„±í•˜ëŠ” í”„ë¡œì„¸ìŠ¤ë¥¼ ê°„ì†Œí™”í•©ë‹ˆë‹¤.
- `ì±„íŒ… ê¸°ë¡(Chat History)`: ì±—ë´‡ì´ ê³¼ê±° ìƒí˜¸ì‘ìš©ì„ "ê¸°ì–µ"í•˜ê³  í›„ì† ì§ˆë¬¸ì— ì‘ë‹µí•  ë•Œ ì´ë¥¼ ê³ ë ¤í•  ìˆ˜ ìˆë„ë¡ í•©ë‹ˆë‹¤. ìì„¸í•œ ë‚´ìš©ì€ [ì—¬ê¸°](https://docs.langchain.com/docs/modules/memory/chat_messages/)ë¥¼ ì°¸ì¡°í•˜ì„¸ìš”.
- `ê²€ìƒ‰ê¸°(Retrievers)`(ì„ íƒ ì‚¬í•­): ë„ë©”ì¸ íŠ¹í™”, ìµœì‹  ì§€ì‹ì„ ì»¨í…ìŠ¤íŠ¸ë¡œ ì‚¬ìš©í•˜ì—¬ ì‘ë‹µì„ ê°•í™”í•  ìˆ˜ ìˆëŠ” ì±—ë´‡ì„ êµ¬ì¶•í•˜ë ¤ëŠ” ê²½ìš° ìœ ìš©í•©ë‹ˆë‹¤. ê²€ìƒ‰ ì‹œìŠ¤í…œì— ëŒ€í•œ ìì„¸í•œ ë¬¸ì„œëŠ” [ì—¬ê¸°](https://docs.langchain.com/docs/modules/data_connection/retrievers)ì—ì„œ í™•ì¸í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.

ìœ„ì˜ êµ¬ì„± ìš”ì†Œë¥¼ ê²°í•©í•˜ì—¬ ê°•ë ¥í•œ ëŒ€í™”í˜• ì±—ë´‡ì„ ë§Œë“œëŠ” ë°©ë²•ì„ ë‹¤ë£¨ê² ìŠµë‹ˆë‹¤.

## ë¹ ë¥¸ ì‹œì‘

ë¨¼ì €, ëª‡ ê°€ì§€ ì¢…ì†ì„±ì„ ì„¤ì¹˜í•˜ê³  í•„ìš”í•œ ìê²© ì¦ëª…ì„ ì„¤ì •í•´ ë³´ê² ìŠµë‹ˆë‹¤:

```python
%pip install --upgrade --quiet langchain langchain-openai langchain-chroma

# í™˜ê²½ ë³€ìˆ˜ OPENAI_API_KEY ì„¤ì • ë˜ëŠ” .env íŒŒì¼ì—ì„œ ë¡œë“œ:

import dotenv

dotenv.load_dotenv()
```

```output
[33mWARNING: You are using pip version 22.0.4; however, version 23.3.2 is available.
You should consider upgrading via the '/Users/jacoblee/.pyenv/versions/3.10.5/bin/python -m pip install --upgrade pip' command.[0m[33m
[0mNote: you may need to restart the kernel to use updated packages.
```

```output
True
```

ì±—ë´‡ì˜ ë‘ë‡Œ ì—­í• ì„ í•  ì±„íŒ… ëª¨ë¸ì„ ì´ˆê¸°í™”í•´ ë³´ê² ìŠµë‹ˆë‹¤:

```python
from langchain_openai import ChatOpenAI

chat = ChatOpenAI(model="gpt-3.5-turbo-1106", temperature=0.2)
```

ì±—ë´‡ ëª¨ë¸ì„ í˜¸ì¶œí•˜ë©´ ì¶œë ¥ì€ `AIMessage`ê°€ ë©ë‹ˆë‹¤:

```python
from langchain_core.messages import HumanMessage

chat.invoke(
    [
        HumanMessage(
            content="Translate this sentence from English to French: I love programming."
        )
    ]
)
```

```output
AIMessage(content="J'adore programmer.")
```

ëª¨ë¸ ìì²´ëŠ” ìƒíƒœì˜ ê°œë…ì´ ì—†ìŠµë‹ˆë‹¤. ì˜ˆë¥¼ ë“¤ì–´, í›„ì† ì§ˆë¬¸ì„ í•˜ë©´:

```python
chat.invoke([HumanMessage(content="What did you just say?")])
```

```output
AIMessage(content='I said, "What did you just say?"')
```

ì´ì „ ëŒ€í™” í„´ì„ ì»¨í…ìŠ¤íŠ¸ë¡œ ì‚¬ìš©í•˜ì§€ ì•Šê¸° ë•Œë¬¸ì— ì§ˆë¬¸ì— ì œëŒ€ë¡œ ë‹µí•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.

ì´ë¥¼ í•´ê²°í•˜ê¸° ìœ„í•´ ì „ì²´ ëŒ€í™” ê¸°ë¡ì„ ëª¨ë¸ì— ì „ë‹¬í•´ì•¼ í•©ë‹ˆë‹¤. ë‹¤ìŒê³¼ ê°™ì´ í•´ë³´ê² ìŠµë‹ˆë‹¤:

```python
from langchain_core.messages import AIMessage

chat.invoke(
    [
        HumanMessage(
            content="Translate this sentence from English to French: I love programming."
        ),
        AIMessage(content="J'adore la programmation."),
        HumanMessage(content="What did you just say?"),
    ]
)
```

```output
AIMessage(content='I said "J\'adore la programmation," which means "I love programming" in French.')
```

ì´ì œ ì¢‹ì€ ì‘ë‹µì„ ì–»ì„ ìˆ˜ ìˆìŒì„ ì•Œ ìˆ˜ ìˆìŠµë‹ˆë‹¤!

ì´ê²ƒì´ ì±—ë´‡ì˜ ëŒ€í™”í˜• ìƒí˜¸ì‘ìš© ëŠ¥ë ¥ì„ ë’·ë°›ì¹¨í•˜ëŠ” ê¸°ë³¸ ì•„ì´ë””ì–´ì…ë‹ˆë‹¤.

## í”„ë¡¬í”„íŠ¸ í…œí”Œë¦¿

í”„ë¡¬í”„íŠ¸ í…œí”Œë¦¿ì„ ì •ì˜í•˜ì—¬ í¬ë§·íŒ…ì„ ì¢€ ë” ì‰½ê²Œ ë§Œë“¤ ìˆ˜ ìˆìŠµë‹ˆë‹¤. ëª¨ë¸ì— íŒŒì´í•‘í•˜ì—¬ ì²´ì¸ì„ ë§Œë“¤ ìˆ˜ ìˆìŠµë‹ˆë‹¤:

```python
from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder

prompt = ChatPromptTemplate.from_messages(
    [
        (
            "system",
            "You are a helpful assistant. Answer all questions to the best of your ability.",
        ),
        MessagesPlaceholder(variable_name="messages"),
    ]
)

chain = prompt | chat
```

ìœ„ì˜ `MessagesPlaceholder`ëŠ” ì²´ì¸ì˜ ì…ë ¥ìœ¼ë¡œ ì „ë‹¬ëœ ì±„íŒ… ë©”ì‹œì§€ë¥¼ `chat_history`ë¡œ í”„ë¡¬í”„íŠ¸ì— ì§ì ‘ ì‚½ì…í•©ë‹ˆë‹¤. ê·¸ëŸ° ë‹¤ìŒ ë‹¤ìŒê³¼ ê°™ì´ ì²´ì¸ì„ í˜¸ì¶œí•  ìˆ˜ ìˆìŠµë‹ˆë‹¤:

```python
chain.invoke(
    {
        "messages": [
            HumanMessage(
                content="Translate this sentence from English to French: I love programming."
            ),
            AIMessage(content="J'adore la programmation."),
            HumanMessage(content="What did you just say?"),
        ],
    }
)
```

```output
AIMessage(content='I said "J\'adore la programmation," which means "I love programming" in French.')
```

## ë©”ì‹œì§€ ê¸°ë¡

ì±„íŒ… ê¸°ë¡ì„ ê´€ë¦¬í•˜ê¸° ìœ„í•œ ì§€ë¦„ê¸¸ë¡œ [`MessageHistory`](/docs/modules/memory/chat_messages/) í´ë˜ìŠ¤ë¥¼ ì‚¬ìš©í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤. ì´ í´ë˜ìŠ¤ëŠ” ì±„íŒ… ë©”ì‹œì§€ë¥¼ ì €ì¥í•˜ê³  ë¡œë“œí•˜ëŠ” ì—­í• ì„ í•©ë‹ˆë‹¤. ë‹¤ì–‘í•œ ë°ì´í„°ë² ì´ìŠ¤ì— ë©”ì‹œì§€ë¥¼ ì§€ì†ì‹œí‚¤ëŠ” ë§ì€ ë‚´ì¥ ë©”ì‹œì§€ ê¸°ë¡ í†µí•©ì´ ìˆì§€ë§Œ, ì´ ë¹ ë¥¸ ì‹œì‘ì—ì„œëŠ” `ChatMessageHistory`ë¼ëŠ” ë©”ëª¨ë¦¬ ë‚´ ë°ëª¨ ë©”ì‹œì§€ ê¸°ë¡ì„ ì‚¬ìš©í•  ê²ƒì…ë‹ˆë‹¤.

ì§ì ‘ ì‚¬ìš©í•˜ëŠ” ì˜ˆì œì…ë‹ˆë‹¤:

```python
from langchain.memory import ChatMessageHistory

demo_ephemeral_chat_history = ChatMessageHistory()

demo_ephemeral_chat_history.add_user_message("hi!")

demo_ephemeral_chat_history.add_ai_message("whats up?")

demo_ephemeral_chat_history.messages
```

```output
[HumanMessage(content='hi!'), AIMessage(content='whats up?')]
```

ì €ì¥ëœ ë©”ì‹œì§€ë¥¼ ì²´ì¸ì˜ ë§¤ê°œë³€ìˆ˜ë¡œ ì§ì ‘ ì „ë‹¬í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤:

```python
demo_ephemeral_chat_history.add_user_message(
    "Translate this sentence from English to French: I love programming."
)

response = chain.invoke({"messages": demo_ephemeral_chat_history.messages})

response
```

```output
AIMessage(content='The translation of "I love programming" in French is "J\'adore la programmation."')
```

```python
demo_ephemeral_chat_history.add_ai_message(response)

demo_ephemeral_chat_history.add_user_message("What did you just say?")

chain.invoke({"messages": demo_ephemeral_chat_history.messages})
```

```output
AIMessage(content='I said "J\'adore la programmation," which is the French translation for "I love programming."')
```

ì´ì œ ê¸°ë³¸ ì±—ë´‡ì„ ê°–ì¶”ê²Œ ë˜ì—ˆìŠµë‹ˆë‹¤!

ì´ ì²´ì¸ì€ ëª¨ë¸ì˜ ë‚´ë¶€ ì§€ì‹ë§Œìœ¼ë¡œë„ ìœ ìš©í•œ ì±—ë´‡ìœ¼ë¡œ ê¸°ëŠ¥í•  ìˆ˜ ìˆì§€ë§Œ, ë„ë©”ì¸ íŠ¹í™” ì§€ì‹ì„ ë°”íƒ•ìœ¼ë¡œ `ê²€ìƒ‰ ì¦ê°• ìƒì„±`(retrieval-augmented generation, RAG) í˜•íƒœë¥¼ ë„ì…í•˜ë©´ ì±—ë´‡ì„ ë”ìš± ì§‘ì¤‘ì ìœ¼ë¡œ ë§Œë“¤ ìˆ˜ ìˆìŠµë‹ˆë‹¤. ë‹¤ìŒìœ¼ë¡œ ì´ë¥¼ ë‹¤ë£¨ê² ìŠµë‹ˆë‹¤.

## Retrievers

ì±—ë´‡ì— ë„ë©”ì¸ íŠ¹í™” ì§€ì‹ì„ ì œê³µí•˜ê¸° ìœ„í•´ [`ê²€ìƒ‰ê¸°`](/docs/modules/data_connection/retrievers/)ë¥¼ ì„¤ì •í•˜ê³  ì‚¬ìš©í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤. ì´ë¥¼ ë³´ì—¬ì£¼ê¸° ìœ„í•´ ìœ„ì—ì„œ ë§Œë“  ê°„ë‹¨í•œ ì±—ë´‡ì„ í™•ì¥í•˜ì—¬ LangSmithì— ê´€í•œ ì§ˆë¬¸ì— ë‹µí•  ìˆ˜ ìˆë„ë¡ í•´ë³´ê² ìŠµë‹ˆë‹¤.

[LangSmith ë¬¸ì„œ](https://docs.smith.langchain.com/overview)ë¥¼ ì†ŒìŠ¤ ìë£Œë¡œ ì‚¬ìš©í•˜ê³ , ë‚˜ì¤‘ì— ê²€ìƒ‰í•  ìˆ˜ ìˆë„ë¡ ë²¡í„°ìŠ¤í† ì–´ì— ì €ì¥í•˜ê² ìŠµë‹ˆë‹¤. ì´ ì˜ˆì œì—ì„œëŠ” ë°ì´í„° ì†ŒìŠ¤ë¥¼ íŒŒì‹±í•˜ê³  ì €ì¥í•˜ëŠ” íŠ¹ì • ì„¸ë¶€ ì‚¬í•­ì„ ìƒëµí•  ê²ƒì…ë‹ˆë‹¤. ê²€ìƒ‰ ì‹œìŠ¤í…œì„ ë§Œë“œëŠ” ë°©ë²•ì— ëŒ€í•œ ìì„¸í•œ ë¬¸ì„œëŠ” [ì—¬ê¸°](https://docs.langchain.com/docs/use_cases/question_answering/)ì—ì„œ í™•ì¸í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.

ê²€ìƒ‰ê¸°ë¥¼ ì„¤ì •í•´ ë³´ê² ìŠµë‹ˆë‹¤. ë¨¼ì € í•„ìš”í•œ ì¢…ì†ì„±ì„ ì„¤ì¹˜í•©ë‹ˆë‹¤:

```python
%pip install --upgrade --quiet langchain-chroma beautifulsoup4
```

```output
[33mWARNING: You are using pip version 22.0.4; however, version 23.3.2 is available.
You should consider upgrading via the '/Users/jacoblee/.pyenv/versions/3.10.5/bin/python -m pip install --upgrade pip' command.[0m[33m
[0mNote: you may need to restart the kernel to use updated packages.
```

ë‹¤ìŒìœ¼ë¡œ, ë¬¸ì„œ ë¡œë”ë¥¼ ì‚¬ìš©í•˜ì—¬ ì›¹í˜ì´ì§€ì—ì„œ ë°ì´í„°ë¥¼ ê°€ì ¸ì˜µë‹ˆë‹¤:

```python
from langchain_community.document_loaders import WebBaseLoader

loader = WebBaseLoader("https://docs.smith.langchain.com/overview")
data = loader.load()
```

ê·¸ëŸ° ë‹¤ìŒ ë°ì´í„°ë¥¼ LLMì˜ ì»¨í…ìŠ¤íŠ¸ ìœˆë„ìš°ì—ì„œ ì²˜ë¦¬í•  ìˆ˜ ìˆëŠ” ì‘ì€ ì²­í¬ë¡œ ë¶„í• í•˜ê³  ë²¡í„° ë°ì´í„°ë² ì´ìŠ¤ì— ì €ì¥í•©ë‹ˆë‹¤:

```python
from langchain_text_splitters import RecursiveCharacterTextSplitter

text_splitter = RecursiveCharacterTextSplitter(chunk_size=500, chunk_overlap=0)
all_splits = text_splitter.split_documents(data)
```

ê·¸ëŸ° ë‹¤ìŒ ì´ëŸ¬í•œ ì²­í¬ë¥¼ ì„ë² ë”©í•˜ê³  ë²¡í„° ë°ì´í„°ë² ì´ìŠ¤ì— ì €ì¥í•©ë‹ˆë‹¤:

```python
from langchain_chroma import Chroma
from langchain_openai import OpenAIEmbeddings

vectorstore = Chroma.from_documents(documents=all_splits, embedding=OpenAIEmbeddings())
```

ë§ˆì§€ë§‰ìœ¼ë¡œ, ì´ˆê¸°í™”ëœ ë²¡í„°ìŠ¤í† ì–´ì—ì„œ ê²€ìƒ‰ê¸°ë¥¼ ìƒì„±í•©ë‹ˆë‹¤:

```python
# këŠ” ê²€ìƒ‰í•  ì²­í¬ì˜ ìˆ˜ì…ë‹ˆë‹¤.

retriever = vectorstore.as_retriever(k=4)

docs = retriever.invoke("how can langsmith help with testing?")

docs
```

```output
[Document(page_content='You can also quickly edit examples and add them to datasets to expand the surface area of your evaluation sets or to fine-tune a model for improved quality or reduced costs.Monitoring\u200bAfter all this, your app might finally ready to go in production. LangSmith can also be used to monitor your application in much the same way that you used for debugging. You can log all traces, visualize latency and token usage statistics, and troubleshoot specific issues as they arise. Each run can also be', metadata={'description': 'Building reliable LLM applications can be challenging. LangChain simplifies the initial setup, but there is still work needed to bring the performance of prompts, chains and agents up the level where they are reliable enough to be used in production.', 'language': 'en', 'source': 'https://docs.smith.langchain.com/overview', 'title': 'LangSmith Overview and User Guide | ğŸ¦œï¸ğŸ› ï¸ LangSmith'}),
 Document(page_content='inputs, and see what happens. At some point though, our application is performing\nwell and we want to be more rigorous about testing changes. We can use a dataset\nthat weâ€™ve constructed along the way (see above). Alternatively, we could spend some\ntime constructing a small dataset by hand. For these situations, LangSmith simplifies', metadata={'description': 'Building reliable LLM applications can be challenging. LangChain simplifies the initial setup, but there is still work needed to bring the performance of prompts, chains and agents up the level where they are reliable enough to be used in production.', 'language': 'en', 'source': 'https://docs.smith.langchain.com/overview', 'title': 'LangSmith Overview and User Guide | ğŸ¦œï¸ğŸ› ï¸ LangSmith'}),
 Document(page_content='Skip to main contentğŸ¦œï¸ğŸ› ï¸ LangSmith DocsPython DocsJS/TS DocsSearchGo to AppLangSmithOverviewTracingTesting & EvaluationOrganizationsHubLangSmith CookbookOverviewOn this pageLangSmith Overview and User GuideBuilding reliable LLM applications can be challenging. LangChain simplifies the initial setup, but there is still work needed to bring the performance of prompts, chains and agents up the level where they are reliable enough to be used in production.Over the past two months, we at LangChain', metadata={'description': 'Building reliable LLM applications can be challenging. LangChain simplifies the initial setup, but there is still work needed to bring the performance of prompts, chains and agents up the level where they are reliable enough to be used in production.', 'language': 'en', 'source': 'https://docs.smith.langchain.com/overview', 'title': 'LangSmith Overview and User Guide | ğŸ¦œï¸ğŸ› ï¸ LangSmith'}),
 Document(page_content='have been building and using LangSmith with the goal of bridging this gap. This is our tactical user guide to outline effective ways to use LangSmith and maximize its benefits.On by default\u200bAt LangChain, all of us have LangSmithâ€™s tracing running in the background by default. On the Python side, this is achieved by setting environment variables, which we establish whenever we launch a virtual environment or open our bash shell and leave them set. The same principle applies to most JavaScript', metadata={'description': 'Building reliable LLM applications can be challenging. LangChain simplifies the initial setup, but there is still work needed to bring the performance of prompts, chains and agents up the level where they are reliable enough to be used in production.', 'language': 'en', 'source': 'https://docs.smith.langchain.com/overview', 'title': 'LangSmith Overview and User Guide | ğŸ¦œï¸ğŸ› ï¸ LangSmith'})]
```

ìœ„ì—ì„œ ê²€ìƒ‰ê¸°ë¥¼ í˜¸ì¶œí•˜ë©´ LangSmith ë¬¸ì„œ ì¤‘ì—ì„œ í…ŒìŠ¤íŠ¸ì™€ ê´€ë ¨ëœ ì •ë³´ë¥¼ í¬í•¨í•˜ëŠ” ë¶€ë¶„ì„ ê²€ìƒ‰í•˜ì—¬ ì±—ë´‡ì´ ì§ˆë¬¸ì— ë‹µí•  ë•Œ ì»¨í…ìŠ¤íŠ¸ë¡œ ì‚¬ìš©í•  ìˆ˜ ìˆìŒì„ ì•Œ ìˆ˜ ìˆìŠµë‹ˆë‹¤.

### ë¬¸ì„œ ì²˜ë¦¬

ì´ì „ í”„ë¡¬í”„íŠ¸ë¥¼ ìˆ˜ì •í•˜ì—¬ ì»¨í…ìŠ¤íŠ¸ë¡œ ë¬¸ì„œë¥¼ ë°›ì•„ë“¤ì´ë„ë¡ í•´ë³´ê² ìŠµë‹ˆë‹¤. ëª¨ë“  ì…ë ¥ ë¬¸ì„œë¥¼ í”„ë¡¬í”„íŠ¸ì— "ì±„ì›Œë„£ëŠ”" [`create_stuff_documents_chain`](https://api.python.langchain.com/en/latest/chains/langchain.chains.combine_documents.stuff.create_stuff_documents_chain.html#langchain.chains.combine_documents.stuff.create_stuff_documents_chain) í—¬í¼ í•¨ìˆ˜ë¥¼ ì‚¬ìš©í•˜ê² ìŠµë‹ˆë‹¤. ë˜í•œ, [`ChatPromptTemplate.from_messages`](/docs/modules/model_io/prompts/quick_start#chatprompttemplate) ë©”ì„œë“œë¥¼ ì‚¬ìš©í•˜ì—¬ ëª¨ë¸ì— ì „ë‹¬í•  ë©”ì‹œì§€ ì…ë ¥ì„ í¬ë§·í•˜ê³ , ì±„íŒ… ê¸°ë¡ ë©”ì‹œì§€ê°€ ì§ì ‘ ì‚½ì…ë  [`MessagesPlaceholder`](/docs/modules/model_io/prompts/quick_start#messagesplaceholder)ë¥¼ í¬í•¨í•˜ê² ìŠµë‹ˆë‹¤:

```python
from langchain.chains.combine_documents import create_stuff_documents_chain

chat = ChatOpenAI(model="gpt-3.5-turbo-1106")

question_answering_prompt = ChatPromptTemplate.from_messages(
    [
        (
            "system",
            "Answer the user's questions based on the below context:\n\n{context}",
        ),
        MessagesPlaceholder(variable_name="messages"),
    ]
)

document_chain = create_stuff_documents_chain(chat, question_answering_prompt)
```

ì´ì œ ìœ„ì—ì„œ ê²€ìƒ‰í•œ ì›ì‹œ ë¬¸ì„œì™€ í•¨ê»˜ `document_chain`ì„ í˜¸ì¶œí•  ìˆ˜ ìˆìŠµë‹ˆë‹¤:

```python
from langchain.memory import ChatMessageHistory

demo_ephemeral_chat_history = ChatMessageHistory()

demo_ephemeral_chat_history.add_user_message("how can langsmith help with testing?")

document_chain.invoke(
    {
        "messages": demo_ephemeral_chat_history.messages,
        "context": docs,
    }
)
```

```output
'LangSmith can assist with testing by providing the capability to quickly edit examples and add them to datasets. This allows for the expansion of evaluation sets or fine-tuning of a model for improved quality or reduced costs. Additionally, LangSmith simplifies the construction of small datasets by hand, providing a convenient way to rigorously test changes in the application.'
```

ë©‹ì§‘ë‹ˆë‹¤! ì…ë ¥ ë¬¸ì„œì˜ ì •ë³´ë¥¼ ë°”íƒ•ìœ¼ë¡œ ì‘ë‹µì´ ìƒì„±ë˜ì—ˆìŠµë‹ˆë‹¤.

### retrieval chain ë§Œë“¤ê¸°

ì´ì œ ê²€ìƒ‰ê¸°ë¥¼ ì²´ì¸ì— í†µí•©í•´ ë³´ê² ìŠµë‹ˆë‹¤. ê²€ìƒ‰ê¸°ëŠ” ì‚¬ìš©ìê°€ ë§ˆì§€ë§‰ìœ¼ë¡œ ë³´ë‚¸ ë©”ì‹œì§€ì™€ ê´€ë ¨ëœ ì •ë³´ë¥¼ ê²€ìƒ‰í•´ì•¼ í•˜ë¯€ë¡œ ì´ë¥¼ ì¶”ì¶œí•˜ì—¬ ê´€ë ¨ ë¬¸ì„œë¥¼ ê°€ì ¸ì˜¤ëŠ” ì…ë ¥ìœ¼ë¡œ ì‚¬ìš©í•©ë‹ˆë‹¤. ê²€ìƒ‰í•œ ë¬¸ì„œë¥¼ í˜„ì¬ ì²´ì¸ì— `context`ë¡œ ì¶”ê°€í•˜ê³ , `context`ì™€ ì´ì „ `messages`ë¥¼ ë¬¸ì„œ ì²´ì¸ì— ì „ë‹¬í•˜ì—¬ ìµœì¢… ë‹µë³€ì„ ìƒì„±í•©ë‹ˆë‹¤.

ê° í˜¸ì¶œì—ì„œ ì¤‘ê°„ ë‹¨ê³„ë¥¼ ì „ë‹¬í•˜ê¸° ìœ„í•´ [`RunnablePassthrough.assign()`](/docs/expression_language/primitives/assign) ë©”ì„œë“œë¥¼ ì‚¬ìš©í•©ë‹ˆë‹¤. ë‹¤ìŒì€ ê·¸ ì˜ˆì œì…ë‹ˆë‹¤:

```python
from typing import Dict

from langchain_core.runnables import RunnablePassthrough


def parse_retriever_input(params: Dict):
    return params["messages"][-1].content


retrieval_chain = RunnablePassthrough.assign(
    context=parse_retriever_input | retriever,
).assign(
    answer=document_chain,
)
```

ì´ì œ ì´ `retrieval_chain`ì„ í˜¸ì¶œí•˜ì—¬ ì‘ë‹µì„ ìƒì„±í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤:

```python
response = retrieval_chain.invoke(
    {
        "messages": demo_ephemeral_chat_history.messages,
    }
)

response
```

```output
{'messages': [HumanMessage(content='how can langsmith help with testing?')],
 'context': [Document(page_content='You can also quickly edit examples and add them to datasets to expand the surface area of your evaluation sets or to fine-tune a model for improved quality or reduced costs.Monitoring\u200bAfter all this, your app might finally ready to go in production. LangSmith can also be used to monitor your application in much the same way that you used for debugging. You can log all traces, visualize latency and token usage statistics, and troubleshoot specific issues as they arise. Each run can also be', metadata={'description': 'Building reliable LLM applications can be challenging. LangChain simplifies the initial setup, but there is still work needed to bring the performance of prompts, chains and agents up the level where they are reliable enough to be used in production.', 'language': 'en', 'source': 'https://docs.smith.langchain.com/overview', 'title': 'LangSmith Overview and User Guide | ğŸ¦œï¸ğŸ› ï¸ LangSmith'}),
  Document(page_content='inputs, and see what happens. At some point though, our application is performing\nwell and we want to be more rigorous about testing changes. We can use a dataset\nthat weâ€™ve constructed along the way (see above). Alternatively, we could spend some\ntime constructing a small dataset by hand. For these situations, LangSmith simplifies', metadata={'description': 'Building reliable LLM applications can be challenging. LangChain simplifies the initial setup, but there is still work needed to bring the performance of prompts, chains and agents up the level where they are reliable enough to be used in production.', 'language': 'en', 'source': 'https://docs.smith.langchain.com/overview', 'title': 'LangSmith Overview and User Guide | ğŸ¦œï¸ğŸ› ï¸ LangSmith'}),
  Document(page_content='Skip to main contentğŸ¦œï¸ğŸ› ï¸ LangSmith DocsPython DocsJS/TS DocsSearchGo to AppLangSmithOverviewTracingTesting & EvaluationOrganizationsHubLangSmith CookbookOverviewOn this pageLangSmith Overview and User GuideBuilding reliable LLM applications can be challenging. LangChain simplifies the initial setup, but there is still work needed to bring the performance of prompts, chains and agents up the level where they are reliable enough to be used in production.Over the past two months, we at LangChain', metadata={'description': 'Building reliable LLM applications can be challenging. LangChain simplifies the initial setup, but there is still work needed to bring the performance of prompts, chains and agents up the level where they are reliable enough to be used in production.', 'language': 'en', 'source': 'https://docs.smith.langchain.com/overview', 'title': 'LangSmith Overview and User Guide | ğŸ¦œï¸ğŸ› ï¸ LangSmith'}),
  Document(page_content='have been building and using LangSmith with the goal of bridging this gap. This is our tactical user guide to outline effective ways to use LangSmith and maximize its benefits.On by default\u200bAt LangChain, all of us have LangSmithâ€™s tracing running in the background by default. On the Python side, this is achieved by setting environment variables, which we establish whenever we launch a virtual environment or open our bash shell and leave them set. The same principle applies to most JavaScript', metadata={'description': 'Building reliable LLM applications can be challenging. LangChain simplifies the initial setup, but there is still work needed to bring the performance of prompts, chains and agents up the level where they are reliable enough to be used in production.', 'language': 'en', 'source': 'https://docs.smith.langchain.com/overview', 'title': 'LangSmith Overview and User Guide | ğŸ¦œï¸ğŸ› ï¸ LangSmith'})],
 'answer': 'LangSmith can help with testing in several ways:\n\n1. Dataset Expansion: LangSmith enables quick editing of examples and adding them to datasets, which expands the surface area of evaluation sets. This allows for more comprehensive testing of models and applications.\n\n2. Fine-Tuning Models: LangSmith facilitates the fine-tuning of models for improved quality or reduced costs. This is beneficial for optimizing the performance of models during testing.\n\n3. Monitoring: LangSmith can be used to monitor applications, log traces, visualize latency and token usage statistics, and troubleshoot specific issues as they arise during testing. This monitoring helps in ensuring the reliability and performance of the application during testing phases.\n\nOverall, LangSmith helps in making testing more rigorous and comprehensive, whether by expanding datasets, fine-tuning models, or monitoring application performance.'}
```

ë‹¤ìŒ ë©”ì‹œì§€ë¥¼ ì¶”ê°€í•˜ì—¬ ì±—ë´‡ì´ ëŒ€í™”ë¥¼ ê¸°ì–µí•˜ê³  ê³„ì†í•  ìˆ˜ ìˆë„ë¡ í•´ë³´ê² ìŠµë‹ˆë‹¤:

```python
demo_ephemeral_chat_history.add_ai_message(response["answer"])

demo_ephemeral_chat_history.add_user_message("tell me more about that!")

retrieval_chain.invoke(
    {
        "messages": demo_ephemeral_chat_history.messages,
    },
)
```

```output
{'messages': [HumanMessage(content='how can langsmith help with testing?'),
  AIMessage(content='LangSmith can help with testing in several ways:\n\n1. Dataset Expansion: LangSmith enables quick editing of examples and adding them to datasets, which expands the surface area of evaluation sets. This allows for more comprehensive testing of models and applications.\n\n2. Fine-Tuning Models: LangSmith facilitates the fine-tuning of models for improved quality or reduced costs. This is beneficial for optimizing the performance of models during testing.\n\n3. Monitoring: LangSmith can be used to monitor applications, log traces, visualize latency and token usage statistics, and troubleshoot specific issues as they arise during testing. This monitoring helps in ensuring the reliability and performance of the application during testing phases.\n\nOverall, LangSmith helps in making testing more rigorous and comprehensive, whether by expanding datasets, fine-tuning models, or monitoring application performance.'),
  HumanMessage(content='tell me more about that!')],
 'context': [Document(page_content='however, there is still no complete substitute for human review to get the utmost quality and reliability from your application.', metadata={'description': 'Building reliable LLM applications can be challenging. LangChain simplifies the initial setup, but there is still work needed to bring the performance of prompts, chains and agents up the level where they are reliable enough to be used in production.', 'language': 'en', 'source': 'https://docs.smith.langchain.com/overview', 'title': 'LangSmith Overview and User Guide | ğŸ¦œï¸ğŸ› ï¸ LangSmith'}),
  Document(page_content='You can also quickly edit examples and add them to datasets to expand the surface area of your evaluation sets or to fine-tune a model for improved quality or reduced costs.Monitoring\u200bAfter all this, your app might finally ready to go in production. LangSmith can also be used to monitor your application in much the same way that you used for debugging. You can log all traces, visualize latency and token usage statistics, and troubleshoot specific issues as they arise. Each run can also be', metadata={'description': 'Building reliable LLM applications can be challenging. LangChain simplifies the initial setup, but there is still work needed to bring the performance of prompts, chains and agents up the level where they are reliable enough to be used in production.', 'language': 'en', 'source': 'https://docs.smith.langchain.com/overview', 'title': 'LangSmith Overview and User Guide | ğŸ¦œï¸ğŸ› ï¸ LangSmith'}),
  Document(page_content="against these known issues.Why is this so impactful? When building LLM applications, itâ€™s often common to start without a dataset of any kind. This is part of the power of LLMs! They are amazing zero-shot learners, making it possible to get started as easily as possible. But this can also be a curse -- as you adjust the prompt, you're wandering blind. You donâ€™t have any examples to benchmark your changes against.LangSmith addresses this problem by including an â€œAdd to Datasetâ€ button for each", metadata={'description': 'Building reliable LLM applications can be challenging. LangChain simplifies the initial setup, but there is still work needed to bring the performance of prompts, chains and agents up the level where they are reliable enough to be used in production.', 'language': 'en', 'source': 'https://docs.smith.langchain.com/overview', 'title': 'LangSmith Overview and User Guide | ğŸ¦œï¸ğŸ› ï¸ LangSmith'}),
  Document(page_content='playground. Here, you can modify the prompt and re-run it to observe the resulting changes to the output - as many times as needed!Currently, this feature supports only OpenAI and Anthropic models and works for LLM and Chat Model calls. We plan to extend its functionality to more LLM types, chains, agents, and retrievers in the future.What is the exact sequence of events?\u200bIn complicated chains and agents, it can often be hard to understand what is going on under the hood. What calls are being', metadata={'description': 'Building reliable LLM applications can be challenging. LangChain simplifies the initial setup, but there is still work needed to bring the performance of prompts, chains and agents up the level where they are reliable enough to be used in production.', 'language': 'en', 'source': 'https://docs.smith.langchain.com/overview', 'title': 'LangSmith Overview and User Guide | ğŸ¦œï¸ğŸ› ï¸ LangSmith'})],
 'answer': 'Certainly! LangSmith offers the following capabilities to aid in testing:\n\n1. Dataset Expansion: By allowing quick editing of examples and adding them to datasets, LangSmith enables the expansion of evaluation sets. This is crucial for thorough testing of models and applications, as it broadens the range of scenarios and inputs that can be used to assess performance.\n\n2. Fine-Tuning Models: LangSmith supports the fine-tuning of models to enhance their quality and reduce operational costs. This capability is valuable during testing as it enables the optimization of model performance based on specific testing requirements and objectives.\n\n3. Monitoring: LangSmith provides monitoring features that allow for the logging of traces, visualization of latency and token usage statistics, and troubleshooting of issues as they occur during testing. This real-time monitoring helps in identifying and addressing any issues that may impact the reliability and performance of the application during testing.\n\nBy leveraging these features, LangSmith enhances the testing process by enabling comprehensive dataset expansion, model fine-tuning, and real-time monitoring to ensure the quality and reliability of applications and models.'}
```

ì¢‹ìŠµë‹ˆë‹¤! ì´ì œ ì±—ë´‡ì´ ëŒ€í™” ë°©ì‹ìœ¼ë¡œ ë„ë©”ì¸ íŠ¹í™” ì§ˆë¬¸ì— ë‹µë³€í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.

ì°¸ê³ ë¡œ, ëª¨ë“  ì¤‘ê°„ ë‹¨ê³„ë¥¼ ë°˜í™˜í•˜ì§€ ì•Šìœ¼ë ¤ë©´, ìµœì¢… `.assign()` í˜¸ì¶œ ëŒ€ì‹  ì§ì ‘ ë¬¸ì„œ ì²´ì¸ì— íŒŒì´í”„í•˜ëŠ” ë°©ì‹ìœ¼ë¡œ ê²€ìƒ‰ ì²´ì¸ì„ ì •ì˜í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤:

```python
retrieval_chain_with_only_answer = (
    RunnablePassthrough.assign(
        context=parse_retriever_input | retriever,
    )
    | document_chain
)

retrieval_chain_with_only_answer.invoke(
    {
        "messages": demo_ephemeral_chat_history.messages,
    },
)
```

```output
"LangSmith offers the capability to quickly edit examples and add them to datasets, thereby enhancing the scope of evaluation sets. This feature is particularly valuable for testing as it allows for a more thorough assessment of model performance and application behavior.\n\nFurthermore, LangSmith enables the fine-tuning of models to enhance quality and reduce costs, which can significantly impact testing outcomes. By adjusting and refining models, developers can ensure that they are thoroughly tested and optimized for various scenarios and use cases.\n\nAdditionally, LangSmith provides monitoring functionality, allowing users to log traces, visualize latency and token usage statistics, and troubleshoot specific issues as they encounter them during testing. This real-time monitoring and troubleshooting capability contribute to the overall effectiveness and reliability of the testing process.\n\nIn essence, LangSmith's features are designed to improve the quality and reliability of testing by expanding evaluation sets, fine-tuning models, and providing comprehensive monitoring capabilities. These aspects collectively contribute to a more robust and thorough testing process for applications and models."
```

## ì¿¼ë¦¬ ë³€í™˜

ì—¬ê¸°ì„œ ë‹¤ë£° ë˜ ë‹¤ë¥¸ ìµœì í™”ê°€ ìˆìŠµë‹ˆë‹¤ - ìœ„ì˜ ì˜ˆì—ì„œ í›„ì† ì§ˆë¬¸ì¸ `ê·¸ê²ƒì— ëŒ€í•´ ë” ë§í•´ì¤˜!`ë¥¼ í–ˆì„ ë•Œ, ê²€ìƒ‰ëœ ë¬¸ì„œì—ëŠ” í…ŒìŠ¤íŠ¸ì— ëŒ€í•œ ì •ë³´ê°€ ì§ì ‘ì ìœ¼ë¡œ í¬í•¨ë˜ì§€ ì•Šì•˜ìŒì„ ì•Œ ìˆ˜ ìˆìŠµë‹ˆë‹¤. ì´ëŠ” `ê·¸ê²ƒì— ëŒ€í•´ ë” ë§í•´ì¤˜!`ë¥¼ ê²€ìƒ‰ì–´ë¡œ ê·¸ëŒ€ë¡œ ì „ë‹¬í•˜ê¸° ë•Œë¬¸ì…ë‹ˆë‹¤. ê²€ìƒ‰ ì²´ì¸ì˜ ì¶œë ¥ì€ ì—¬ì „íˆ ê´œì°®ì§€ë§Œ, ë¬¸ì„œ ì²´ì¸ ê²€ìƒ‰ ì²´ì¸ì´ ëŒ€í™” ê¸°ë¡ì„ ë°”íƒ•ìœ¼ë¡œ ë‹µë³€ì„ ìƒì„±í•  ìˆ˜ ìˆê¸° ë•Œë¬¸ì…ë‹ˆë‹¤. ê·¸ëŸ¬ë‚˜ ë” í’ë¶€í•˜ê³  ìœ ìµí•œ ë¬¸ì„œë¥¼ ê²€ìƒ‰í•  ìˆ˜ ìˆì—ˆìŠµë‹ˆë‹¤:

```python
retriever.invoke("how can langsmith help with testing?")
```

```output
[Document(page_content='You can also quickly edit examples and add them to datasets to expand the surface area of your evaluation sets or to fine-tune a model for improved quality or reduced costs.Monitoring\u200bAfter all this, your app might finally ready to go in production. LangSmith can also be used to monitor your application in much the same way that you used for debugging. You can log all traces, visualize latency and token usage statistics, and troubleshoot specific issues as they arise. Each run can also be', metadata={'description': 'Building reliable LLM applications can be challenging. LangChain simplifies the initial setup, but there is still work needed to bring the performance of prompts, chains and agents up the level where they are reliable enough to be used in production.', 'language': 'en', 'source': 'https://docs.smith.langchain.com/overview', 'title': 'LangSmith Overview and User Guide | ğŸ¦œï¸ğŸ› ï¸ LangSmith'}),
 Document(page_content='inputs, and see what happens. At some point though, our application is performing\nwell and we want to be more rigorous about testing changes. We can use a dataset\nthat weâ€™ve constructed along the way (see above). Alternatively, we could spend some\ntime constructing a small dataset by hand. For these situations, LangSmith simplifies', metadata={'description': 'Building reliable LLM applications can be challenging. LangChain simplifies the initial setup, but there is still work needed to bring the performance of prompts, chains and agents up the level where they are reliable enough to be used in production.', 'language': 'en', 'source': 'https://docs.smith.langchain.com/overview', 'title': 'LangSmith Overview and User Guide | ğŸ¦œï¸ğŸ› ï¸ LangSmith'}),
 Document(page_content='Skip to main contentğŸ¦œï¸ğŸ› ï¸ LangSmith DocsPython DocsJS/TS DocsSearchGo to AppLangSmithOverviewTracingTesting & EvaluationOrganizationsHubLangSmith CookbookOverviewOn this pageLangSmith Overview and User GuideBuilding reliable LLM applications can be challenging. LangChain simplifies the initial setup, but there is still work needed to bring the performance of prompts, chains and agents up the level where they are reliable enough to be used in production.Over the past two months, we at LangChain', metadata={'description': 'Building reliable LLM applications can be challenging. LangChain simplifies the initial setup, but there is still work needed to bring the performance of prompts, chains and agents up the level where they are reliable enough to be used in production.', 'language': 'en', 'source': 'https://docs.smith.langchain.com/overview', 'title': 'LangSmith Overview and User Guide | ğŸ¦œï¸ğŸ› ï¸ LangSmith'}),
 Document(page_content='have been building and using LangSmith with the goal of bridging this gap. This is our tactical user guide to outline effective ways to use LangSmith and maximize its benefits.On by default\u200bAt LangChain, all of us have LangSmithâ€™s tracing running in the background by default. On the Python side, this is achieved by setting environment variables, which we establish whenever we launch a virtual environment or open our bash shell and leave them set. The same principle applies to most JavaScript', metadata={'description': 'Building reliable LLM applications can be challenging. LangChain simplifies the initial setup, but there is still work needed to bring the performance of prompts, chains and agents up the level where they are reliable enough to be used in production.', 'language': 'en', 'source': 'https://docs.smith.langchain.com/overview', 'title': 'LangSmith Overview and User Guide | ğŸ¦œï¸ğŸ› ï¸ LangSmith'})]
```

```python
retriever.invoke("tell me more about that!")
```

```output
[Document(page_content='however, there is still no complete substitute for human review to get the utmost quality and reliability from your application.', metadata={'description': 'Building reliable LLM applications can be challenging. LangChain simplifies the initial setup, but there is still work needed to bring the performance of prompts, chains and agents up the level where they are reliable enough to be used in production.', 'language': 'en', 'source': 'https://docs.smith.langchain.com/overview', 'title': 'LangSmith Overview and User Guide | ğŸ¦œï¸ğŸ› ï¸ LangSmith'}),
 Document(page_content='You can also quickly edit examples and add them to datasets to expand the surface area of your evaluation sets or to fine-tune a model for improved quality or reduced costs.Monitoring\u200bAfter all this, your app might finally ready to go in production. LangSmith can also be used to monitor your application in much the same way that you used for debugging. You can log all traces, visualize latency and token usage statistics, and troubleshoot specific issues as they arise. Each run can also be', metadata={'description': 'Building reliable LLM applications can be challenging. LangChain simplifies the initial setup, but there is still work needed to bring the performance of prompts, chains and agents up the level where they are reliable enough to be used in production.', 'language': 'en', 'source': 'https://docs.smith.langchain.com/overview', 'title': 'LangSmith Overview and User Guide | ğŸ¦œï¸ğŸ› ï¸ LangSmith'}),
 Document(page_content="against these known issues.Why is this so impactful? When building LLM applications, itâ€™s often common to start without a dataset of any kind. This is part of the power of LLMs! They are amazing zero-shot learners, making it possible to get started as easily as possible. But this can also be a curse -- as you adjust the prompt, you're wandering blind. You donâ€™t have any examples to benchmark your changes against.LangSmith addresses this problem by including an â€œAdd to Datasetâ€ button for each", metadata={'description': 'Building reliable LLM applications can be challenging. LangChain simplifies the initial setup, but there is still work needed to bring the performance of prompts, chains and agents up the level where they are reliable enough to be used in production.', 'language': 'en', 'source': 'https://docs.smith.langchain.com/overview', 'title': 'LangSmith Overview and User Guide | ğŸ¦œï¸ğŸ› ï¸ LangSmith'}),
 Document(page_content='playground. Here, you can modify the prompt and re-run it to observe the resulting changes to the output - as many times as needed!Currently, this feature supports only OpenAI and Anthropic models and works for LLM and Chat Model calls. We plan to extend its functionality to more LLM types, chains, agents, and retrievers in the future.What is the exact sequence of events?\u200bIn complicated chains and agents, it can often be hard to understand what is going on under the hood. What calls are being', metadata={'description': 'Building reliable LLM applications can be challenging. LangChain simplifies the initial setup, but there is still work needed to bring the performance of prompts, chains and agents up the level where they are reliable enough to be used in production.', 'language': 'en', 'source': 'https://docs.smith.langchain.com/overview', 'title': 'LangSmith Overview and User Guide | ğŸ¦œï¸ğŸ› ï¸ LangSmith'})]
```

ì´ ì¼ë°˜ì ì¸ ë¬¸ì œë¥¼ í•´ê²°í•˜ê¸° ìœ„í•´, ì…ë ¥ì—ì„œ ì°¸ì¡°ë¥¼ ì œê±°í•˜ëŠ” `ì¿¼ë¦¬ ë³€í™˜` ë‹¨ê³„ë¥¼ ì¶”ê°€í•´ ë³´ê² ìŠµë‹ˆë‹¤. ê¸°ì¡´ ê²€ìƒ‰ê¸°ë¥¼ ë‹¤ìŒê³¼ ê°™ì´ ê°ì‹¸ê² ìŠµë‹ˆë‹¤:

```python
from langchain_core.output_parsers import StrOutputParser
from langchain_core.runnables import RunnableBranch

# ë³€í™˜ëœ ê²€ìƒ‰ ì¿¼ë¦¬ë¥¼ ìƒì„±í•˜ê¸° ìœ„í•´ LLMì— ì „ë‹¬í•  í”„ë¡¬í”„íŠ¸ê°€ í•„ìš”í•©ë‹ˆë‹¤.

chat = ChatOpenAI(model="gpt-3.5-turbo-1106", temperature=0.2)

query_transform_prompt = ChatPromptTemplate.from_messages(
    [
        MessagesPlaceholder(variable_name="messages"),
        (
            "user",
            "ìœ„ì˜ ëŒ€í™”ë¥¼ ë°”íƒ•ìœ¼ë¡œ, ëŒ€í™”ì™€ ê´€ë ¨ëœ ì •ë³´ë¥¼ ì–»ê¸° ìœ„í•´ ê²€ìƒ‰í•  ì¿¼ë¦¬ë¥¼ ìƒì„±í•˜ì„¸ìš”. ì¿¼ë¦¬ë§Œ ì‘ë‹µí•˜ê³ , ë‹¤ë¥¸ ê²ƒì€ í•˜ì§€ ë§ˆì„¸ìš”.",
        ),
    ]
)

query_transforming_retriever_chain = RunnableBranch(
    (
        lambda x: len(x.get("messages", [])) == 1,
        # ë©”ì‹œì§€ê°€ í•˜ë‚˜ë§Œ ìˆìœ¼ë©´ ê·¸ ë©”ì‹œì§€ ë‚´ìš©ì„ ê²€ìƒ‰ê¸°ì— ì „ë‹¬í•©ë‹ˆë‹¤
        (lambda x: x["messages"][-1].content) | retriever,
    ),
    # ë©”ì‹œì§€ê°€ ìˆìœ¼ë©´ LLM ì²´ì¸ì— ì…ë ¥ì„ ì „ë‹¬í•´ ì¿¼ë¦¬ë¥¼ ë³€í™˜í•œ ë‹¤ìŒ, ê²€ìƒ‰ê¸°ì— ì „ë‹¬í•©ë‹ˆë‹¤
    query_transform_prompt | chat | StrOutputParser() | retriever,
).with_config(run_name="chat_retriever_chain")
```

ì´ì œ ì´ ìƒˆë¡œìš´ `query_transforming_retriever_chain`ì„ ì‚¬ìš©í•˜ì—¬ ì´ì „ ì²´ì¸ì„ ì¬êµ¬ì„±í•´ ë³´ê² ìŠµë‹ˆë‹¤. ì´ ìƒˆë¡œìš´ ì²´ì¸ì€ ì…ë ¥ìœ¼ë¡œ dictë¥¼ ë°›ì•„ë“¤ì´ê³  ë¬¸ìì—´ì„ ë¶„ì„í•˜ì—¬ ê²€ìƒ‰ê¸°ì— ì „ë‹¬í•˜ë¯€ë¡œ ìµœìƒìœ„ ìˆ˜ì¤€ì—ì„œ ì¶”ê°€ ë¶„ì„ì´ í•„ìš”í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤:

```python
document_chain = create_stuff_documents_chain(chat, question_answering_prompt)

conversational_retrieval_chain = RunnablePassthrough.assign(
    context=query_transforming_retriever_chain,
).assign(
    answer=document_chain,
)

demo_ephemeral_chat_history = ChatMessageHistory()
```

ë§ˆì§€ë§‰ìœ¼ë¡œ, ì´ë¥¼ í˜¸ì¶œí•´ ë³´ê² ìŠµë‹ˆë‹¤!

```python
demo_ephemeral_chat_history.add_user_message("how can langsmith help with testing?")

response = conversational_retrieval_chain.invoke(
    {"messages": demo_ephemeral_chat_history.messages},
)

demo_ephemeral_chat_history.add_ai_message(response["answer"])

response
```

```output
{'messages': [HumanMessage(content='how can langsmith help with testing?'),
  AIMessage(content='LangSmithëŠ” ì—¬ëŸ¬ ê°€ì§€ ë°©ë²•ìœ¼ë¡œ í…ŒìŠ¤íŠ¸ë¥¼ ë„ìš¸ ìˆ˜ ìˆìŠµë‹ˆë‹¤. ì˜ˆì œë¥¼ ë¹ ë¥´ê²Œ í¸ì§‘í•˜ê³  ë°ì´í„°ì…‹ì— ì¶”ê°€í•˜ì—¬ í‰ê°€ ì„¸íŠ¸ì˜ ë²”ìœ„ë¥¼ í™•ì¥í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤. ì´ëŠ” ëª¨ë¸ì˜ í’ˆì§ˆì„ í–¥ìƒì‹œí‚¤ê±°ë‚˜ ë¹„ìš©ì„ ì ˆê°í•˜ëŠ” ë° ë„ì›€ì´ ë©ë‹ˆë‹¤. ë˜í•œ, LangSmithëŠ” ì‘ì€ ë°ì´í„°ì…‹ì„ ì†ì‰½ê²Œ êµ¬ì„±í•  ìˆ˜ ìˆë„ë¡ í•˜ì—¬ ì• í”Œë¦¬ì¼€ì´ì…˜ì˜ ë³€ê²½ ì‚¬í•­ì„ ì—„ê²©í•˜ê²Œ í…ŒìŠ¤íŠ¸í•˜ëŠ” í¸ë¦¬í•œ ë°©ë²•ì„ ì œê³µí•©ë‹ˆë‹¤. ë” ë‚˜ì•„ê°€, LangSmithëŠ” ì• í”Œë¦¬ì¼€ì´ì…˜ì„ ëª¨ë‹ˆí„°ë§í•˜ì—¬ ëª¨ë“  ì¶”ì ì„ ê¸°ë¡í•˜ê³ , ëŒ€ê¸° ì‹œê°„ ë° í† í° ì‚¬ìš© í†µê³„ë¥¼ ì‹œê°í™”í•˜ë©°, ë°œìƒí•˜ëŠ” íŠ¹ì • ë¬¸ì œë¥¼ í•´ê²°í•  ìˆ˜ ìˆê²Œ í•´ì¤ë‹ˆë‹¤.')],
 'context': [Document(page_content='You can also quickly edit examples and add them to datasets to expand the surface area of your evaluation sets or to fine-tune a model for improved quality or reduced costs.Monitoring\u200bAfter all this, your app might finally ready to go in production. LangSmith can also be used to monitor your application in much the same way that you used for debugging. You can log all traces, visualize latency and token usage statistics, and troubleshoot specific issues as they arise. Each run can also be', metadata={'description': 'Building reliable LLM applications can be challenging. LangChain simplifies the initial setup, but there is still work needed to bring the performance of prompts, chains and agents up the level where they are reliable enough to be used in production.', 'language': 'en', 'source': 'https://docs.smith.langchain.com/overview', 'title': 'LangSmith Overview and User Guide | ğŸ¦œï¸ğŸ› ï¸ LangSmith'}),
  Document(page_content='inputs, and see what happens. At some point though, our application is performing\nwell and we want to be more rigorous about testing changes. We can use a dataset\nthat weâ€™ve constructed along the way (see above). Alternatively, we could spend some\ntime constructing a small dataset by hand. For these situations, LangSmith simplifies', metadata={'description': 'Building reliable LLM applications can be challenging. LangChain simplifies the initial setup, but there is still work needed to bring the performance of prompts, chains and agents up the level where they are reliable enough to be used in production.', 'language': 'en', 'source': 'https://docs.smith.langchain.com/overview', 'title': 'LangSmith Overview and User Guide | ğŸ¦œï¸ğŸ› ï¸ LangSmith'}),
  Document(page_content='Skip to main contentğŸ¦œï¸ğŸ› ï¸ LangSmith DocsPython DocsJS/TS DocsSearchGo to AppLangSmithOverviewTracingTesting & EvaluationOrganizationsHubLangSmith CookbookOverviewOn this pageLangSmith Overview and User GuideBuilding reliable LLM applications can be challenging. LangChain simplifies the initial setup, but there is still work needed to bring the performance of prompts, chains and agents up the level where they are reliable enough to be used in production.Over the past two months, we at LangChain', metadata={'description': 'Building reliable LLM applications can be challenging. LangChain simplifies the initial setup, but there is still work needed to bring the performance of prompts, chains and agents up the level where they are reliable enough to be used in production.', 'language': 'en', 'source': 'https://docs.smith.langchain.com/overview', 'title': 'LangSmith Overview and User Guide | ğŸ¦œï¸ğŸ› ï¸ LangSmith'}),
  Document(page_content='have been building and using LangSmith with the goal of bridging this gap. This is our tactical user guide to outline effective ways to use LangSmith and maximize its benefits.On by default\u200bAt LangChain, all of us have LangSmithâ€™s tracing running in the background by default. On the Python side, this is achieved by setting environment variables, which we establish whenever we launch a virtual environment or open our bash shell and leave them set. The same principle applies to most JavaScript', metadata={'description': 'Building reliable LLM applications can be challenging. LangChain simplifies the initial setup, but there is still work needed to bring the performance of prompts, chains and agents up the level where they are reliable enough to be used in production.', 'language': 'en', 'source': 'https://docs.smith.langchain.com/overview', 'title': 'LangSmith Overview and User Guide | ğŸ¦œï¸ğŸ› ï¸ LangSmith'})],
 'answer': 'LangSmithëŠ” ì—¬ëŸ¬ ê°€ì§€ ë°©ë²•ìœ¼ë¡œ í…ŒìŠ¤íŠ¸ë¥¼ ë„ìš¸ ìˆ˜ ìˆìŠµë‹ˆë‹¤. ì˜ˆì œë¥¼ ë¹ ë¥´ê²Œ í¸ì§‘í•˜ê³  ë°ì´í„°ì…‹ì— ì¶”ê°€í•˜ì—¬ í‰ê°€ ì„¸íŠ¸ì˜ ë²”ìœ„ë¥¼ í™•ì¥í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤. ì´ëŠ” ëª¨ë¸ì˜ í’ˆì§ˆì„ í–¥ìƒì‹œí‚¤ê±°ë‚˜ ë¹„ìš©ì„ ì ˆê°í•˜ëŠ” ë° ë„ì›€ì´ ë©ë‹ˆë‹¤. ë˜í•œ, LangSmithëŠ” ì‘ì€ ë°ì´í„°ì…‹ì„ ì†ì‰½ê²Œ êµ¬ì„±í•  ìˆ˜ ìˆë„ë¡ í•˜ì—¬ ì• í”Œë¦¬ì¼€ì´ì…˜ì˜ ë³€ê²½ ì‚¬í•­ì„ ì—„ê²©í•˜ê²Œ í…ŒìŠ¤íŠ¸í•˜ëŠ” í¸ë¦¬í•œ ë°©ë²•ì„ ì œê³µí•©ë‹ˆë‹¤. ë” ë‚˜ì•„ê°€, LangSmithëŠ” ì• í”Œë¦¬ì¼€ì´ì…˜ì„ ëª¨ë‹ˆí„°ë§í•˜ì—¬ ëª¨ë“  ì¶”ì ì„ ê¸°ë¡í•˜ê³ , ëŒ€ê¸° ì‹œê°„ ë° í† í° ì‚¬ìš© í†µê³„ë¥¼ ì‹œê°í™”í•˜ë©°, ë°œìƒí•˜ëŠ” íŠ¹ì • ë¬¸ì œë¥¼ í•´ê²°í•  ìˆ˜ ìˆê²Œ í•´ì¤ë‹ˆë‹¤.'}
```

```python
demo_ephemeral_chat_history.add_user_message("tell me more about that!")

conversational_retrieval_chain.invoke(
    {"messages": demo_ephemeral_chat_history.messages}
)
```

```output
{'messages': [HumanMessage(content='how can langsmith help with testing?'),
  AIMessage(content='LangSmithëŠ” ì—¬ëŸ¬ ê°€ì§€ ë°©ë²•ìœ¼ë¡œ í…ŒìŠ¤íŠ¸ë¥¼ ë„ìš¸ ìˆ˜ ìˆìŠµë‹ˆë‹¤. ì˜ˆì œë¥¼ ë¹ ë¥´ê²Œ í¸ì§‘í•˜ê³  ë°ì´í„°ì…‹ì— ì¶”ê°€í•˜ì—¬ í‰ê°€ ì„¸íŠ¸ì˜ ë²”ìœ„ë¥¼ í™•ì¥í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤. ì´ëŠ” ëª¨ë¸ì˜ í’ˆì§ˆì„ í–¥ìƒì‹œí‚¤ê±°ë‚˜ ë¹„ìš©ì„ ì ˆê°í•˜ëŠ” ë° ë„ì›€ì´ ë©ë‹ˆë‹¤. ë˜í•œ, LangSmithëŠ” ì‘ì€ ë°ì´í„°ì…‹ì„ ì†ì‰½ê²Œ êµ¬ì„±í•  ìˆ˜ ìˆë„ë¡ í•˜ì—¬ ì• í”Œë¦¬ì¼€ì´ì…˜ì˜ ë³€ê²½ ì‚¬í•­ì„ ì—„ê²©í•˜ê²Œ í…ŒìŠ¤íŠ¸í•˜ëŠ” í¸ë¦¬í•œ ë°©ë²•ì„ ì œê³µí•©ë‹ˆë‹¤. ë” ë‚˜ì•„ê°€, LangSmithëŠ” ì• í”Œë¦¬ì¼€ì´ì…˜ì„ ëª¨ë‹ˆí„°ë§í•˜ì—¬ ëª¨ë“  ì¶”ì ì„ ê¸°ë¡í•˜ê³ , ëŒ€ê¸° ì‹œê°„ ë° í† í° ì‚¬ìš© í†µê³„ë¥¼ ì‹œê°í™”í•˜ë©°, ë°œìƒí•˜ëŠ” íŠ¹ì • ë¬¸ì œë¥¼ í•´ê²°í•  ìˆ˜ ìˆê²Œ í•´ì¤ë‹ˆë‹¤.'),
  HumanMessage(content='tell me more about that!')],
 'context': [Document(page_content='LangSmith Overview and User Guide | ğŸ¦œï¸ğŸ› ï¸ LangSmith', metadata={'description': 'Building reliable LLM applications can be challenging. LangChain simplifies the initial setup, but there is still work needed to bring the performance of prompts, chains and agents up the level where they are reliable enough to be used in production.', 'language': 'en', 'source': 'https://docs.smith.langchain.com/overview', 'title': 'LangSmith Overview and User Guide | ğŸ¦œï¸ğŸ› ï¸ LangSmith'}),
  Document(page_content='You can also quickly edit examples and add them to datasets to expand the surface area of your evaluation sets or to fine-tune a model for improved quality or reduced costs.Monitoring\u200bAfter all this, your app might finally ready to go in production. LangSmith can also be used to monitor your application in much the same way that you used for debugging. You can log all traces, visualize latency and token usage statistics, and troubleshoot specific issues as they arise. Each run can also be', metadata={'description': 'Building reliable LLM applications can be challenging. LangChain simplifies the initial setup, but there is still work needed to bring the performance of prompts, chains and agents up the level where they are reliable enough to be used in production.', 'language': 'en', 'source': 'https://docs.smith.langchain.com/overview', 'title': 'LangSmith Overview and User Guide | ğŸ¦œï¸ğŸ› ï¸ LangSmith'}),
  Document(page_content='Skip to main contentğŸ¦œï¸ğŸ› ï¸ LangSmith DocsPython DocsJS/TS DocsSearchGo to AppLangSmithOverviewTracingTesting & EvaluationOrganizationsHubLangSmith CookbookOverviewOn this pageLangSmith Overview and User GuideBuilding reliable LLM applications can be challenging. LangChain simplifies the initial setup, but there is still work needed to bring the performance of prompts, chains and agents up the level where they are reliable enough to be used in production.Over the past two months, we at LangChain', metadata={'description': 'Building reliable LLM applications can be challenging. LangChain simplifies the initial setup, but there is still work needed to bring the performance of prompts, chains and agents up the level where they are reliable enough to be used in production.', 'language': 'en', 'source': 'https://docs.smith.langchain.com/overview', 'title': 'LangSmith Overview and User Guide | ğŸ¦œï¸ğŸ› ï¸ LangSmith'}),
  Document(page_content='inputs, and see what happens. At some point though, our application is performing\nwell and we want to be more rigorous about testing changes. We can use a dataset\nthat weâ€™ve constructed along the way (see above). Alternatively, we could spend some\ntime constructing a small dataset by hand. For these situations, LangSmith simplifies', metadata={'description': 'Building reliable LLM applications can be challenging. LangChain simplifies the initial setup, but there is still work needed to bring the performance of prompts, chains and agents up the level where they are reliable enough to be used in production.', 'language': 'en', 'source': 'https://docs.smith.langchain.com/overview', 'title': 'LangSmith Overview and User Guide | ğŸ¦œï¸ğŸ› ï¸ LangSmith'})],
 'answer': 'ë¬¼ë¡ ì…ë‹ˆë‹¤! LangSmithëŠ” ë°ì´í„°ì…‹ êµ¬ì„± ë° í¸ì§‘ ê³¼ì •ì„ ê°„ì†Œí™”í•˜ì—¬ í…ŒìŠ¤íŠ¸ì™€ ëª¨ë¸ì˜ ë¯¸ì„¸ ì¡°ì •ì„ ë•ìŠµë‹ˆë‹¤. ì˜ˆì œë¥¼ ë¹ ë¥´ê²Œ í¸ì§‘í•˜ê³  ë°ì´í„°ì…‹ì— ì¶”ê°€í•¨ìœ¼ë¡œì¨ í‰ê°€ ì„¸íŠ¸ì˜ ë²”ìœ„ë¥¼ í™•ì¥í•  ìˆ˜ ìˆìœ¼ë©°, ì´ëŠ” ëª¨ë¸ í’ˆì§ˆ í–¥ìƒ ë° ë¹„ìš© ì ˆê°ì— ë„ì›€ì´ ë©ë‹ˆë‹¤. ë˜í•œ, LangSmithëŠ” ì• í”Œë¦¬ì¼€ì´ì…˜ì˜ ëª¨ë“  ì¶”ì ì„ ê¸°ë¡í•˜ê³ , ëŒ€ê¸° ì‹œê°„ ë° í† í° ì‚¬ìš© í†µê³„ë¥¼ ì‹œê°í™”í•˜ë©°, ë°œìƒí•˜ëŠ” íŠ¹ì • ë¬¸ì œë¥¼ í•´ê²°í•  ìˆ˜ ìˆê²Œ í•´ì£¼ëŠ” ëª¨ë‹ˆí„°ë§ ê¸°ëŠ¥ì„ ì œê³µí•©ë‹ˆë‹¤. ì´ëŸ¬í•œ ì¢…í•©ì ì¸ ëª¨ë‹ˆí„°ë§ ê¸°ëŠ¥ì€ ì• í”Œë¦¬ì¼€ì´ì…˜ì˜ ì‹ ë¢°ì„±ê³¼ ì„±ëŠ¥ì„ ë³´ì¥í•˜ëŠ” ë° ë„ì›€ì´ ë©ë‹ˆë‹¤.'}
```

ë‚´ë¶€ì ìœ¼ë¡œ ë¬´ìŠ¨ ì¼ì´ ì¼ì–´ë‚˜ê³  ìˆëŠ”ì§€ ì´í•´ë¥¼ ë•ê¸° ìœ„í•´, [ì´ LangSmith ì¶”ì ](https://smith.langchain.com/public/42f8993b-7d19-42d3-990a-6608a73c5824/r)ì€ ì²« ë²ˆì§¸ í˜¸ì¶œì„ ë³´ì—¬ì¤ë‹ˆë‹¤. ì‚¬ìš©ìì˜ ì´ˆê¸° ì¿¼ë¦¬ê°€ ê²€ìƒ‰ê¸°ì— ì§ì ‘ ì „ë‹¬ë˜ì–´ ì ì ˆí•œ ë¬¸ì„œê°€ ë°˜í™˜ë˜ëŠ” ê²ƒì„ ë³¼ ìˆ˜ ìˆìŠµë‹ˆë‹¤.

í›„ì† ì§ˆë¬¸ì„ ìœ„í•œ í˜¸ì¶œ, [ì´ LangSmith ì¶”ì ](https://smith.langchain.com/public/7b463791-868b-42bd-8035-17b471e9c7cd/r)ì€ ì‚¬ìš©ìì˜ ì´ˆê¸° ì§ˆë¬¸ì„ LangSmithì™€ì˜ í…ŒìŠ¤íŠ¸ì— ë” ê´€ë ¨ëœ ë‚´ìš©ìœ¼ë¡œ ë‹¤ì‹œ í‘œí˜„í•˜ì—¬ ë” ë†’ì€ í’ˆì§ˆì˜ ë¬¸ì„œë¥¼ ë°˜í™˜í•©ë‹ˆë‹¤.

ì´ì œ ìš°ë¦¬ëŠ” ëŒ€í™”í˜• ê²€ìƒ‰ì´ ê°€ëŠ¥í•œ ì±—ë´‡ì„ ê°–ì¶”ê²Œ ë˜ì—ˆìŠµë‹ˆë‹¤!

## ë‹¤ìŒ ë‹¨ê³„

ì´ì œ ê³¼ê±° ë©”ì‹œì§€ì™€ ë„ë©”ì¸ë³„ ì§€ì‹ì„ í†µí•©í•˜ì—¬ ìƒì„±í•  ìˆ˜ ìˆëŠ” ëŒ€í™”í˜• ì±—ë´‡ì„ ë§Œë“œëŠ” ë°©ë²•ì„ ì•Œê²Œ ë˜ì—ˆìŠµë‹ˆë‹¤. ì´ì™€ ê´€ë ¨í•˜ì—¬ í•  ìˆ˜ ìˆëŠ” ë§ì€ ìµœì í™”ê°€ ìˆìŠµë‹ˆë‹¤ - ìì„¸í•œ ë‚´ìš©ì€ ë‹¤ìŒ í˜ì´ì§€ë¥¼ ì°¸ì¡°í•˜ì„¸ìš”:

- [ë©”ëª¨ë¦¬ ê´€ë¦¬](/docs/use_cases/chatbots/memory_management): ì±„íŒ… ê¸°ë¡ì„ ìë™ìœ¼ë¡œ ì—…ë°ì´íŠ¸í•˜ê³ , ê¸´ ëŒ€í™”ë¥¼ ì •ë¦¬, ìš”ì•½ ë˜ëŠ” ìˆ˜ì •í•˜ì—¬ ë´‡ì„ ì§‘ì¤‘ì‹œí‚¤ëŠ” ê°€ì´ë“œê°€ í¬í•¨ë˜ì–´ ìˆìŠµë‹ˆë‹¤.
- [ê²€ìƒ‰](/docs/use_cases/chatbots/retrieval): ì±—ë´‡ì—ì„œ ë‹¤ì–‘í•œ ìœ í˜•ì˜ ê²€ìƒ‰ì„ ì‚¬ìš©í•˜ëŠ” ë°©ë²•ì— ëŒ€í•œ ì‹¬ì¸µ ë¶„ì„.
- [ë„êµ¬ ì‚¬ìš©](/docs/use_cases/chatbots/tool_usage): ë‹¤ë¥¸ API ë° ì‹œìŠ¤í…œê³¼ ìƒí˜¸ì‘ìš©í•˜ëŠ” ë„êµ¬ë¥¼ ì±—ë´‡ì´ ì‚¬ìš©í•˜ëŠ” ë°©ë²•.