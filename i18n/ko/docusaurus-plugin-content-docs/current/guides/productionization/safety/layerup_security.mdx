---
translated: true
---

# Layerup Security

[Layerup Security](https://uselayerup.com) 통합을 사용하면 LangChain LLM, LLM 체인 또는 LLM 에이전트에 대한 호출을 안전하게 할 수 있습니다. LLM 객체는 기존 LLM 객체를 감싸 사용자와 LLM 사이에 보안 계층을 제공할 수 있습니다.

Layerup Security 객체는 LLM으로 설계되었지만 실제로는 LLM이 아니며, 단순히 LLM을 감싸서 기본 LLM과 동일한 기능을 사용할 수 있도록 합니다.

## 설정

먼저, Layerup [웹사이트](https://uselayerup.com)에서 Layerup Security 계정을 만들어야 합니다.

다음으로, [대시보드](https://dashboard.uselayerup.com)에서 프로젝트를 생성하고 API 키를 복사합니다. 프로젝트 환경 변수에 API 키를 넣는 것이 좋습니다.

Layerup Security SDK를 설치합니다:

```bash
pip install LayerupSecurity
```

LangChain Community를 설치합니다:

```bash
pip install langchain-community
```

이제 Layerup Security로 LLM 호출을 보호할 준비가 되었습니다!

```python
<!--IMPORTS:[{"imported": "LayerupSecurity", "source": "langchain_community.llms.layerup_security", "docs": "https://api.python.langchain.com/en/latest/llms/langchain_community.llms.layerup_security.LayerupSecurity.html", "title": "Layerup Security"}, {"imported": "OpenAI", "source": "langchain_openai", "docs": "https://api.python.langchain.com/en/latest/llms/langchain_openai.llms.base.OpenAI.html", "title": "Layerup Security"}]-->
from langchain_community.llms.layerup_security import LayerupSecurity
from langchain_openai import OpenAI

# 선호하는 LLM 인스턴스를 생성합니다.

openai = OpenAI(
    model_name="gpt-3.5-turbo",
    openai_api_key="OPENAI_API_KEY",
)

# Layerup Security 구성

layerup_security = LayerupSecurity(
    # Layerup Security가 감쌀 LLM 지정
    llm=openai,

    # Layerup 대시보드에서 받은 Layerup API 키
    layerup_api_key="LAYERUP_API_KEY",

    # 셀프 호스팅 시 커스텀 베이스 URL
    layerup_api_base_url="https://api.uselayerup.com/v1",

    # LLM이 호출되기 전에 프롬프트에 실행할 가드레일 목록
    prompt_guardrails=[],

    # LLM의 응답에 실행할 가드레일 목록
    response_guardrails=["layerup.hallucination"],

    # PII 및 민감한 데이터를 마스킹할지 여부
    mask=False,

    # 남용 추적, 고객 추적 및 범위 추적을 위한 메타데이터
    metadata={"customer": "example@uselayerup.com"},

    # 프롬프트 가드레일 위반 핸들러
    handle_prompt_guardrail_violation=(
        lambda violation: {
            "role": "assistant",
            "content": (
                "민감한 데이터가 있었습니다! 응답할 수 없습니다. "
                "다이내믹한 canned 응답입니다. 현재 날짜: {}"
            ).format(datetime.now())
        }
        if violation["offending_guardrail"] == "layerup.sensitive_data"
        else None
    ),

    # 응답 가드레일 위반 핸들러
    handle_response_guardrail_violation=(
        lambda violation: {
            "role": "assistant",
            "content": (
                "다이내믹 데이터가 포함된 맞춤 canned 응답입니다! "
                "위반 규칙은 {}였습니다."
            ).format(violation["offending_guardrail"])
        }
    ),
)

response = layerup_security.invoke(
    "이 메시지를 요약해주세요: 제 이름은 Bob Dylan입니다. 제 SSN은 123-45-6789입니다."
)
```