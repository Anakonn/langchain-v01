---
sidebar_position: 7
translated: true
---

# ê²€ìƒ‰ì„ í†µí•œ ìžê¸° ì§ˆë¬¸

ì´ ì—°ìŠµì—ì„œëŠ” ê²€ìƒ‰ì„ í†µí•œ ìžê¸° ì§ˆë¬¸ ì—ì´ì „íŠ¸ë¥¼ ì†Œê°œí•©ë‹ˆë‹¤.

```python
from langchain import hub
from langchain.agents import AgentExecutor, create_self_ask_with_search_agent
from langchain_community.llms import Fireworks
from langchain_community.tools.tavily_search import TavilyAnswer
```

## ë„êµ¬ ì´ˆê¸°í™”

ìš°ë¦¬ëŠ” ì‚¬ìš©í•  ë„êµ¬ë¥¼ ì´ˆê¸°í™”í•  ê²ƒìž…ë‹ˆë‹¤. ì´ëŠ” **ë‹µë³€**ì„ ì œê³µí•˜ëŠ” ì¢‹ì€ ë„êµ¬ìž…ë‹ˆë‹¤(ë¬¸ì„œê°€ ì•„ë‹˜).

ì´ ì—ì´ì „íŠ¸ì˜ ê²½ìš° í•˜ë‚˜ì˜ ë„êµ¬ë§Œ ì‚¬ìš©í•  ìˆ˜ ìžˆìœ¼ë©° "ì¤‘ê°„ ë‹µë³€"ì´ë¼ëŠ” ì´ë¦„ìœ¼ë¡œ ì§€ì •í•´ì•¼ í•©ë‹ˆë‹¤.

```python
tools = [TavilyAnswer(max_results=1, name="Intermediate Answer")]
```

## ì—ì´ì „íŠ¸ ìƒì„±

```python
# Get the prompt to use - you can modify this!
prompt = hub.pull("hwchase17/self-ask-with-search")
```

```python
# Choose the LLM that will drive the agent
llm = Fireworks()

# Construct the Self Ask With Search Agent
agent = create_self_ask_with_search_agent(llm, tools, prompt)
```

## ì—ì´ì „íŠ¸ ì‹¤í–‰

```python
# Create an agent executor by passing in the agent and tools
agent_executor = AgentExecutor(agent=agent, tools=tools, verbose=True)
```

```python
agent_executor.invoke(
    {"input": "What is the hometown of the reigning men's U.S. Open champion?"}
)
```

```output


[1m> Entering new AgentExecutor chain...[0m
[32;1m[1;3m Yes.
Follow up: Who is the reigning men's U.S. Open champion?[0m[36;1m[1;3mThe reigning men's U.S. Open champion is Novak Djokovic. He won his 24th Grand Slam singles title by defeating Daniil Medvedev in the final of the 2023 U.S. Open.[0m[32;1m[1;3m
So the final answer is: Novak Djokovic.[0m

[1m> Finished chain.[0m
```

```output
{'input': "What is the hometown of the reigning men's U.S. Open champion?",
 'output': 'Novak Djokovic.'}
```
