---
translated: true
---

# ëŒ€í™” ì§€ì‹ ê·¸ë˜í”„

ì´ ìœ í˜•ì˜ ë©”ëª¨ë¦¬ëŠ” ì§€ì‹ ê·¸ë˜í”„ë¥¼ ì‚¬ìš©í•˜ì—¬ ë©”ëª¨ë¦¬ë¥¼ ì¬í˜„í•©ë‹ˆë‹¤.

## LLMì„ ì‚¬ìš©í•œ ë©”ëª¨ë¦¬ ì‚¬ìš©

```python
from langchain.memory import ConversationKGMemory
from langchain_openai import OpenAI
```

```python
llm = OpenAI(temperature=0)
memory = ConversationKGMemory(llm=llm)
memory.save_context({"input": "say hi to sam"}, {"output": "who is sam"})
memory.save_context({"input": "sam is a friend"}, {"output": "okay"})
```

```python
memory.load_memory_variables({"input": "who is sam"})
```

```output
{'history': 'On Sam: Sam is friend.'}
```

ë©”ì‹œì§€ ëª©ë¡ìœ¼ë¡œ ê¸°ë¡ì„ ì–»ì„ ìˆ˜ë„ ìˆìŠµë‹ˆë‹¤(ì±„íŒ… ëª¨ë¸ê³¼ í•¨ê»˜ ì‚¬ìš©í•˜ëŠ” ê²½ìš° ìœ ìš©í•©ë‹ˆë‹¤).

```python
memory = ConversationKGMemory(llm=llm, return_messages=True)
memory.save_context({"input": "say hi to sam"}, {"output": "who is sam"})
memory.save_context({"input": "sam is a friend"}, {"output": "okay"})
```

```python
memory.load_memory_variables({"input": "who is sam"})
```

```output
{'history': [SystemMessage(content='On Sam: Sam is friend.', additional_kwargs={})]}
```

ìƒˆ ë©”ì‹œì§€ì—ì„œ í˜„ì¬ ì—”í‹°í‹°ë¥¼ ë³´ë‹¤ ëª¨ë“ˆì‹ìœ¼ë¡œ ê°€ì ¸ì˜¬ ìˆ˜ë„ ìˆìŠµë‹ˆë‹¤(ì´ì „ ë©”ì‹œì§€ë¥¼ ì»¨í…ìŠ¤íŠ¸ë¡œ ì‚¬ìš©í•  ê²ƒì…ë‹ˆë‹¤).

```python
memory.get_current_entities("what's Sams favorite color?")
```

```output
['Sam']
```

ìƒˆ ë©”ì‹œì§€ì—ì„œ ì§€ì‹ íŠ¸ë¦¬í”Œë¦¿ì„ ë³´ë‹¤ ëª¨ë“ˆì‹ìœ¼ë¡œ ê°€ì ¸ì˜¬ ìˆ˜ë„ ìˆìŠµë‹ˆë‹¤(ì´ì „ ë©”ì‹œì§€ë¥¼ ì»¨í…ìŠ¤íŠ¸ë¡œ ì‚¬ìš©í•  ê²ƒì…ë‹ˆë‹¤).

```python
memory.get_knowledge_triplets("her favorite color is red")
```

```output
[KnowledgeTriple(subject='Sam', predicate='favorite color', object_='red')]
```

## ì²´ì¸ì—ì„œ ì‚¬ìš©í•˜ê¸°

ì´ì œ ì´ê²ƒì„ ì²´ì¸ì—ì„œ ì‚¬ìš©í•´ ë³´ê² ìŠµë‹ˆë‹¤!

```python
llm = OpenAI(temperature=0)
from langchain.chains import ConversationChain
from langchain_core.prompts.prompt import PromptTemplate

template = """The following is a friendly conversation between a human and an AI. The AI is talkative and provides lots of specific details from its context.
If the AI does not know the answer to a question, it truthfully says it does not know. The AI ONLY uses information contained in the "Relevant Information" section and does not hallucinate.

Relevant Information:

{history}

Conversation:
Human: {input}
AI:"""
prompt = PromptTemplate(input_variables=["history", "input"], template=template)
conversation_with_kg = ConversationChain(
    llm=llm, verbose=True, prompt=prompt, memory=ConversationKGMemory(llm=llm)
)
```

```python
conversation_with_kg.predict(input="Hi, what's up?")
```

```output


[1m> Entering new ConversationChain chain...[0m
Prompt after formatting:
[32;1m[1;3mThe following is a friendly conversation between a human and an AI. The AI is talkative and provides lots of specific details from its context.
If the AI does not know the answer to a question, it truthfully says it does not know. The AI ONLY uses information contained in the "Relevant Information" section and does not hallucinate.

Relevant Information:



Conversation:
Human: Hi, what's up?
AI:[0m

[1m> Finished chain.[0m
```

```output
" Hi there! I'm doing great. I'm currently in the process of learning about the world around me. I'm learning about different cultures, languages, and customs. It's really fascinating! How about you?"
```

```python
conversation_with_kg.predict(
    input="My name is James and I'm helping Will. He's an engineer."
)
```

```output


[1m> Entering new ConversationChain chain...[0m
Prompt after formatting:
[32;1m[1;3mThe following is a friendly conversation between a human and an AI. The AI is talkative and provides lots of specific details from its context.
If the AI does not know the answer to a question, it truthfully says it does not know. The AI ONLY uses information contained in the "Relevant Information" section and does not hallucinate.

Relevant Information:



Conversation:
Human: My name is James and I'm helping Will. He's an engineer.
AI:[0m

[1m> Finished chain.[0m
```

```output
" Hi James, it's nice to meet you. I'm an AI and I understand you're helping Will, the engineer. What kind of engineering does he do?"
```

```python
conversation_with_kg.predict(input="What do you know about Will?")
```

```output


[1m> Entering new ConversationChain chain...[0m
Prompt after formatting:
[32;1m[1;3mThe following is a friendly conversation between a human and an AI. The AI is talkative and provides lots of specific details from its context.
If the AI does not know the answer to a question, it truthfully says it does not know. The AI ONLY uses information contained in the "Relevant Information" section and does not hallucinate.

Relevant Information:

On Will: Will is an engineer.

Conversation:
Human: What do you know about Will?
AI:[0m

[1m> Finished chain.[0m
```

```output
' Will is an engineer.'
```
