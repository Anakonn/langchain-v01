---
translated: true
---

# ì‚¬ìš©ì ì •ì˜ ì¶œë ¥ íŒŒì„œ

ê²½ìš°ì— ë”°ë¼ ëª¨ë¸ ì¶œë ¥ì„ ì‚¬ìš©ì ì •ì˜ í˜•ì‹ìœ¼ë¡œ êµ¬ì¡°í™”í•˜ê¸° ìœ„í•´ ì‚¬ìš©ì ì •ì˜ íŒŒì„œë¥¼ êµ¬í˜„í•˜ê³  ì‹¶ì„ ìˆ˜ ìˆìŠµë‹ˆë‹¤.

ì‚¬ìš©ì ì •ì˜ íŒŒì„œë¥¼ êµ¬í˜„í•˜ëŠ” ë‘ ê°€ì§€ ë°©ë²•ì´ ìˆìŠµë‹ˆë‹¤:

1. LCELì—ì„œ `RunnableLambda` ë˜ëŠ” `RunnableGenerator` ì‚¬ìš© - ëŒ€ë¶€ë¶„ì˜ ê²½ìš° ì´ ë°©ë²•ì„ ê°•ë ¥íˆ ì¶”ì²œí•©ë‹ˆë‹¤.
2. íŒŒì‹± ê¸°ë³¸ í´ë˜ìŠ¤ ì¤‘ í•˜ë‚˜ë¥¼ ìƒì† - ì´ëŠ” ê¹Œë‹¤ë¡œìš´ ë°©ë²•ì…ë‹ˆë‹¤.

ë‘ ê°€ì§€ ì ‘ê·¼ ë°©ì‹ì˜ ì°¨ì´ëŠ” ì£¼ë¡œ í‘œë©´ì ì´ë©°, ì£¼ë¡œ ì–´ë–¤ ì½œë°±ì´ íŠ¸ë¦¬ê±°ë˜ëŠ”ì§€(ì˜ˆ: `on_chain_start` vs. `on_parser_start`)ì™€ ì‹¤í–‰ ê°€ëŠ¥í•œ ëŒë‹¤ vs. íŒŒì„œê°€ LangSmithì™€ ê°™ì€ ì¶”ì  í”Œë«í¼ì—ì„œ ì–´ë–»ê²Œ ì‹œê°í™”ë ì§€ì— ìˆìŠµë‹ˆë‹¤.

## ì‹¤í–‰ ê°€ëŠ¥í•œ ëŒë‹¤ì™€ ìƒì„±ê¸°

**ì‹¤í–‰ ê°€ëŠ¥í•œ ëŒë‹¤**ì™€ **ì‹¤í–‰ ê°€ëŠ¥í•œ ìƒì„±ê¸°**ë¥¼ ì‚¬ìš©í•˜ì—¬ íŒŒì‹±í•˜ëŠ” ê²ƒì´ ê¶Œì¥ë˜ëŠ” ë°©ë²•ì…ë‹ˆë‹¤!

ì—¬ê¸°ì„œëŠ” ëª¨ë¸ ì¶œë ¥ì˜ ëŒ€ì†Œë¬¸ìë¥¼ ë°˜ì „ì‹œí‚¤ëŠ” ê°„ë‹¨í•œ íŒŒì„œë¥¼ ë§Œë“¤ ê²ƒì…ë‹ˆë‹¤.

ì˜ˆë¥¼ ë“¤ì–´, ëª¨ë¸ì´ "Meow"ë¥¼ ì¶œë ¥í•˜ë©´ íŒŒì„œëŠ” "mEOW"ë¥¼ ìƒì„±í•©ë‹ˆë‹¤.

```python
from typing import Iterable

from langchain_anthropic.chat_models import ChatAnthropic
from langchain_core.messages import AIMessage, AIMessageChunk

model = ChatAnthropic(model_name="claude-2.1")


def parse(ai_message: AIMessage) -> str:
    """Parse the AI message."""
    return ai_message.content.swapcase()


chain = model | parse
chain.invoke("hello")
```

```output
'hELLO!'
```

:::tip

LCELì€ `|` êµ¬ë¬¸ì„ ì‚¬ìš©í•˜ì—¬ `parse` í•¨ìˆ˜ë¥¼ `RunnableLambda(parse)`ë¡œ ìë™ ì—…ê·¸ë ˆì´ë“œí•©ë‹ˆë‹¤.

ì›í•˜ì§€ ì•Šìœ¼ì‹œë©´ `RunnableLambda`ë¥¼ ìˆ˜ë™ìœ¼ë¡œ ê°€ì ¸ì™€ì„œ `parse = RunnableLambda(parse)`ë¥¼ ì‹¤í–‰í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.
:::

ìŠ¤íŠ¸ë¦¬ë°ì´ ì‘ë™í• ê¹Œìš”?

```python
for chunk in chain.stream("tell me about yourself in one sentence"):
    print(chunk, end="|", flush=True)
```

```output
i'M cLAUDE, AN ai ASSISTANT CREATED BY aNTHROPIC TO BE HELPFUL, HARMLESS, AND HONEST.|
```

ì•„ë‹ˆìš”, ì‘ë™í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤. ì™œëƒí•˜ë©´ íŒŒì„œê°€ ì…ë ¥ì„ ì§‘ê³„í•œ í›„ì— ì¶œë ¥ì„ êµ¬ë¬¸ ë¶„ì„í•˜ê¸° ë•Œë¬¸ì…ë‹ˆë‹¤.

ìŠ¤íŠ¸ë¦¬ë° íŒŒì„œë¥¼ êµ¬í˜„í•˜ë ¤ë©´ íŒŒì„œê°€ ì…ë ¥ì˜ ë°˜ë³µ ê°€ëŠ¥í•œ ê°ì²´ë¥¼ ë°›ì•„ë“¤ì´ê³  ê²°ê³¼ë¥¼ ì‚¬ìš© ê°€ëŠ¥í•  ë•Œ yieldí•˜ë„ë¡ í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.

```python
from langchain_core.runnables import RunnableGenerator


def streaming_parse(chunks: Iterable[AIMessageChunk]) -> Iterable[str]:
    for chunk in chunks:
        yield chunk.content.swapcase()


streaming_parse = RunnableGenerator(streaming_parse)
```

:::important

ìŠ¤íŠ¸ë¦¬ë° íŒŒì„œë¥¼ `RunnableGenerator`ë¡œ ë˜í•‘í•˜ì‹­ì‹œì˜¤. `|` êµ¬ë¬¸ìœ¼ë¡œ ìë™ ì—…ê·¸ë ˆì´ë“œë¥¼ ì¤‘ì§€í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.
:::

```python
chain = model | streaming_parse
chain.invoke("hello")
```

```output
'hELLO!'
```

ìŠ¤íŠ¸ë¦¬ë°ì´ ì‘ë™í•˜ëŠ”ì§€ í™•ì¸í•´ ë´…ì‹œë‹¤!

```python
for chunk in chain.stream("tell me about yourself in one sentence"):
    print(chunk, end="|", flush=True)
```

```output
i|'M| cLAUDE|,| AN| ai| ASSISTANT| CREATED| BY| aN|THROP|IC| TO| BE| HELPFUL|,| HARMLESS|,| AND| HONEST|.|
```

## íŒŒì‹± ê¸°ë³¸ í´ë˜ìŠ¤ ìƒì†

íŒŒì„œë¥¼ êµ¬í˜„í•˜ëŠ” ë˜ ë‹¤ë¥¸ ë°©ë²•ì€ `BaseOutputParser`, `BaseGenerationOutputParser` ë˜ëŠ” í•„ìš”ì— ë”°ë¥¸ ë‹¤ë¥¸ ê¸°ë³¸ íŒŒì„œ ì¤‘ í•˜ë‚˜ë¥¼ ìƒì†í•˜ëŠ” ê²ƒì…ë‹ˆë‹¤.

ì¼ë°˜ì ìœ¼ë¡œ ì´ ì ‘ê·¼ ë°©ì‹ì€ **ê¶Œì¥ë˜ì§€ ì•ŠìŠµë‹ˆë‹¤**. ì¤‘ìš”í•œ ì´ì  ì—†ì´ ë” ë§ì€ ì½”ë“œë¥¼ ì‘ì„±í•´ì•¼ í•˜ê¸° ë•Œë¬¸ì…ë‹ˆë‹¤.

ê°€ì¥ ê°„ë‹¨í•œ ìœ í˜•ì˜ ì¶œë ¥ íŒŒì„œëŠ” `BaseOutputParser` í´ë˜ìŠ¤ë¥¼ í™•ì¥í•˜ë©° ë‹¤ìŒ ë©”ì„œë“œë¥¼ êµ¬í˜„í•´ì•¼ í•©ë‹ˆë‹¤:

* `parse`: ëª¨ë¸ì—ì„œ ì¶œë ¥ëœ ë¬¸ìì—´ì„ êµ¬ë¬¸ ë¶„ì„í•©ë‹ˆë‹¤.
* (ì„ íƒ ì‚¬í•­) `_type`: íŒŒì„œì˜ ì´ë¦„ì„ ì‹ë³„í•©ë‹ˆë‹¤.

ì±„íŒ… ëª¨ë¸ ë˜ëŠ” LLMì˜ ì¶œë ¥ì´ ì˜ëª»ëœ ê²½ìš° `OutputParserException`ì„ throwí•˜ì—¬ êµ¬ë¬¸ ë¶„ì„ì´ ì˜ëª»ëœ ì…ë ¥ìœ¼ë¡œ ì¸í•´ ì‹¤íŒ¨í–ˆìŒì„ ë‚˜íƒ€ë‚¼ ìˆ˜ ìˆìŠµë‹ˆë‹¤. ì´ ì˜ˆì™¸ë¥¼ ì‚¬ìš©í•˜ë©´ íŒŒì„œë¥¼ ì‚¬ìš©í•˜ëŠ” ì½”ë“œì—ì„œ ì˜ˆì™¸ë¥¼ ì¼ê´€ëœ ë°©ì‹ìœ¼ë¡œ ì²˜ë¦¬í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.

:::tip íŒŒì„œëŠ” Runnablesì…ë‹ˆë‹¤! ğŸƒ

`BaseOutputParser`ê°€ `Runnable` ì¸í„°í˜ì´ìŠ¤ë¥¼ êµ¬í˜„í•˜ë¯€ë¡œ, ì´ ë°©ì‹ìœ¼ë¡œ ìƒì„±í•œ ì‚¬ìš©ì ì •ì˜ íŒŒì„œëŠ” ìœ íš¨í•œ LangChain Runnablesê°€ ë˜ì–´ ìë™ ë¹„ë™ê¸° ì§€ì›, ë°°ì¹˜ ì¸í„°í˜ì´ìŠ¤, ë¡œê¹… ì§€ì› ë“±ì˜ ì´ì ì„ ëˆ„ë¦´ ìˆ˜ ìˆìŠµë‹ˆë‹¤.
:::

### ê°„ë‹¨í•œ íŒŒì„œ

ì—¬ê¸°ì—ëŠ” ë¶€ìš¸ ê°’ì˜ ë¬¸ìì—´ í‘œí˜„(ì˜ˆ: `YES` ë˜ëŠ” `NO`)ì„ êµ¬ë¬¸ ë¶„ì„í•˜ê³  í•´ë‹¹ `boolean` ìœ í˜•ìœ¼ë¡œ ë³€í™˜í•˜ëŠ” ê°„ë‹¨í•œ íŒŒì„œê°€ ìˆìŠµë‹ˆë‹¤.

```python
from langchain_core.exceptions import OutputParserException
from langchain_core.output_parsers import BaseOutputParser


# The [bool] desribes a parameterization of a generic.
# It's basically indicating what the return type of parse is
# in this case the return type is either True or False
class BooleanOutputParser(BaseOutputParser[bool]):
    """Custom boolean parser."""

    true_val: str = "YES"
    false_val: str = "NO"

    def parse(self, text: str) -> bool:
        cleaned_text = text.strip().upper()
        if cleaned_text not in (self.true_val.upper(), self.false_val.upper()):
            raise OutputParserException(
                f"BooleanOutputParser expected output value to either be "
                f"{self.true_val} or {self.false_val} (case-insensitive). "
                f"Received {cleaned_text}."
            )
        return cleaned_text == self.true_val.upper()

    @property
    def _type(self) -> str:
        return "boolean_output_parser"
```

```python
parser = BooleanOutputParser()
parser.invoke("YES")
```

```output
True
```

```python
try:
    parser.invoke("MEOW")
except Exception as e:
    print(f"Triggered an exception of type: {type(e)}")
```

```output
Triggered an exception of type: <class 'langchain_core.exceptions.OutputParserException'>
```

ë§¤ê°œë³€ìˆ˜í™”ë¥¼ ë³€ê²½í•´ ë³´ê² ìŠµë‹ˆë‹¤.

```python
parser = BooleanOutputParser(true_val="OKAY")
parser.invoke("OKAY")
```

```output
True
```

ë‹¤ë¥¸ LCEL ë©”ì„œë“œê°€ ì¡´ì¬í•˜ëŠ”ì§€ í™•ì¸í•´ ë´…ì‹œë‹¤.

```python
parser.batch(["OKAY", "NO"])
```

```output
[True, False]
```

```python
await parser.abatch(["OKAY", "NO"])
```

```output
[True, False]
```

```python
from langchain_anthropic.chat_models import ChatAnthropic

anthropic = ChatAnthropic(model_name="claude-2.1")
anthropic.invoke("say OKAY or NO")
```

```output
AIMessage(content='OKAY')
```

íŒŒì„œê°€ ì‘ë™í•˜ëŠ”ì§€ í…ŒìŠ¤íŠ¸í•´ ë´…ì‹œë‹¤!

```python
chain = anthropic | parser
chain.invoke("say OKAY or NO")
```

```output
True
```

:::note
íŒŒì„œëŠ” LLMì˜ ì¶œë ¥(ë¬¸ìì—´) ë˜ëŠ” ì±„íŒ… ëª¨ë¸ì˜ ì¶œë ¥(`AIMessage`)ê³¼ í•¨ê»˜ ì‘ë™í•©ë‹ˆë‹¤!
:::

### ì›ì‹œ ëª¨ë¸ ì¶œë ¥ êµ¬ë¬¸ ë¶„ì„

ë•Œë¡œëŠ” ì›ì‹œ í…ìŠ¤íŠ¸ ì™¸ì—ë„ ëª¨ë¸ ì¶œë ¥ì— ì¤‘ìš”í•œ ë©”íƒ€ë°ì´í„°ê°€ ìˆìŠµë‹ˆë‹¤. ì´ ê²½ìš°ì˜ í•œ ì˜ˆëŠ” ë„êµ¬ í˜¸ì¶œì´ë©°, í˜¸ì¶œëœ í•¨ìˆ˜ì— ì „ë‹¬ë˜ì–´ì•¼ í•˜ëŠ” ì¸ìˆ˜ê°€ ë³„ë„ì˜ ì†ì„±ìœ¼ë¡œ ë°˜í™˜ë©ë‹ˆë‹¤. ì´ëŸ¬í•œ ì„¸ë¶€ì ì¸ ì œì–´ê°€ í•„ìš”í•œ ê²½ìš° ëŒ€ì‹  `BaseGenerationOutputParser` í´ë˜ìŠ¤ë¥¼ ìƒì†í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.

ì´ í´ë˜ìŠ¤ì—ëŠ” `parse_result` ë©”ì„œë“œ í•˜ë‚˜ë§Œ í•„ìš”í•©ë‹ˆë‹¤. ì´ ë©”ì„œë“œëŠ” ì›ì‹œ ëª¨ë¸ ì¶œë ¥(ì˜ˆ: `Generation` ë˜ëŠ” `ChatGeneration` ëª©ë¡)ì„ ë°›ì•„ êµ¬ë¬¸ ë¶„ì„ëœ ì¶œë ¥ì„ ë°˜í™˜í•©ë‹ˆë‹¤.

`Generation`ê³¼ `ChatGeneration` ëª¨ë‘ë¥¼ ì§€ì›í•˜ë©´ íŒŒì„œê°€ ì¼ë°˜ LLMê³¼ ì±„íŒ… ëª¨ë¸ ëª¨ë‘ì—ì„œ ì‘ë™í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.

```python
from typing import List

from langchain_core.exceptions import OutputParserException
from langchain_core.messages import AIMessage
from langchain_core.output_parsers import BaseGenerationOutputParser
from langchain_core.outputs import ChatGeneration, Generation


class StrInvertCase(BaseGenerationOutputParser[str]):
    """An example parser that inverts the case of the characters in the message.

    This is an example parse shown just for demonstration purposes and to keep
    the example as simple as possible.
    """

    def parse_result(self, result: List[Generation], *, partial: bool = False) -> str:
        """Parse a list of model Generations into a specific format.

        Args:
            result: A list of Generations to be parsed. The Generations are assumed
                to be different candidate outputs for a single model input.
                Many parsers assume that only a single generation is passed it in.
                We will assert for that
            partial: Whether to allow partial results. This is used for parsers
                     that support streaming
        """
        if len(result) != 1:
            raise NotImplementedError(
                "This output parser can only be used with a single generation."
            )
        generation = result[0]
        if not isinstance(generation, ChatGeneration):
            # Say that this one only works with chat generations
            raise OutputParserException(
                "This output parser can only be used with a chat generation."
            )
        return generation.message.content.swapcase()


chain = anthropic | StrInvertCase()
```

ìƒˆ íŒŒì„œë¥¼ í…ŒìŠ¤íŠ¸í•´ ë´…ì‹œë‹¤! ëª¨ë¸ ì¶œë ¥ì„ ë°˜ì „ì‹œì¼œì•¼ í•©ë‹ˆë‹¤.

```python
chain.invoke("Tell me a short sentence about yourself")
```

```output
'hELLO! mY NAME IS cLAUDE.'
```
