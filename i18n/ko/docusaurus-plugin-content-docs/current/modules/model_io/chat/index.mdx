---
sidebar_class_name: hidden
sidebar_position: 3
translated: true
---

# 채팅 모델

채팅 모델은 LangChain의 핵심 구성 요소입니다.

채팅 모델은 채팅 메시지를 입력으로 사용하고 채팅 메시지를 출력으로 반환하는 언어 모델입니다(일반 텍스트와 달리).

LangChain은 많은 모델 공급업체(OpenAI, Cohere, Hugging Face 등)와의 통합을 제공하며 이러한 모든 모델과 상호 작용하기 위한 표준 인터페이스를 노출합니다.

LangChain을 사용하면 동기, 비동기, 배치 및 스트리밍 모드에서 모델을 사용할 수 있으며 캐싱 등의 기타 기능을 제공합니다.

## [빠른 시작](./quick_start)

[이 빠른 시작](./quick_start)을 확인하여 ChatModels로 작업하는 방법에 대한 개요를 확인하세요. 여기에는 그들이 노출하는 다양한 메서드가 포함됩니다.

## [통합](/docs/integrations/chat/)

LangChain이 제공하는 모든 LLM 통합의 전체 목록은 [통합 페이지](/docs/integrations/chat/)를 참조하세요.

## 방법 가이드

LLM의 고급 사용을 위한 여러 방법 가이드가 있습니다.
여기에는 다음이 포함됩니다:

- [ChatModel 응답 캐싱 방법](./chat_model_caching)
- [함수 호출을 지원하는 ChatModels 사용 방법](./function_calling)
- [ChatModel에서 응답 스트리밍 방법](./streaming)
- [ChatModel 호출에서 토큰 사용량 추적 방법](./token_usage_tracking)
- [사용자 정의 ChatModel 생성 방법](./custom_chat_model)
