---
keywords:
- RunnablePassthrough
- assign
- LCEL
sidebar_position: 6
title: 'Assign: Add values to state'
translated: true
---

# Ajouter des valeurs √† l'√©tat de la cha√Æne

La m√©thode statique `RunnablePassthrough.assign(...)` prend une valeur d'entr√©e et ajoute les arguments suppl√©mentaires pass√©s √† la fonction d'assignation.

Cela est utile lorsque vous cr√©ez de mani√®re additive un dictionnaire √† utiliser comme entr√©e pour une √©tape ult√©rieure, ce qui est un mod√®le LCEL courant.

Voici un exemple :

```python
%pip install --upgrade --quiet langchain langchain-openai
```

```output
[33mWARNING: You are using pip version 22.0.4; however, version 24.0 is available.
You should consider upgrading via the '/Users/jacoblee/.pyenv/versions/3.10.5/bin/python -m pip install --upgrade pip' command.[0m[33m
[0mNote: you may need to restart the kernel to use updated packages.
```

```python
from langchain_core.runnables import RunnableParallel, RunnablePassthrough

runnable = RunnableParallel(
    extra=RunnablePassthrough.assign(mult=lambda x: x["num"] * 3),
    modified=lambda x: x["num"] + 1,
)

runnable.invoke({"num": 1})
```

```output
{'extra': {'num': 1, 'mult': 3}, 'modified': 2}
```

Examinons ce qui se passe ici.

- L'entr√©e de la cha√Æne est `{"num": 1}`. Cela est transmis √† un `RunnableParallel`, qui invoque les runnables qui lui sont pass√©s en parall√®le avec cette entr√©e.
- La valeur sous la cl√© `extra` est invoqu√©e. `RunnablePassthrough.assign()` conserve les cl√©s d'origine dans le dictionnaire d'entr√©e (`{"num": 1}`), et attribue une nouvelle cl√© appel√©e `mult`. La valeur est `lambda x: x["num"] * 3)`, ce qui donne `3`. Ainsi, le r√©sultat est `{"num": 1, "mult": 3}`.
- `{"num": 1, "mult": 3}` est renvoy√© √† l'appel `RunnableParallel` et est d√©fini comme valeur de la cl√© `extra`.
- En m√™me temps, la cl√© `modified` est appel√©e. Le r√©sultat est `2`, car le lambda extrait une cl√© appel√©e `"num"` de son entr√©e et ajoute un.

Ainsi, le r√©sultat est `{'extra': {'num': 1, 'mult': 3}, 'modified': 2}`.

## Streaming

Une belle fonctionnalit√© de cette m√©thode est qu'elle permet aux valeurs de passer d√®s qu'elles sont disponibles. Pour le montrer, nous utiliserons `RunnablePassthrough.assign()` pour renvoyer imm√©diatement les documents source dans une cha√Æne de r√©cup√©ration :

```python
from langchain_community.vectorstores import FAISS
from langchain_core.output_parsers import StrOutputParser
from langchain_core.prompts import ChatPromptTemplate
from langchain_core.runnables import RunnablePassthrough
from langchain_openai import ChatOpenAI, OpenAIEmbeddings

vectorstore = FAISS.from_texts(
    ["harrison worked at kensho"], embedding=OpenAIEmbeddings()
)
retriever = vectorstore.as_retriever()
template = """Answer the question based only on the following context:
{context}

Question: {question}
"""
prompt = ChatPromptTemplate.from_template(template)
model = ChatOpenAI()

generation_chain = prompt | model | StrOutputParser()

retrieval_chain = {
    "context": retriever,
    "question": RunnablePassthrough(),
} | RunnablePassthrough.assign(output=generation_chain)

stream = retrieval_chain.stream("where did harrison work?")

for chunk in stream:
    print(chunk)
```

```output
{'question': 'where did harrison work?'}
{'context': [Document(page_content='harrison worked at kensho')]}
{'output': ''}
{'output': 'H'}
{'output': 'arrison'}
{'output': ' worked'}
{'output': ' at'}
{'output': ' Kens'}
{'output': 'ho'}
{'output': '.'}
{'output': ''}
```

Nous pouvons voir que le premier bloc contient le `"question"` d'origine, car il est imm√©diatement disponible. Le deuxi√®me bloc contient `"context"` car le r√©cup√©rateur termine en deuxi√®me. Enfin, la sortie de la `generation_chain` arrive en flux au fur et √† mesure qu'elle est disponible.
