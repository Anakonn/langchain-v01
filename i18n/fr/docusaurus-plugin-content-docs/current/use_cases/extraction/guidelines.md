---
sidebar_position: 5
title: Directives
translated: true
---

La qualitÃ© des rÃ©sultats d'extraction dÃ©pend de nombreux facteurs.

Voici un ensemble de directives pour vous aider Ã  obtenir les meilleures performances de vos modÃ¨les :

* DÃ©finissez la tempÃ©rature du modÃ¨le sur `0`.
* AmÃ©liorez l'invite. L'invite doit Ãªtre prÃ©cise et concise.
* Documentez le schÃ©ma : assurez-vous que le schÃ©ma est documentÃ© pour fournir plus d'informations au LLM.
* Fournissez des exemples de rÃ©fÃ©rence ! Des exemples diversifiÃ©s peuvent Ãªtre utiles, y compris des exemples oÃ¹ rien ne doit Ãªtre extrait.
* Si vous avez beaucoup d'exemples, utilisez un rÃ©cupÃ©rateur pour rÃ©cupÃ©rer les exemples les plus pertinents.
* Effectuez des tests avec le meilleur LLM/modÃ¨le de chat disponible (par exemple, gpt-4, claude-3, etc.) - vÃ©rifiez auprÃ¨s du fournisseur du modÃ¨le lequel est le plus rÃ©cent et le plus performant !
* Si le schÃ©ma est trÃ¨s volumineux, essayez de le diviser en plusieurs schÃ©mas plus petits, effectuez des extractions sÃ©parÃ©es et fusionnez les rÃ©sultats.
* Assurez-vous que le schÃ©ma permet au modÃ¨le de REJETER l'extraction d'informations. Sinon, le modÃ¨le sera forcÃ© d'inventer des informations !
* Ajoutez des Ã©tapes de vÃ©rification/correction (demandez Ã  un LLM de corriger ou de vÃ©rifier les rÃ©sultats de l'extraction).

## Benchmark

* CrÃ©ez et testez des donnÃ©es pour votre cas d'utilisation Ã  l'aide de [LangSmith ğŸ¦œï¸ğŸ› ï¸](https://docs.smith.langchain.com/).
* Votre LLM est-il suffisamment bon ? Utilisez [langchain-benchmarks ğŸ¦œğŸ’¯ ](https://github.com/langchain-ai/langchain-benchmarks) pour tester votre LLM Ã  l'aide de jeux de donnÃ©es existants.

## Ã€ garder Ã  l'esprit ! ğŸ˜¶â€ğŸŒ«ï¸

* Les LLM sont formidables, mais ne sont pas nÃ©cessaires dans tous les cas ! Si vous extrayez des informations Ã  partir d'une seule source structurÃ©e (par exemple, LinkedIn), l'utilisation d'un LLM n'est pas une bonne idÃ©e - le web-scraping traditionnel sera beaucoup moins coÃ»teux et plus fiable.

* **Humain dans la boucle** Si vous avez besoin d'une **qualitÃ© parfaite**, vous devrez probablement prÃ©voir d'avoir un humain dans la boucle - mÃªme les meilleurs LLM feront des erreurs lors de tÃ¢ches d'extraction complexes.
