---
translated: true
---

<a target="_blank" href="https://colab.research.google.com/github/langchain-ai/langchain/blob/master/docs/docs/integrations/callbacks/uptrain.ipynb">
  <img src="https://colab.research.google.com/assets/colab-badge.svg" alt="Ouvrir dans Colab"/>
</a>

# UpTrain

> UpTrain [[github](https://github.com/uptrain-ai/uptrain) || [site web](https://uptrain.ai/) || [documentation](https://docs.uptrain.ai/getting-started/introduction)] est une plateforme open-source pour √©valuer et am√©liorer les applications de LLM. Elle fournit des notes pour plus de 20 v√©rifications pr√©configur√©es (couvrant les cas d'utilisation du langage, du code, des embeddings), effectue des analyses des causes profondes sur les cas d'√©chec et fournit des conseils pour les r√©soudre.

## Gestionnaire de rappels UpTrain

Ce notebook pr√©sente le gestionnaire de rappels UpTrain s'int√©grant en douceur dans votre pipeline, facilitant diverses √©valuations. Nous avons choisi quelques √©valuations que nous avons jug√©es appropri√©es pour √©valuer les cha√Ænes. Ces √©valuations s'ex√©cutent automatiquement, avec les r√©sultats affich√©s dans la sortie. Plus de d√©tails sur les √©valuations d'UpTrain peuvent √™tre trouv√©s [ici](https://github.com/uptrain-ai/uptrain?tab=readme-ov-file#pre-built-evaluations-we-offer-).

Les retrievers s√©lectionn√©s de Langchain sont mis en √©vidence pour la d√©monstration :

### 1. **Vanilla RAG** :

RAG joue un r√¥le crucial dans la r√©cup√©ration du contexte et la g√©n√©ration de r√©ponses. Pour assurer ses performances et la qualit√© de ses r√©ponses, nous effectuons les √©valuations suivantes :

- **[Pertinence du contexte](https://docs.uptrain.ai/predefined-evaluations/context-awareness/context-relevance)** : D√©termine si le contexte extrait de la requ√™te est pertinent pour la r√©ponse.
- **[Exactitude factuelle](https://docs.uptrain.ai/predefined-evaluations/context-awareness/factual-accuracy)** : √âvalue si le LLM hallucine ou fournit des informations incorrectes.
- **[Exhaustivit√© de la r√©ponse](https://docs.uptrain.ai/predefined-evaluations/response-quality/response-completeness)** : V√©rifie si la r√©ponse contient toutes les informations demand√©es par la requ√™te.

### 2. **G√©n√©ration de requ√™tes multiples** :

MultiQueryRetriever cr√©e plusieurs variantes d'une question ayant un sens similaire √† la question d'origine. Compte tenu de la complexit√©, nous incluons les √©valuations pr√©c√©dentes et ajoutons :

- **[Pr√©cision des requ√™tes multiples](https://docs.uptrain.ai/predefined-evaluations/query-quality/multi-query-accuracy)** : Assure que les multi-requ√™tes g√©n√©r√©es ont le m√™me sens que la requ√™te d'origine.

### 3. **Compression et reclassement du contexte** :

Le reclassement implique le reclassement des n≈ìuds en fonction de leur pertinence par rapport √† la requ√™te et le choix des n meilleurs n≈ìuds. Comme le nombre de n≈ìuds peut √™tre r√©duit une fois le reclassement termin√©, nous effectuons les √©valuations suivantes :

- **[Reclassement du contexte](https://docs.uptrain.ai/predefined-evaluations/context-awareness/context-reranking)** : V√©rifie si l'ordre des n≈ìuds reclass√©s est plus pertinent √† la requ√™te que l'ordre d'origine.
- **[Concision du contexte](https://docs.uptrain.ai/predefined-evaluations/context-awareness/context-conciseness)** : Examine si le nombre r√©duit de n≈ìuds fournit toujours toutes les informations n√©cessaires.

Ces √©valuations assurent collectivement la robustesse et l'efficacit√© de RAG, MultiQueryRetriever et du processus de reclassement dans la cha√Æne.

## Installer les d√©pendances

```python
%pip install -qU langchain langchain_openai uptrain faiss-cpu flashrank
```

```output
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)

[33mWARNING: There was an error checking the latest version of pip.[0m[33m
[0mNote: you may need to restart the kernel to use updated packages.
```

REMARQUE : vous pouvez √©galement installer `faiss-gpu` au lieu de `faiss-cpu` si vous voulez utiliser la version activ√©e par GPU de la biblioth√®que.

## Importer les biblioth√®ques

```python
from getpass import getpass

from langchain.chains import RetrievalQA
from langchain.retrievers import ContextualCompressionRetriever
from langchain.retrievers.document_compressors import FlashrankRerank
from langchain.retrievers.multi_query import MultiQueryRetriever
from langchain_community.callbacks.uptrain_callback import UpTrainCallbackHandler
from langchain_community.document_loaders import TextLoader
from langchain_community.vectorstores import FAISS
from langchain_core.output_parsers.string import StrOutputParser
from langchain_core.prompts.chat import ChatPromptTemplate
from langchain_core.runnables.passthrough import RunnablePassthrough
from langchain_openai import ChatOpenAI, OpenAIEmbeddings
from langchain_text_splitters import (
    RecursiveCharacterTextSplitter,
)
```

## Charger les documents

```python
loader = TextLoader("../../modules/state_of_the_union.txt")
documents = loader.load()
```

## Diviser le document en morceaux

```python
text_splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=0)
chunks = text_splitter.split_documents(documents)
```

## Cr√©er le retriever

```python
embeddings = OpenAIEmbeddings()
db = FAISS.from_documents(chunks, embeddings)
retriever = db.as_retriever()
```

## D√©finir le LLM

```python
llm = ChatOpenAI(temperature=0, model="gpt-4")
```

## D√©finir la cl√© API openai

Cette cl√© est n√©cessaire pour effectuer les √©valuations. UpTrain utilise les mod√®les GPT pour √©valuer les r√©ponses g√©n√©r√©es par le LLM.

```python
OPENAI_API_KEY = getpass()
```

## Configuration

Pour chacun des retrievers ci-dessous, il est pr√©f√©rable de d√©finir √† nouveau le gestionnaire de rappels pour √©viter les interf√©rences. Vous pouvez choisir entre les options suivantes pour √©valuer √† l'aide d'UpTrain :

### 1. **Logiciel open-source (OSS) d'UpTrain** :

Vous pouvez utiliser le service d'√©valuation open-source pour √©valuer votre mod√®le.
Dans ce cas, vous devrez fournir une cl√© API OpenAI. Vous pouvez obtenir la v√¥tre [ici](https://platform.openai.com/account/api-keys).

Param√®tres :
- key_type="openai"
- api_key="OPENAI_API_KEY"
- project_name_prefix="PROJECT_NAME_PREFIX"

### 2. **Service g√©r√© et tableaux de bord d'UpTrain** :

Vous pouvez cr√©er un compte gratuit UpTrain [ici](https://uptrain.ai/) et obtenir des cr√©dits d'essai gratuits. Si vous voulez plus de cr√©dits d'essai, [r√©servez un appel avec les responsables d'UpTrain ici](https://calendly.com/uptrain-sourabh/30min).

Le service g√©r√© d'UpTrain fournit :
1. Tableaux de bord avec des options de ventilation et de filtrage avanc√©es
1. Informations et sujets courants parmi les cas d'√©chec
1. Observabilit√© et surveillance en temps r√©el des donn√©es de production
1. Tests de r√©gression via une int√©gration transparente avec vos pipelines CI/CD

Le notebook contient quelques captures d'√©cran des tableaux de bord et des informations que vous pouvez obtenir √† partir du service g√©r√© d'UpTrain.

Param√®tres :
- key_type="uptrain"
- api_key="UPTRAIN_API_KEY"
- project_name_prefix="PROJECT_NAME_PREFIX"

**Remarque :** Le `project_name_prefix` sera utilis√© comme pr√©fixe pour les noms de projet dans le tableau de bord UpTrain. Ils seront diff√©rents pour les diff√©rents types d'√©valuations. Par exemple, si vous d√©finissez project_name_prefix="langchain" et effectuez l'√©valuation multi_query, le nom du projet sera "langchain_multi_query".

# 1. Vanilla RAG

Le gestionnaire de rappels UpTrain capturera automatiquement la requ√™te, le contexte et la r√©ponse une fois g√©n√©r√©s et ex√©cutera les trois √©valuations suivantes *(not√©es de 0 √† 1)* sur la r√©ponse :
- **[Pertinence du contexte](https://docs.uptrain.ai/predefined-evaluations/context-awareness/context-relevance)** : V√©rifier si le contexte extrait de la requ√™te est pertinent pour la r√©ponse.
- **[Exactitude factuelle](https://docs.uptrain.ai/predefined-evaluations/context-awareness/factual-accuracy)** : V√©rifier la pr√©cision factuelle de la r√©ponse.
- **[Exhaustivit√© de la r√©ponse](https://docs.uptrain.ai/predefined-evaluations/response-quality/response-completeness)** : V√©rifier si la r√©ponse contient toutes les informations demand√©es par la requ√™te.

```python
# Create the RAG prompt
template = """Answer the question based only on the following context, which can include text and tables:
{context}
Question: {question}
"""
rag_prompt_text = ChatPromptTemplate.from_template(template)

# Create the chain
chain = (
    {"context": retriever, "question": RunnablePassthrough()}
    | rag_prompt_text
    | llm
    | StrOutputParser()
)

# Create the uptrain callback handler
uptrain_callback = UpTrainCallbackHandler(key_type="openai", api_key=OPENAI_API_KEY)
config = {"callbacks": [uptrain_callback]}

# Invoke the chain with a query
query = "What did the president say about Ketanji Brown Jackson"
docs = chain.invoke(query, config=config)
```

```output
[32m2024-04-17 17:03:44.969[0m | [1mINFO    [0m | [36muptrain.framework.evalllm[0m:[36mevaluate_on_server[0m:[36m378[0m - [1mSending evaluation request for rows 0 to <50 to the Uptrain[0m
[32m2024-04-17 17:04:05.809[0m | [1mINFO    [0m | [36muptrain.framework.evalllm[0m:[36mevaluate[0m:[36m367[0m - [1mLocal server not running, start the server to log data and visualize in the dashboard![0m


Question: What did the president say about Ketanji Brown Jackson
Response: The president mentioned that he had nominated Ketanji Brown Jackson to serve on the United States Supreme Court 4 days ago. He described her as one of the nation's top legal minds who will continue Justice Breyer‚Äôs legacy of excellence. He also mentioned that she is a former top litigator in private practice, a former federal public defender, and comes from a family of public school educators and police officers. He described her as a consensus builder and noted that since her nomination, she has received a broad range of support from various groups, including the Fraternal Order of Police and former judges appointed by both Democrats and Republicans.

Context Relevance Score: 1.0
Factual Accuracy Score: 1.0
Response Completeness Score: 1.0
```

# 2. G√©n√©ration de requ√™tes multiples

Le **MultiQueryRetriever** est utilis√© pour r√©soudre le probl√®me que le pipeline RAG pourrait ne pas renvoyer le meilleur ensemble de documents en fonction de la requ√™te. Il g√©n√®re plusieurs requ√™tes ayant le m√™me sens que la requ√™te d'origine, puis r√©cup√®re des documents pour chacune d'entre elles.

Pour √©valuer ce r√©cup√©rateur, UpTrain ex√©cutera l'√©valuation suivante :
- **[Pr√©cision des requ√™tes multiples](https://docs.uptrain.ai/predefined-evaluations/query-quality/multi-query-accuracy)** : V√©rifie si les requ√™tes multiples g√©n√©r√©es ont le m√™me sens que la requ√™te d'origine.

```python
# Create the retriever
multi_query_retriever = MultiQueryRetriever.from_llm(retriever=retriever, llm=llm)

# Create the uptrain callback
uptrain_callback = UpTrainCallbackHandler(key_type="openai", api_key=OPENAI_API_KEY)
config = {"callbacks": [uptrain_callback]}

# Create the RAG prompt
template = """Answer the question based only on the following context, which can include text and tables:
{context}
Question: {question}
"""
rag_prompt_text = ChatPromptTemplate.from_template(template)

chain = (
    {"context": multi_query_retriever, "question": RunnablePassthrough()}
    | rag_prompt_text
    | llm
    | StrOutputParser()
)

# Invoke the chain with a query
question = "What did the president say about Ketanji Brown Jackson"
docs = chain.invoke(question, config=config)
```

```output
[32m2024-04-17 17:04:10.675[0m | [1mINFO    [0m | [36muptrain.framework.evalllm[0m:[36mevaluate_on_server[0m:[36m378[0m - [1mSending evaluation request for rows 0 to <50 to the Uptrain[0m
[32m2024-04-17 17:04:16.804[0m | [1mINFO    [0m | [36muptrain.framework.evalllm[0m:[36mevaluate[0m:[36m367[0m - [1mLocal server not running, start the server to log data and visualize in the dashboard![0m


Question: What did the president say about Ketanji Brown Jackson
Multi Queries:
  - How did the president comment on Ketanji Brown Jackson?
  - What were the president's remarks regarding Ketanji Brown Jackson?
  - What statements has the president made about Ketanji Brown Jackson?

Multi Query Accuracy Score: 0.5

[32m2024-04-17 17:04:22.027[0m | [1mINFO    [0m | [36muptrain.framework.evalllm[0m:[36mevaluate_on_server[0m:[36m378[0m - [1mSending evaluation request for rows 0 to <50 to the Uptrain[0m
[32m2024-04-17 17:04:44.033[0m | [1mINFO    [0m | [36muptrain.framework.evalllm[0m:[36mevaluate[0m:[36m367[0m - [1mLocal server not running, start the server to log data and visualize in the dashboard![0m


Question: What did the president say about Ketanji Brown Jackson
Response: The president mentioned that he had nominated Circuit Court of Appeals Judge Ketanji Brown Jackson to serve on the United States Supreme Court 4 days ago. He described her as one of the nation's top legal minds who will continue Justice Breyer‚Äôs legacy of excellence. He also mentioned that since her nomination, she has received a broad range of support‚Äîfrom the Fraternal Order of Police to former judges appointed by Democrats and Republicans.

Context Relevance Score: 1.0
Factual Accuracy Score: 1.0
Response Completeness Score: 1.0
```

# 3. Compression et reclassement du contexte

Le processus de reclassement consiste √† r√©ordonner les n≈ìuds en fonction de leur pertinence par rapport √† la requ√™te et √† choisir les n premiers n≈ìuds. √âtant donn√© que le nombre de n≈ìuds peut √™tre r√©duit une fois le reclassement termin√©, nous effectuons les √©valuations suivantes :
- **[Reclassement du contexte](https://docs.uptrain.ai/predefined-evaluations/context-awareness/context-reranking)** : V√©rifier si l'ordre des n≈ìuds reclass√©s est plus pertinent pour la requ√™te que l'ordre d'origine.
- **[Concision du contexte](https://docs.uptrain.ai/predefined-evaluations/context-awareness/context-conciseness)** : V√©rifier si le nombre r√©duit de n≈ìuds fournit toujours toutes les informations n√©cessaires.

```python
# Create the retriever
compressor = FlashrankRerank()
compression_retriever = ContextualCompressionRetriever(
    base_compressor=compressor, base_retriever=retriever
)

# Create the chain
chain = RetrievalQA.from_chain_type(llm=llm, retriever=compression_retriever)

# Create the uptrain callback
uptrain_callback = UpTrainCallbackHandler(key_type="openai", api_key=OPENAI_API_KEY)
config = {"callbacks": [uptrain_callback]}

# Invoke the chain with a query
query = "What did the president say about Ketanji Brown Jackson"
result = chain.invoke(query, config=config)
```

```output
[32m2024-04-17 17:04:46.462[0m | [1mINFO    [0m | [36muptrain.framework.evalllm[0m:[36mevaluate_on_server[0m:[36m378[0m - [1mSending evaluation request for rows 0 to <50 to the Uptrain[0m
[32m2024-04-17 17:04:53.561[0m | [1mINFO    [0m | [36muptrain.framework.evalllm[0m:[36mevaluate[0m:[36m367[0m - [1mLocal server not running, start the server to log data and visualize in the dashboard![0m


Question: What did the president say about Ketanji Brown Jackson

Context Conciseness Score: 0.0
Context Reranking Score: 1.0

[32m2024-04-17 17:04:56.947[0m | [1mINFO    [0m | [36muptrain.framework.evalllm[0m:[36mevaluate_on_server[0m:[36m378[0m - [1mSending evaluation request for rows 0 to <50 to the Uptrain[0m
[32m2024-04-17 17:05:16.551[0m | [1mINFO    [0m | [36muptrain.framework.evalllm[0m:[36mevaluate[0m:[36m367[0m - [1mLocal server not running, start the server to log data and visualize in the dashboard![0m


Question: What did the president say about Ketanji Brown Jackson
Response: The President mentioned that he nominated Circuit Court of Appeals Judge Ketanji Brown Jackson to serve on the United States Supreme Court 4 days ago. He described her as one of the nation's top legal minds who will continue Justice Breyer‚Äôs legacy of excellence.

Context Relevance Score: 1.0
Factual Accuracy Score: 1.0
Response Completeness Score: 0.5
```
