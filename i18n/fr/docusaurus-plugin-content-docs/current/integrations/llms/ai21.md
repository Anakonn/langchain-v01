---
sidebar_label: AI21 Labs
translated: true
---

# AI21LLM

Cet exemple explique comment utiliser LangChain pour interagir avec les modèles `AI21`.

## Installation

```python
!pip install -qU langchain-ai21
```

## Configuration de l'environnement

Nous devrons obtenir une [clé API AI21](https://docs.ai21.com/) et définir la variable d'environnement `AI21_API_KEY` :

```python
import os
from getpass import getpass

os.environ["AI21_API_KEY"] = getpass()
```

## Utilisation

```python
from langchain_ai21 import AI21LLM
from langchain_core.prompts import PromptTemplate

template = """Question: {question}

Answer: Let's think step by step."""

prompt = PromptTemplate.from_template(template)

model = AI21LLM(model="j2-ultra")

chain = prompt | model

chain.invoke({"question": "What is LangChain?"})
```

```output
'\nLangChain is a (database)\nLangChain is a database for storing and processing documents'
```

# Réponse contextuelle AI21

Vous pouvez utiliser le modèle de réponses contextuelles d'AI21 pour recevoir du texte ou un document, servant de contexte,
et une question et renvoyer une réponse basée uniquement sur ce contexte.

Cela signifie que si la réponse à votre question ne se trouve pas dans le document,
le modèle l'indiquera (au lieu de fournir une réponse erronée).

```python
from langchain_ai21 import AI21ContextualAnswers

tsm = AI21ContextualAnswers()

response = tsm.invoke(input={"context": "Your context", "question": "Your question"})
```

Vous pouvez également l'utiliser avec des chaînes, des parseurs de sortie et des bases de données vectorielles.

```python
from langchain_ai21 import AI21ContextualAnswers
from langchain_core.output_parsers import StrOutputParser

tsm = AI21ContextualAnswers()
chain = tsm | StrOutputParser()

response = chain.invoke(
    {"context": "Your context", "question": "Your question"},
)
```
