---
keywords:
- compatibilité
sidebar_class_name: hidden
sidebar_position: 1
translated: true
---

# LLMs

## Fonctionnalités (prises en charge nativement)

Tous les LLM implémentent l'interface Runnable, qui comprend des implémentations par défaut de toutes les méthodes, c'est-à-dire `ainvoke`, `batch`, `abatch`, `stream`, `astream`. Cela donne à tous les LLM un support de base pour l'asynchrone, le streaming et le batch, qui par défaut est implémenté comme suit :
- Le support *asynchrone* se résume par défaut à appeler la méthode synchrone respective dans l'exécuteur de thread du pool par défaut d'asyncio. Cela permet à d'autres fonctions asynchrones de votre application de progresser pendant que le LLM est en cours d'exécution, en déplaçant cet appel dans un thread d'arrière-plan.
- Le support du *streaming* se résume par défaut à renvoyer un `Iterator` (ou un `AsyncIterator` dans le cas du streaming asynchrone) d'une seule valeur, le résultat final renvoyé par le fournisseur LLM sous-jacent. Cela ne vous donne évidemment pas de streaming token par token, ce qui nécessite un support natif du fournisseur LLM, mais garantit que votre code qui s'attend à un itérateur de tokens peut fonctionner pour n'importe laquelle de nos intégrations LLM.
- Le support du *batch* se résume par défaut à appeler le LLM sous-jacent en parallèle pour chaque entrée en utilisant un exécuteur de pool de threads (dans le cas du batch synchrone) ou `asyncio.gather` (dans le cas du batch asynchrone). La concurrence peut être contrôlée avec la clé `max_concurrency` dans `RunnableConfig`.

Chaque intégration LLM peut éventuellement fournir des implémentations natives pour l'asynchrone, le streaming ou le batch, qui, pour les fournisseurs qui le prennent en charge, peuvent être plus efficaces. Le tableau indique, pour chaque intégration, quelles fonctionnalités ont été implémentées avec un support natif.

Modèle|Invoke|Invoke asynchrone|Stream|Stream asynchrone|Batch|Batch asynchrone
:-|:-:|:-:|:-:|:-:|:-:|:-:
AI21|✅|❌|❌|❌|❌|❌
AlephAlpha|✅|❌|❌|❌|❌|❌
AmazonAPIGateway|✅|❌|❌|❌|❌|❌
Anthropic|✅|✅|✅|✅|❌|❌
Anyscale|✅|✅|✅|✅|✅|✅
Aphrodite|✅|❌|❌|❌|✅|❌
Arcee|✅|❌|❌|❌|❌|❌
Aviary|✅|❌|❌|❌|❌|❌
AzureMLOnlineEndpoint|✅|❌|❌|❌|✅|❌
AzureOpenAI|✅|✅|✅|✅|✅|✅
BaichuanLLM|✅|❌|❌|❌|❌|❌
Banana|✅|❌|❌|❌|❌|❌
Baseten|✅|❌|❌|❌|❌|❌
Beam|✅|❌|❌|❌|❌|❌
Bedrock|✅|✅|✅|✅|❌|❌
CTransformers|✅|✅|❌|❌|❌|❌
CTranslate2|✅|❌|❌|❌|✅|❌
CerebriumAI|✅|❌|❌|❌|❌|❌
ChatGLM|✅|❌|❌|❌|❌|❌
Clarifai|✅|❌|❌|❌|❌|❌
Cohere|✅|✅|❌|❌|❌|❌
Databricks|✅|❌|❌|❌|❌|❌
DeepInfra|✅|✅|✅|✅|❌|❌
DeepSparse|✅|✅|✅|✅|❌|❌
EdenAI|✅|✅|❌|❌|❌|❌
Fireworks|✅|✅|✅|✅|✅|✅
ForefrontAI|✅|❌|❌|❌|❌|❌
Friendli|✅|✅|✅|✅|❌|❌
GPT4All|✅|❌|❌|❌|❌|❌
GigaChat|✅|✅|✅|✅|✅|✅
GooglePalm|✅|❌|✅|❌|✅|❌
GooseAI|✅|❌|❌|❌|❌|❌
GradientLLM|✅|✅|❌|❌|✅|✅
HuggingFaceEndpoint|✅|✅|✅|✅|❌|❌
HuggingFaceHub|✅|❌|❌|❌|❌|❌
HuggingFacePipeline|✅|❌|❌|❌|✅|❌
HuggingFaceTextGenInference|✅|✅|✅|✅|❌|❌
HumanInputLLM|✅|❌|❌|❌|❌|❌
IpexLLM|✅|❌|❌|❌|❌|❌
JavelinAIGateway|✅|✅|❌|❌|❌|❌
KoboldApiLLM|✅|❌|❌|❌|❌|❌
Konko|✅|✅|❌|❌|❌|❌
LlamaCpp|✅|❌|✅|❌|❌|❌
Llamafile|✅|❌|✅|❌|❌|❌
MLXPipeline|✅|❌|✅|❌|❌|❌
ManifestWrapper|✅|❌|❌|❌|❌|❌
Minimax|✅|❌|❌|❌|❌|❌
Mlflow|✅|❌|❌|❌|❌|❌
MlflowAIGateway|✅|❌|❌|❌|❌|❌
Modal|✅|❌|❌|❌|❌|❌
MosaicML|✅|❌|❌|❌|❌|❌
NIBittensorLLM|✅|❌|❌|❌|❌|❌
NLPCloud|✅|❌|❌|❌|❌|❌
Nebula|✅|❌|❌|❌|❌|❌
OCIGenAI|✅|❌|❌|❌|❌|❌
OCIModelDeploymentTGI|✅|❌|❌|❌|❌|❌
OCIModelDeploymentVLLM|✅|❌|❌|❌|❌|❌
OctoAIEndpoint|✅|✅|✅|✅|✅|✅
Ollama|✅|❌|❌|❌|❌|❌
OpaquePrompts|✅|❌|❌|❌|❌|❌
OpenAI|✅|✅|✅|✅|✅|✅
OpenLLM|✅|✅|❌|❌|❌|❌
OpenLM|✅|✅|✅|✅|✅|✅
PaiEasEndpoint|✅|❌|✅|❌|❌|❌
Petals|✅|❌|❌|❌|❌|❌
PipelineAI|✅|❌|❌|❌|❌|❌
Predibase|✅|❌|❌|❌|❌|❌
PredictionGuard|✅|❌|❌|❌|❌|❌
PromptLayerOpenAI|✅|❌|❌|❌|❌|❌
QianfanLLMEndpoint|✅|✅|✅|✅|❌|❌
RWKV|✅|❌|❌|❌|❌|❌
Replicate|✅|❌|✅|❌|❌|❌
SagemakerEndpoint|✅|❌|❌|❌|❌|❌
SambaStudio|✅|❌|✅|❌|❌|❌
Sambaverse|✅|❌|✅|❌|❌|❌
SelfHostedHuggingFaceLLM|✅|❌|❌|❌|❌|❌
SelfHostedPipeline|✅|❌|❌|❌|❌|❌
SparkLLM|✅|❌|✅|❌|❌|❌
StochasticAI|✅|❌|❌|❌|❌|❌
TextGen|✅|❌|❌|❌|❌|❌
TitanTakeoff|✅|❌|✅|❌|❌|❌
TitanTakeoffPro|✅|❌|✅|❌|❌|❌
Together|✅|✅|❌|❌|❌|❌
Tongyi|✅|✅|✅|✅|✅|✅
VLLM|✅|❌|❌|❌|✅|❌
VLLMOpenAI|✅|✅|✅|✅|✅|✅
VertexAI|✅|✅|✅|❌|✅|✅
VertexAIModelGarden|✅|✅|❌|❌|✅|✅
VolcEngineMaasLLM|✅|❌|✅|❌|❌|❌
WatsonxLLM|✅|❌|✅|❌|✅|❌
WeightOnlyQuantPipeline|✅|❌|❌|❌|❌|❌
Writer|✅|❌|❌|❌|❌|❌
Xinference|✅|❌|❌|❌|❌|❌
YandexGPT|✅|✅|❌|❌|❌|❌
Yuan2|✅|❌|❌|❌|❌|❌
