---
translated: true
---

# PremAI

>[PremAI](https://app.premai.io) est une plateforme unifi√©e qui vous permet de construire des applications puissantes et pr√™tes pour la production avec GenAI avec le moins d'efforts possible, afin que vous puissiez vous concentrer davantage sur l'exp√©rience utilisateur et la croissance globale. Dans cette section, nous allons discuter de la fa√ßon dont nous pouvons acc√©der √† diff√©rents mod√®les d'int√©gration √† l'aide de `PremAIEmbeddings`.

## Installation et configuration

Nous commen√ßons par installer langchain et premai-sdk. Vous pouvez taper la commande suivante pour installer :

```bash
pip install premai langchain
```

Avant d'aller plus loin, assurez-vous d'avoir cr√©√© un compte sur Prem et d√©marr√© un projet. Sinon, voici comment vous pouvez commencer gratuitement :

1. Connectez-vous √† [PremAI](https://app.premai.io/accounts/login/), si c'est votre premi√®re visite, et cr√©ez votre cl√© API [ici](https://app.premai.io/api_keys/).

2. Allez sur [app.premai.io](https://app.premai.io) et cela vous am√®nera au tableau de bord du projet.

3. Cr√©ez un projet et cela g√©n√©rera un ID de projet (√©crit sous forme d'ID). Cet ID vous aidera √† interagir avec votre application d√©ploy√©e.

F√©licitations pour la cr√©ation de votre premi√®re application d√©ploy√©e sur Prem üéâ Maintenant, nous pouvons utiliser langchain pour interagir avec notre application.

```python
# Let's start by doing some imports and define our embedding object

from langchain_community.embeddings import PremAIEmbeddings
```

Une fois que nous avons import√© nos modules requis, configurons notre client. Pour l'instant, supposons que notre `project_id` est 8. Mais assurez-vous d'utiliser votre ID de projet, sinon cela g√©n√©rera une erreur.

```python
import getpass
import os

if os.environ.get("PREMAI_API_KEY") is None:
    os.environ["PREMAI_API_KEY"] = getpass.getpass("PremAI API Key:")
```

```python
model = "text-embedding-3-large"
embedder = PremAIEmbeddings(project_id=8, model=model)
```

Nous avons d√©fini notre mod√®le d'int√©gration. Nous prenons en charge de nombreux mod√®les d'int√©gration. Voici un tableau qui montre le nombre de mod√®les d'int√©gration que nous prenons en charge.

| Fournisseur | Slug                                     | Jetons de contexte |
|-------------|------------------------------------------|-------------------|
| cohere      | embed-english-v3.0                       | N/A               |
| openai      | text-embedding-3-small                   | 8191              |
| openai      | text-embedding-3-large                   | 8191              |
| openai      | text-embedding-ada-002                   | 8191              |
| replicate   | replicate/all-mpnet-base-v2              | N/A               |
| together    | togethercomputer/Llama-2-7B-32K-Instruct | N/A               |
| mistralai   | mistral-embed                            | 4096              |

Pour changer de mod√®le, il vous suffit de copier le `slug` et d'acc√©der √† votre mod√®le d'int√©gration. Maintenant, commen√ßons √† utiliser notre mod√®le d'int√©gration avec une seule requ√™te suivie de plusieurs requ√™tes (√©galement appel√©es document).

```python
query = "Hello, this is a test query"
query_result = embedder.embed_query(query)

# Let's print the first five elements of the query embedding vector

print(query_result[:5])
```

```output
[-0.02129288576543331, 0.0008162345038726926, -0.004556538071483374, 0.02918623760342598, -0.02547479420900345]
```

Enfin, int√©grons un document

```python
documents = ["This is document1", "This is document2", "This is document3"]

doc_result = embedder.embed_documents(documents)

# Similar to previous result, let's print the first five element
# of the first document vector

print(doc_result[0][:5])
```

```output
[-0.0030691148713231087, -0.045334383845329285, -0.0161729846149683, 0.04348714277148247, -0.0036920777056366205]
```
