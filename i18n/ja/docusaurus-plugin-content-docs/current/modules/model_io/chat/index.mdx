---
sidebar_class_name: hidden
sidebar_position: 3
translated: true
---

# チャットモデル

チャットモデルは、LangChainの中核的なコンポーネントです。

チャットモデルは、チャットメッセージを入力として使用し、チャットメッセージを出力として返す言語モデルです(プレーンテキストを使用するのとは対照的です)。

LangChainには多くのモデルプロバイダー(OpenAI、Cohere、Hugging Faceなど)との統合があり、これらすべてのモデルとやり取りするための標準インターフェイスを提供しています。

LangChainでは、同期、非同期、バッチ処理、ストリーミングモードでモデルを使用できるほか、キャッシングなどの機能も提供しています。

## [クイックスタート](./quick_start)

[このクイックスタート](./quick_start)を確認して、ChatModelsの使用方法の概要を把握してください。様々なメソッドを紹介しています。

## [統合](/docs/integrations/chat/)

LangChainが提供するすべてのLLM統合の一覧については、[統合ページ](/docs/integrations/chat/)をご覧ください。

## ハウツーガイド

LLMの高度な使用方法については、いくつかのハウツーガイドをご用意しています。
これには以下が含まれます:

- [ChatModelの応答をキャッシュする方法](./chat_model_caching)
- [関数呼び出しをサポートするChatModelsの使用方法](./function_calling)
- [ChatModelからの応答をストリーミングする方法](./streaming)
- [ChatModel呼び出しでトークン使用量を追跡する方法](./token_usage_tracking)
- [カスタムChatModelを作成する方法](./custom_chat_model)
