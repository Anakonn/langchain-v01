---
fixed: true
translated: true
---

# ğŸ¦œğŸ•¸ï¸LangGraph

[![Downloads](https://static.pepy.tech/badge/langgraph/month)](https://pepy.tech/project/langgraph)
[![Open Issues](https://img.shields.io/github/issues-raw/langchain-ai/langgraph)](https://github.com/langchain-ai/langgraph/issues)
[![](https://dcbadge.vercel.app/api/server/6adMQxSpJS?compact=true&style=flat)](https://discord.com/channels/1038097195422978059/1170024642245832774)
[![Docs](https://img.shields.io/badge/docs-latest-blue)](https://langchain-ai.github.io/langgraph/)

âš¡ è¨€èªã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆã‚’ã‚°ãƒ©ãƒ•ã¨ã—ã¦æ§‹ç¯‰ âš¡

## æ¦‚è¦

[LangGraph](https://langchain-ai.github.io/langgraph/) ã¯ã€LLMsã‚’ä½¿ç”¨ã—ã¦ã‚¹ãƒ†ãƒ¼ãƒˆãƒ•ãƒ«ãªãƒãƒ«ãƒã‚¢ã‚¯ã‚¿ãƒ¼ã‚¢ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³ã‚’æ§‹ç¯‰ã™ã‚‹ãŸã‚ã®ãƒ©ã‚¤ãƒ–ãƒ©ãƒªã§ã™ã€‚
[Pregel](https://research.google/pubs/pub37252/) ã¨ [Apache Beam](https://beam.apache.org/) ã«è§¦ç™ºã•ã‚Œã€LangGraphã¯é€šå¸¸ã®Pythoné–¢æ•°ï¼ˆã¾ãŸã¯ [JS](https://github.com/langchain-ai/langgraphjs))ï¼‰ã‚’ä½¿ç”¨ã—ã¦ã€ã‚µã‚¤ã‚¯ãƒ«è¨ˆç®—ã‚¹ãƒ†ãƒƒãƒ—å…¨ä½“ã«ã‚ãŸã£ã¦è¤‡æ•°ã®ãƒã‚§ãƒ¼ãƒ³ï¼ˆã¾ãŸã¯ã‚¢ã‚¯ã‚¿ãƒ¼ï¼‰ã‚’èª¿æ•´ãŠã‚ˆã³ãƒã‚§ãƒƒã‚¯ãƒã‚¤ãƒ³ãƒˆã™ã‚‹ã“ã¨ãŒã§ãã¾ã™ã€‚å…¬é–‹ã‚¤ãƒ³ã‚¿ãƒ¼ãƒ•ã‚§ãƒ¼ã‚¹ã¯ [NetworkX](https://networkx.org/documentation/latest/) ã«è§¦ç™ºã•ã‚Œã¦ã„ã¾ã™ã€‚

ä¸»ãªç”¨é€”ã¯ã€LLMã‚¢ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³ã«**ã‚µã‚¤ã‚¯ãƒ«**ã¨**æŒç¶šæ€§**ã‚’è¿½åŠ ã™ã‚‹ã“ã¨ã§ã™ã€‚è¿…é€Ÿãªæœ‰å‘éå·¡å›ã‚°ãƒ©ãƒ•ï¼ˆDAGï¼‰ã ã‘ãŒå¿…è¦ãªå ´åˆã¯ã€[LangChain Expression Language](https://python.langchain.com/docs/expression_language/) ã‚’ä½¿ç”¨ã—ã¦ã“ã‚Œã‚’é”æˆã§ãã¾ã™ã€‚

ã‚µã‚¤ã‚¯ãƒ«ã¯ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆã®è¡Œå‹•ã«é‡è¦ã§ã€LLMã‚’ãƒ«ãƒ¼ãƒ—å†…ã§å‘¼ã³å‡ºã—ã€æ¬¡ã«å–ã‚‹ã¹ãã‚¢ã‚¯ã‚·ãƒ§ãƒ³ã‚’å°‹ã­ã‚‹å ´åˆã«å¿…è¦ã§ã™ã€‚

## ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«

```shell
pip install -U langgraph
```

## ã‚¯ã‚¤ãƒƒã‚¯ã‚¹ã‚¿ãƒ¼ãƒˆ

LangGraphã®ä¸­å¿ƒçš„ãªæ¦‚å¿µã®ä¸€ã¤ã¯çŠ¶æ…‹ã§ã™ã€‚å„ã‚°ãƒ©ãƒ•å®Ÿè¡Œã¯çŠ¶æ…‹ã‚’ä½œæˆã—ã€ã‚°ãƒ©ãƒ•å†…ã®ãƒãƒ¼ãƒ‰ãŒå®Ÿè¡Œã•ã‚Œã‚‹éš›ã«ãã®çŠ¶æ…‹ãŒãƒãƒ¼ãƒ‰é–“ã§æ¸¡ã•ã‚Œã¾ã™ã€‚å„ãƒãƒ¼ãƒ‰ã¯å®Ÿè¡Œå¾Œã«ãã®æˆ»ã‚Šå€¤ã§å†…éƒ¨çŠ¶æ…‹ã‚’æ›´æ–°ã—ã¾ã™ã€‚ã‚°ãƒ©ãƒ•ãŒå†…éƒ¨çŠ¶æ…‹ã‚’æ›´æ–°ã™ã‚‹æ–¹æ³•ã¯ã€é¸æŠã•ã‚ŒãŸã‚°ãƒ©ãƒ•ã®ç¨®é¡ã¾ãŸã¯ã‚«ã‚¹ã‚¿ãƒ é–¢æ•°ã«ã‚ˆã£ã¦å®šç¾©ã•ã‚Œã¾ã™ã€‚

LangGraphã®çŠ¶æ…‹ã¯ã‹ãªã‚Šä¸€èˆ¬çš„ã«ã§ãã¾ã™ãŒã€ç°¡å˜ã«å§‹ã‚ã‚‹ãŸã‚ã«ã€çµ„ã¿è¾¼ã¿ã® `MessageGraph` ã‚¯ãƒ©ã‚¹ã‚’ä½¿ç”¨ã—ã¦ã€ã‚°ãƒ©ãƒ•ã®çŠ¶æ…‹ãŒãƒãƒ£ãƒƒãƒˆãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã®ãƒªã‚¹ãƒˆã«é™å®šã•ã‚Œã‚‹ä¾‹ã‚’ç¤ºã—ã¾ã™ã€‚ã“ã‚Œã¯ã€LangGraphã‚’LangChainãƒãƒ£ãƒƒãƒˆãƒ¢ãƒ‡ãƒ«ã¨ä¸€ç·’ã«ä½¿ç”¨ã™ã‚‹å ´åˆã«ä¾¿åˆ©ã§ã€ãƒãƒ£ãƒƒãƒˆãƒ¢ãƒ‡ãƒ«ã®å‡ºåŠ›ã‚’ç›´æ¥è¿”ã™ã“ã¨ãŒã§ãã¾ã™ã€‚

ã¾ãšã€LangChain OpenAIçµ±åˆãƒ‘ãƒƒã‚±ãƒ¼ã‚¸ã‚’ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«ã—ã¾ã™ï¼š

```python
pip install langchain_openai
```

ã¾ãŸã€ã„ãã¤ã‹ã®ç’°å¢ƒå¤‰æ•°ã‚’ã‚¨ã‚¯ã‚¹ãƒãƒ¼ãƒˆã™ã‚‹å¿…è¦ãŒã‚ã‚Šã¾ã™ï¼š

```shell
export OPENAI_API_KEY=sk-...
```

ãã—ã¦ã€æº–å‚™å®Œäº†ã§ã™ï¼ä»¥ä¸‹ã®ã‚°ãƒ©ãƒ•ã«ã¯ã€ãƒãƒ£ãƒƒãƒˆãƒ¢ãƒ‡ãƒ«ã‚’å®Ÿè¡Œã—ã€çµæœã‚’è¿”ã™å˜ä¸€ã®ãƒãƒ¼ãƒ‰ `"oracle"` ãŒå«ã¾ã‚Œã¦ã„ã¾ã™ï¼š

```python
<!--IMPORTS:[{"imported": "ChatOpenAI", "source": "langchain_openai", "docs": "https://api.python.langchain.com/en/latest/chat_models/langchain_openai.chat_models.base.ChatOpenAI.html", "title": "\ud83e\udd9c\ud83d\udd78\ufe0fLangGraph"}, {"imported": "HumanMessage", "source": "langchain_core.messages", "docs": "https://api.python.langchain.com/en/latest/messages/langchain_core.messages.human.HumanMessage.html", "title": "\ud83e\udd9c\ud83d\udd78\ufe0fLangGraph"}]-->
from langchain_openai import ChatOpenAI
from langchain_core.messages import HumanMessage
from langgraph.graph import END, MessageGraph

model = ChatOpenAI(temperature=0)

graph = MessageGraph()

graph.add_node("oracle", model)
graph.add_edge("oracle", END)

graph.set_entry_point("oracle")

runnable = graph.compile()
```

å®Ÿè¡Œã—ã¦ã¿ã¾ã—ã‚‡ã†ï¼

```python
runnable.invoke(HumanMessage("What is 1 + 1?"))
```

```python
[HumanMessage(content='What is 1 + 1?'), AIMessage(content='1 + 1 equals 2.')]
```

ã“ã“ã§ä½•ã‚’ã—ãŸã®ã‹ã‚’ã‚¹ãƒ†ãƒƒãƒ—ãƒã‚¤ã‚¹ãƒ†ãƒƒãƒ—ã§èª¬æ˜ã—ã¾ã™ï¼š

1. ã¾ãšã€ãƒ¢ãƒ‡ãƒ«ã¨ `MessageGraph` ã‚’åˆæœŸåŒ–ã—ã¾ã™ã€‚
2. æ¬¡ã«ã€ä¸ãˆã‚‰ã‚ŒãŸå…¥åŠ›ã§ãƒ¢ãƒ‡ãƒ«ã‚’å‘¼ã³å‡ºã™ã ã‘ã®å˜ä¸€ã®ãƒãƒ¼ãƒ‰ `"oracle"` ã‚’ã‚°ãƒ©ãƒ•ã«è¿½åŠ ã—ã¾ã™ã€‚
3. ã“ã® `"oracle"` ãƒãƒ¼ãƒ‰ã‹ã‚‰ç‰¹åˆ¥ãªæ–‡å­—åˆ— `END`ï¼ˆ`"__end__"`ï¼‰ã¸ã®ã‚¨ãƒƒã‚¸ã‚’è¿½åŠ ã—ã¾ã™ã€‚ã“ã‚Œã«ã‚ˆã‚Šã€ç¾åœ¨ã®ãƒãƒ¼ãƒ‰ã®å¾Œã«å®Ÿè¡ŒãŒçµ‚äº†ã—ã¾ã™ã€‚
4. `"oracle"` ã‚’ã‚°ãƒ©ãƒ•ã®ã‚¨ãƒ³ãƒˆãƒªãƒ¼ãƒã‚¤ãƒ³ãƒˆã¨ã—ã¦è¨­å®šã—ã¾ã™ã€‚
5. ã‚°ãƒ©ãƒ•ã‚’ã‚³ãƒ³ãƒ‘ã‚¤ãƒ«ã—ã€ä½ãƒ¬ãƒ™ãƒ«ã® [Pregelæ“ä½œ](https://research.google/pubs/pregel-a-system-for-large-scale-graph-processing/) ã«å¤‰æ›ã—ã¦å®Ÿè¡Œå¯èƒ½ã«ã—ã¾ã™ã€‚

æ¬¡ã«ã€ã‚°ãƒ©ãƒ•ã‚’å®Ÿè¡Œã™ã‚‹ã¨ï¼š

1. LangGraphã¯å…¥åŠ›ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã‚’å†…éƒ¨çŠ¶æ…‹ã«è¿½åŠ ã—ã€ãã®çŠ¶æ…‹ã‚’ã‚¨ãƒ³ãƒˆãƒªãƒ¼ãƒã‚¤ãƒ³ãƒˆãƒãƒ¼ãƒ‰ `"oracle"` ã«æ¸¡ã—ã¾ã™ã€‚
2. `"oracle"` ãƒãƒ¼ãƒ‰ãŒå®Ÿè¡Œã•ã‚Œã€ãƒãƒ£ãƒƒãƒˆãƒ¢ãƒ‡ãƒ«ã‚’å‘¼ã³å‡ºã—ã¾ã™ã€‚
3. ãƒãƒ£ãƒƒãƒˆãƒ¢ãƒ‡ãƒ«ãŒ `AIMessage` ã‚’è¿”ã—ã¾ã™ã€‚LangGraphã¯ã“ã‚Œã‚’çŠ¶æ…‹ã«è¿½åŠ ã—ã¾ã™ã€‚
4. å®Ÿè¡ŒãŒç‰¹åˆ¥ãª `END` å€¤ã«é€²ã¿ã€æœ€çµ‚çŠ¶æ…‹ã‚’å‡ºåŠ›ã—ã¾ã™ã€‚

çµæœã¨ã—ã¦ã€2ã¤ã®ãƒãƒ£ãƒƒãƒˆãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã®ãƒªã‚¹ãƒˆãŒå‡ºåŠ›ã•ã‚Œã¾ã™ã€‚

### LCELã¨ã®ç›¸äº’ä½œç”¨

LangChainã«æ—¢ã«ç²¾é€šã—ã¦ã„ã‚‹æ–¹ã¸ã®å‚è€ƒã¨ã—ã¦ã€`add_node` ã¯å®Ÿéš›ã«ã¯ä»»æ„ã®é–¢æ•°ã¾ãŸã¯ [runnable](https://python.langchain.com/docs/expression_language/interface/) ã‚’å…¥åŠ›ã¨ã—ã¦å—ã‘å–ã‚Šã¾ã™ã€‚ä¸Šè¨˜ã®ä¾‹ã§ã¯ã€ãƒ¢ãƒ‡ãƒ«ã¯ "as-is" ã§ä½¿ç”¨ã•ã‚Œã¦ã„ã¾ã™ãŒã€é–¢æ•°ã‚’æ¸¡ã™ã“ã¨ã‚‚ã§ãã¾ã™ï¼š

```python
def call_oracle(messages: list):
    return model.invoke(messages)

graph.add_node("oracle", call_oracle)
```

ãŸã ã—ã€[runnable](https://python.langchain.com/docs/expression_language/interface/) ã¸ã®å…¥åŠ›ã¯**ç¾åœ¨ã®å…¨çŠ¶æ…‹**ã§ã‚ã‚‹ã“ã¨ã‚’å¿µé ­ã«ç½®ã„ã¦ãã ã•ã„ã€‚ã—ãŸãŒã£ã¦ã€ã“ã‚Œã¯å¤±æ•—ã—ã¾ã™ï¼š

```python
<!--IMPORTS:[{"imported": "ChatPromptTemplate", "source": "langchain_core.prompts", "docs": "https://api.python.langchain.com/en/latest/prompts/langchain_core.prompts.chat.ChatPromptTemplate.html", "title": "\ud83e\udd9c\ud83d\udd78\ufe0fLangGraph"}, {"imported": "MessagesPlaceholder", "source": "langchain_core.prompts", "docs": "https://api.python.langchain.com/en/latest/prompts/langchain_core.prompts.chat.MessagesPlaceholder.html", "title": "\ud83e\udd9c\ud83d\udd78\ufe0fLangGraph"}]-->
# This will not work with MessageGraph!
from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder

prompt = ChatPromptTemplate.from_messages([
    ("system", "You are a helpful assistant named {name} who always speaks in pirate dialect"),
    MessagesPlaceholder(variable_name="messages"),
])

chain = prompt | model

# State is a list of messages, but our chain expects a dict input:
#
# { "name": some_string, "messages": [] }
#
# Therefore, the graph will throw an exception when it executes here.
graph.add_node("oracle", chain)
```

## æ¡ä»¶ä»˜ãã‚¨ãƒƒã‚¸

ã•ã¦ã€ã‚‚ã†å°‘ã—è¤‡é›‘ãªã‚‚ã®ã«é€²ã¿ã¾ã—ã‚‡ã†ã€‚LLMsã¯æ•°å­¦ã«è‹¦åŠ´ã™ã‚‹ã®ã§ã€LLMãŒæ¡ä»¶ä»˜ãã§ `"multiply"` ãƒãƒ¼ãƒ‰ã‚’å‘¼ã³å‡ºã—ã€[tool calling](https://python.langchain.com/docs/modules/model_io/chat/function_calling/) ã‚’ä½¿ç”¨ã—ã¦çµæœã‚’è¨ˆç®—ã§ãã‚‹ã‚ˆã†ã«ã—ã¾ã™ã€‚

æœ€è¿‘ã®ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ãŒãƒ„ãƒ¼ãƒ«ã‚³ãƒ¼ãƒ«ã§ã‚ã‚‹å ´åˆã€ãã®çµæœã‚’è¨ˆç®—ã™ã‚‹ãŸã‚ã«è¿½åŠ ã® `"multiply"` ãƒãƒ¼ãƒ‰ã‚’æŒã¤ã‚°ãƒ©ãƒ•ã‚’å†ä½œæˆã—ã¾ã™ã€‚
ã¾ãŸã€ãƒ„ãƒ¼ãƒ«ã‚’å¿…è¦ã«å¿œã˜ã¦ä½¿ç”¨ã§ãã‚‹ã‚ˆã†ã«ã™ã‚‹ãŸã‚ã«ã€OpenAIãƒ¢ãƒ‡ãƒ«ã«é›»å“ã®ã‚¹ã‚­ãƒ¼ãƒã‚’ãƒ„ãƒ¼ãƒ«ã¨ã—ã¦[bind](https://api.python.langchain.com/en/latest/chat_models/langchain_openai.chat_models.base.ChatOpenAI.html#langchain_openai.chat_models.base.ChatOpenAI.bind_tools) ã—ã¾ã™ï¼š

```python
<!--IMPORTS:[{"imported": "tool", "source": "langchain_core.tools", "docs": "https://api.python.langchain.com/en/latest/tools/langchain_core.tools.tool.html", "title": "\ud83e\udd9c\ud83d\udd78\ufe0fLangGraph"}]-->
from langchain_core.tools import tool
from langgraph.prebuilt import ToolNode

@tool
def multiply(first_number: int, second_number: int):
    """Multiplies two numbers together."""
    return first_number * second_number

model = ChatOpenAI(temperature=0)
model_with_tools = model.bind_tools([multiply])

builder = MessageGraph()

builder.add_node("oracle", model_with_tools)

tool_node = ToolNode([multiply])
builder.add_node("multiply", tool_node)

builder.add_edge("multiply", END)

builder.set_entry_point("oracle")
```

ã§ã¯ã€ä½•ãŒèµ·ã“ã‚‹ã¹ãã‹è€ƒãˆã¦ã¿ã¾ã—ã‚‡ã†ã€‚

- `"oracle"` ãƒãƒ¼ãƒ‰ãŒãƒ„ãƒ¼ãƒ«ã‚³ãƒ¼ãƒ«ã‚’æœŸå¾…ã™ã‚‹ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã‚’è¿”ã™å ´åˆã€`"multiply"` ãƒãƒ¼ãƒ‰ã‚’å®Ÿè¡Œã—ãŸã„
- ãã†ã§ãªã„å ´åˆã€å®Ÿè¡Œã‚’çµ‚äº†ã§ãã¾ã™

ã“ã‚Œã‚’**æ¡ä»¶ä»˜ãã‚¨ãƒƒã‚¸**ã‚’ä½¿ç”¨ã—ã¦é”æˆã§ãã¾ã™ã€‚æ¡ä»¶ä»˜ãã‚¨ãƒƒã‚¸ã¯ã€ç¾åœ¨ã®çŠ¶æ…‹ã«é–¢æ•°ã‚’å‘¼ã³å‡ºã—ã€ãã®é–¢æ•°ã®å‡ºåŠ›ã«åŸºã¥ã„ã¦ãƒãƒ¼ãƒ‰ã¸ã®å®Ÿè¡Œã‚’ãƒ«ãƒ¼ãƒ†ã‚£ãƒ³ã‚°ã—ã¾ã™ã€‚

ãã®ä¾‹ãŒã“ã¡ã‚‰ã§ã™ï¼š

```python
from typing import Literal

def router(state: List[BaseMessage]) -> Literal["multiply", "__end__"]:
    tool_calls = state[-1].additional_kwargs.get("tool_calls", [])
    if len(tool_calls):
        return "multiply"
    else:
        return "__end__"

builder.add_conditional_edges("oracle", router)
```

ãƒ¢ãƒ‡ãƒ«ã®å‡ºåŠ›ã«ãƒ„ãƒ¼ãƒ«ã‚³ãƒ¼ãƒ«ãŒå«ã¾ã‚Œã¦ã„ã‚‹å ´åˆã€`"multiply"` ãƒãƒ¼ãƒ‰ã«ç§»å‹•ã—ã¾ã™ã€‚ãã†ã§ãªã„å ´åˆã€å®Ÿè¡Œã‚’çµ‚äº†ã—ã¾ã™ã€‚

ç´ æ™´ã‚‰ã—ã„ï¼æ®‹ã‚‹ã¯ã‚°ãƒ©ãƒ•ã‚’ã‚³ãƒ³ãƒ‘ã‚¤ãƒ«ã—ã¦è©¦ã—ã¦ã¿ã‚‹ã“ã¨ã ã‘ã§ã™ã€‚æ•°å­¦é–¢é€£ã®è³ªå•ã¯é›»å“ãƒ„ãƒ¼ãƒ«ã«ãƒ«ãƒ¼ãƒ†ã‚£ãƒ³ã‚°ã•ã‚Œã¾ã™ï¼š

```python
runnable = builder.compile()

runnable.invoke(HumanMessage("What is 123 * 456?"))
```

```output

[HumanMessage(content='What is 123 * 456?'),
 AIMessage(content='', additional_kwargs={'tool_calls': [{'id': 'call_OPbdlm8Ih1mNOObGf3tMcNgb', 'function': {'arguments': '{"first_number":123,"second_number":456}', 'name': 'multiply'}, 'type': 'function'}]}),
 ToolMessage(content='56088', tool_call_id='call_OPbdlm8Ih1mNOObGf3tMcNgb')]
```

å¯¾è©±çš„ãªå¿œç­”ã¯ç›´æ¥å‡ºåŠ›ã•ã‚Œã¾ã™ï¼š

```python
runnable.invoke(HumanMessage("What is your name?"))
```

```output
[HumanMessage(content='What is your name?'),
 AIMessage(content='My name is Assistant. How can I assist you today?')]
```

## ã‚µã‚¤ã‚¯ãƒ«

ã§ã¯ã€ã‚ˆã‚Šä¸€èˆ¬çš„ãªã‚µã‚¤ã‚¯ãƒ«ã®ä¾‹ã‚’è¦‹ã¦ã¿ã¾ã—ã‚‡ã†ã€‚LangChainã® `AgentExecutor` ã‚¯ãƒ©ã‚¹ã‚’å†ä½œæˆã—ã¾ã™ã€‚ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆè‡ªä½“ã¯ãƒãƒ£ãƒƒãƒˆãƒ¢ãƒ‡ãƒ«ã¨ãƒ„ãƒ¼ãƒ«ã‚³ãƒ¼ãƒ«ã‚’ä½¿ç”¨ã—ã¾ã™ã€‚
ã“ã®ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆã¯ã™ã¹ã¦ã®çŠ¶æ…‹ã‚’ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã®ãƒªã‚¹ãƒˆã¨ã—ã¦è¡¨ã—ã¾ã™ã€‚

ã„ãã¤ã‹ã®LangChainã‚³ãƒŸãƒ¥ãƒ‹ãƒ†ã‚£ãƒ‘ãƒƒã‚±ãƒ¼ã‚¸ã¨ã€ä¾‹ã¨ã—ã¦ä½¿ç”¨ã™ã‚‹ãŸã‚ã® [Tavily](https://app.tavily.com/sign-in) ã‚’ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«ã™ã‚‹å¿…è¦ãŒã‚ã‚Šã¾ã™ã€‚

```shell
pip install -U langgraph langchain_openai tavily-python
```

ã¾ãŸã€OpenAIã¨Tavily APIã‚¢ã‚¯ã‚»ã‚¹ã®ãŸã‚ã«è¿½åŠ ã®ç’°å¢ƒå¤‰æ•°ã‚’ã‚¨ã‚¯ã‚¹ãƒãƒ¼ãƒˆã™ã‚‹å¿…è¦ãŒã‚ã‚Šã¾ã™ã€‚

```shell
export OPENAI_API_KEY=sk-...
export TAVILY_API_KEY=tvly-...
```

ã‚ªãƒ—ã‚·ãƒ§ãƒ³ã¨ã—ã¦ã€æœ€é«˜ã®è¦³æ¸¬æ€§ã®ãŸã‚ã« [LangSmith](https://docs.smith.langchain.com/) ã‚’è¨­å®šã§ãã¾ã™ã€‚

```shell
export LANGCHAIN_TRACING_V2="true"
export LANGCHAIN_API_KEY=ls__...
```

### ãƒ„ãƒ¼ãƒ«ã®è¨­å®š

ä¸Šè¨˜ã®ã‚ˆã†ã«ã€ã¾ãšä½¿ç”¨ã—ãŸã„ãƒ„ãƒ¼ãƒ«ã‚’å®šç¾©ã—ã¾ã™ã€‚
ã“ã®ã‚·ãƒ³ãƒ—ãƒ«ãªä¾‹ã§ã¯ã€ã‚¦ã‚§ãƒ–æ¤œç´¢ãƒ„ãƒ¼ãƒ«ã‚’ä½¿ç”¨ã—ã¾ã™ã€‚
ãŸã ã—ã€ç‹¬è‡ªã®ãƒ„ãƒ¼ãƒ«ã‚’ä½œæˆã™ã‚‹ã®ã¯éå¸¸ã«ç°¡å˜ã§ã™ã€‚æ–¹æ³•ã«ã¤ã„ã¦ã¯[ã“ã¡ã‚‰](https://python.langchain.com/docs/modules/agents/tools/custom_tools) ã®ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆã‚’å‚ç…§ã—ã¦ãã ã•ã„ã€‚

```python
<!--IMPORTS:[{"imported": "TavilySearchResults", "source": "langchain_community.tools.tavily_search", "docs": "https://api.python.langchain.com/en/latest/tools/langchain_community.tools.tavily_search.tool.TavilySearchResults.html", "title": "\ud83e\udd9c\ud83d\udd78\ufe0fLangGraph"}]-->
from langchain_community.tools.tavily_search import TavilySearchResults

tools = [TavilySearchResults(max_results=1)]
```

ã“ã‚Œã‚‰ã®ãƒ„ãƒ¼ãƒ«ã‚’ã‚·ãƒ³ãƒ—ãƒ«ãªLangGraph [ToolNode](https://langchain-ai.github.io/langgraph/reference/prebuilt/#toolnode) ã«ãƒ©ãƒƒãƒ—ã§ãã¾ã™ã€‚
ã“ã®ã‚¯ãƒ©ã‚¹ã¯ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã®ãƒªã‚¹ãƒˆï¼ˆ[tool_calls](https://api.python.langchain.com/en/latest/messages/langchain_core.messages.ai.AIMessage.html#langchain_core.messages.ai.AIMessage.tool_calls) ã‚’å«ã‚€ï¼‰ã‚’å—ã‘å–ã‚Šã€LLMãŒå®Ÿè¡Œã™ã‚‹ã‚ˆã†ã«è¦æ±‚ã—ãŸãƒ„ãƒ¼ãƒ«ã‚’å‘¼ã³å‡ºã—ã€å‡ºåŠ›ã‚’æ–°ã—ã„ [ToolMessage](https://api.python.langchain.com/en/latest/messages/langchain_core.messages.tool.ToolMessage.html#langchain_core.messages.tool.ToolMessage)(s) ã¨ã—ã¦è¿”ã—ã¾ã™ã€‚

```python
from langgraph.prebuilt import ToolNode

tool_node = ToolNode(tools)
```

### ãƒ¢ãƒ‡ãƒ«ã®è¨­å®š

æ¬¡ã«ã€ä½¿ç”¨ã™ã‚‹ãƒãƒ£ãƒƒãƒˆãƒ¢ãƒ‡ãƒ«ã‚’ãƒ­ãƒ¼ãƒ‰ã™ã‚‹å¿…è¦ãŒã‚ã‚Šã¾ã™ã€‚

```python
<!--IMPORTS:[{"imported": "ChatOpenAI", "source": "langchain_openai", "docs": "https://api.python.langchain.com/en/latest/chat_models/langchain_openai.chat_models.base.ChatOpenAI.html", "title": "\ud83e\udd9c\ud83d\udd78\ufe0fLangGraph"}]-->
from langchain_openai import ChatOpenAI

# We will set streaming=True so that we can stream tokens
# See the streaming section for more information on this.
model = ChatOpenAI(model="gpt-3.5-turbo", temperature=0, streaming=True)
```

ã“ã‚Œã‚’è¡Œã£ãŸå¾Œã€ãƒ¢ãƒ‡ãƒ«ãŒã“ã‚Œã‚‰ã®ãƒ„ãƒ¼ãƒ«ã‚’å‘¼ã³å‡ºã›ã‚‹ã“ã¨ã‚’ç¢ºèªã™ã‚‹å¿…è¦ãŒã‚ã‚Šã¾ã™ã€‚
ã“ã‚Œã‚’è¡Œã†ã«ã¯ã€LangChainãƒ„ãƒ¼ãƒ«ã‚’OpenAIãƒ„ãƒ¼ãƒ«ã‚³ãƒ¼ãƒ«ç”¨ã®å½¢å¼ã«å¤‰æ›ã™ã‚‹ [bind_tools()](https://api.python.langchain.com/en/latest/chat_models/langchain_openai.chat_models.base.ChatOpenAI.html#langchain_openai.chat_models.base.ChatOpenAI.bind_tools) ãƒ¡ã‚½ãƒƒãƒ‰ã‚’ä½¿ç”¨ã—ã¾ã™ã€‚

```python
model = model.bind_tools(tools)
```

### ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆçŠ¶æ…‹ã®å®šç¾©

ä»Šå›ã¯ã€ã‚ˆã‚Šä¸€èˆ¬çš„ãª `StateGraph` ã‚’ä½¿ç”¨ã—ã¾ã™ã€‚
ã“ã®ã‚°ãƒ©ãƒ•ã¯ã€å„ãƒãƒ¼ãƒ‰ã«æ¸¡ã•ã‚Œã‚‹çŠ¶æ…‹ã‚ªãƒ–ã‚¸ã‚§ã‚¯ãƒˆã«ã‚ˆã£ã¦ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿åŒ–ã•ã‚Œã¾ã™ã€‚
å„ãƒãƒ¼ãƒ‰ã¯ã€ãã®çŠ¶æ…‹ã‚’æ›´æ–°ã™ã‚‹ãŸã‚ã®æ“ä½œã‚’è¿”ã—ã¾ã™ã€‚
ã“ã‚Œã‚‰ã®æ“ä½œã¯ã€çŠ¶æ…‹ã®ç‰¹å®šã®å±æ€§ã‚’è¨­å®šï¼ˆSETï¼‰ã™ã‚‹ã‹ï¼ˆæ—¢å­˜ã®å€¤ã‚’ä¸Šæ›¸ãï¼‰ã€æ—¢å­˜ã®å±æ€§ã«è¿½åŠ ï¼ˆADDï¼‰ã™ã‚‹ã“ã¨ãŒã§ãã¾ã™ã€‚
è¨­å®šã¾ãŸã¯è¿½åŠ ã™ã‚‹ã‹ã¯ã€æ§‹ç¯‰ã™ã‚‹çŠ¶æ…‹ã‚ªãƒ–ã‚¸ã‚§ã‚¯ãƒˆã«æ³¨é‡ˆã‚’ä»˜ã‘ã¦ç¤ºã•ã‚Œã¾ã™ã€‚

ã“ã®ä¾‹ã§ã¯ã€è¿½è·¡ã™ã‚‹çŠ¶æ…‹ã¯ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã®ãƒªã‚¹ãƒˆã ã‘ã§ã™ã€‚
å„ãƒãƒ¼ãƒ‰ãŒãã®ãƒªã‚¹ãƒˆã«ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã‚’è¿½åŠ ã™ã‚‹ã ã‘ã§ã™ã€‚
ã—ãŸãŒã£ã¦ã€`TypedDict` ã‚’ä½¿ç”¨ã—ã€ä¸€ã¤ã®ã‚­ãƒ¼ï¼ˆ`messages`ï¼‰ã‚’æŒã¡ã€ãã‚Œã‚’æ³¨é‡ˆã—ã¦ã€æ›´æ–°æ™‚ã«å¸¸ã« **messages** ã‚­ãƒ¼ã«è¿½åŠ ã™ã‚‹ã‚ˆã†ã«ã—ã¾ã™ã€‚äºŒã¤ç›®ã®ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ï¼ˆ`operator.add`ï¼‰ã‚’ä½¿ç”¨ã—ã¦è¿½åŠ ã•ã‚Œã¾ã™ã€‚
ï¼ˆæ³¨ï¼šçŠ¶æ…‹ã¯ä»»æ„ã®[å‹](https://docs.python.org/3/library/stdtypes.html#type-objects)ã«ã™ã‚‹ã“ã¨ãŒã§ãã€[pydantic BaseModel's](https://docs.pydantic.dev/latest/api/base_model/)) ã‚’å«ã¿ã¾ã™ï¼‰

```python
from typing import TypedDict, Annotated

def add_messages(left: list, right: list):
    """Add-don't-overwrite."""
    return left + right

class AgentState(TypedDict):
    # The `add_messages` function within the annotation defines
    # *how* updates should be merged into the state.
    messages: Annotated[list, add_messages]
```

åˆæœŸã®ä¾‹ã§ä½¿ç”¨ã•ã‚ŒãŸ `MessageGraph` ã‚’ã€ã“ã®ã‚°ãƒ©ãƒ•ã®äº‹å‰è¨­å®šã•ã‚ŒãŸãƒãƒ¼ã‚¸ãƒ§ãƒ³ã¨è€ƒãˆã‚‹ã“ã¨ãŒã§ãã¾ã™ã€‚ã“ã®ã‚°ãƒ©ãƒ•ã§ã¯ã€çŠ¶æ…‹ãŒç›´æ¥ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã®é…åˆ—ã§ã‚ã‚Šã€æ›´æ–°ã‚¹ãƒ†ãƒƒãƒ—ã§ã¯ãƒãƒ¼ãƒ‰ã®æˆ»ã‚Šå€¤ã‚’å†…éƒ¨çŠ¶æ…‹ã«è¿½åŠ ã™ã‚‹ã ã‘ã§ã™ã€‚

### ãƒãƒ¼ãƒ‰ã‚’å®šç¾©ã™ã‚‹

æ¬¡ã«ã€ã‚°ãƒ©ãƒ•å†…ã§ã„ãã¤ã‹ã®ç•°ãªã‚‹ãƒãƒ¼ãƒ‰ã‚’å®šç¾©ã™ã‚‹å¿…è¦ãŒã‚ã‚Šã¾ã™ã€‚
`langgraph`ã§ã¯ã€ãƒãƒ¼ãƒ‰ã¯é€šå¸¸ã®Pythoné–¢æ•°ã¾ãŸã¯[runnable](https://python.langchain.com/docs/expression_language/)ã®ã„ãšã‚Œã‹ã§ã™ã€‚

ã“ã‚Œã«ã¯2ã¤ã®ä¸»ãªãƒãƒ¼ãƒ‰ãŒå¿…è¦ã§ã™ï¼š

1. ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆ: ã©ã®ã‚¢ã‚¯ã‚·ãƒ§ãƒ³ï¼ˆã‚‚ã—ã‚ã‚Œã°ï¼‰ã‚’å–ã‚‹ã‹ã‚’æ±ºå®šã—ã¾ã™ã€‚
2. ãƒ„ãƒ¼ãƒ«ã‚’å‘¼ã³å‡ºã™é–¢æ•°: ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆãŒã‚¢ã‚¯ã‚·ãƒ§ãƒ³ã‚’å–ã‚‹ã¨æ±ºå®šã—ãŸå ´åˆã€ã“ã®ãƒãƒ¼ãƒ‰ãŒãã®ã‚¢ã‚¯ã‚·ãƒ§ãƒ³ã‚’å®Ÿè¡Œã—ã¾ã™ã€‚ã“ã‚Œã¯ã™ã§ã«ä¸Šã§å®šç¾©ã—ã¾ã—ãŸã€‚

ã¾ãŸã€ã„ãã¤ã‹ã®ã‚¨ãƒƒã‚¸ã‚’å®šç¾©ã™ã‚‹å¿…è¦ãŒã‚ã‚Šã¾ã™ã€‚
ã“ã‚Œã‚‰ã®ã‚¨ãƒƒã‚¸ã®ä¸€éƒ¨ã¯æ¡ä»¶ä»˜ãã§ã‚ã‚‹å ´åˆãŒã‚ã‚Šã¾ã™ã€‚
æ¡ä»¶ä»˜ãã§ã‚ã‚‹ç†ç”±ã¯ã€ç›®çš„åœ°ãŒã‚°ãƒ©ãƒ•ã®`State`ã®å†…å®¹ã«ä¾å­˜ã™ã‚‹ãŸã‚ã§ã™ã€‚

å–ã‚‰ã‚Œã‚‹ãƒ‘ã‚¹ã¯ã€ãã®ãƒãƒ¼ãƒ‰ãŒå®Ÿè¡Œã•ã‚Œã‚‹ã¾ã§ï¼ˆLLMãŒæ±ºå®šã™ã‚‹ã¾ã§ï¼‰ã‚ã‹ã‚Šã¾ã›ã‚“ã€‚ç§ãŸã¡ã®ä½¿ç”¨ä¾‹ã§ã¯ã€å„ç¨®é¡ã®ã‚¨ãƒƒã‚¸ãŒ1ã¤ãšã¤å¿…è¦ã§ã™ï¼š

1. æ¡ä»¶ä»˜ãã‚¨ãƒƒã‚¸: ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆãŒå‘¼ã³å‡ºã•ã‚ŒãŸå¾Œã€æ¬¡ã®ã„ãšã‚Œã‹ã‚’å®Ÿè¡Œã™ã‚‹å¿…è¦ãŒã‚ã‚Šã¾ã™ï¼š

   a. ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆãŒã‚¢ã‚¯ã‚·ãƒ§ãƒ³ã‚’å–ã‚‹ã‚ˆã†ã«æŒ‡ç¤ºã—ãŸå ´åˆã€ãƒ„ãƒ¼ãƒ«ã‚’å®Ÿè¡Œã™ã‚‹ã€ã¾ãŸã¯

   b. ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆãŒãƒ„ãƒ¼ãƒ«ã‚’å®Ÿè¡Œã™ã‚‹ã‚ˆã†ã«æŒ‡ç¤ºã—ãªã‹ã£ãŸå ´åˆã€çµ‚äº†ï¼ˆãƒ¦ãƒ¼ã‚¶ãƒ¼ã«å¿œç­”ï¼‰

2. é€šå¸¸ã®ã‚¨ãƒƒã‚¸: ãƒ„ãƒ¼ãƒ«ãŒå‘¼ã³å‡ºã•ã‚ŒãŸå¾Œã€ã‚°ãƒ©ãƒ•ã¯å¸¸ã«æ¬¡ã«ä½•ã‚’ã™ã‚‹ã‹ã‚’æ±ºå®šã™ã‚‹ãŸã‚ã«ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆã«æˆ»ã‚‹å¿…è¦ãŒã‚ã‚Šã¾ã™

ãƒãƒ¼ãƒ‰ã‚’å®šç¾©ã—ã€æ¡ä»¶ä»˜ãã‚¨ãƒƒã‚¸ã‚’å®šç¾©ã™ã‚‹é–¢æ•°ã‚‚å®šç¾©ã—ã¾ã—ã‚‡ã†ã€‚

```python
from typing import Literal

# Define the function that determines whether to continue or not
def should_continue(state: AgentState) -> Literal["action", "__end__"]:
    messages = state['messages']
    last_message = messages[-1]
    # If the LLM makes a tool call, then we route to the "action" node
    if last_message.tool_calls:
        return "action"
    # Otherwise, we stop (reply to the user)
    return "__end__"


# Define the function that calls the model
def call_model(state: AgentState):
    messages = state['messages']
    response = model.invoke(messages)
    # We return a list, because this will get added to the existing list
    return {"messages": [response]}
```

### ã‚°ãƒ©ãƒ•ã‚’å®šç¾©ã™ã‚‹

ã“ã‚Œã§ã€ã™ã¹ã¦ã‚’ã¾ã¨ã‚ã¦ã‚°ãƒ©ãƒ•ã‚’å®šç¾©ã§ãã¾ã™ï¼

```python
from langgraph.graph import StateGraph, END
# Define a new graph
workflow = StateGraph(AgentState)

# Define the two nodes we will cycle between
workflow.add_node("agent", call_model)
workflow.add_node("action", tool_node)

# Set the entrypoint as `agent`
# This means that this node is the first one called
workflow.set_entry_point("agent")

# We now add a conditional edge
workflow.add_conditional_edges(
    # First, we define the start node. We use `agent`.
    # This means these are the edges taken after the `agent` node is called.
    "agent",
    # Next, we pass in the function that will determine which node is called next.
    should_continue,
)

# We now add a normal edge from `tools` to `agent`.
# This means that after `tools` is called, `agent` node is called next.
workflow.add_edge('action', 'agent')

# Finally, we compile it!
# This compiles it into a LangChain Runnable,
# meaning you can use it as you would any other runnable
app = workflow.compile()
```

### ä½¿ã£ã¦ã¿ã¾ã—ã‚‡ã†ï¼

ã“ã‚Œã§ä½¿ãˆã‚‹ã‚ˆã†ã«ãªã‚Šã¾ã—ãŸï¼
ã“ã‚Œã§ä»–ã®ã™ã¹ã¦ã®LangChainã®[runnable](https://python.langchain.com/docs/expression_language/)ã¨åŒã˜ã‚¤ãƒ³ã‚¿ãƒ¼ãƒ•ã‚§ãƒ¼ã‚¹ãŒå…¬é–‹ã•ã‚Œã¾ã™ã€‚
ã“ã®[runnable](https://python.langchain.com/docs/expression_language/interface/)ã¯ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã®ãƒªã‚¹ãƒˆã‚’å—ã‘å–ã‚Šã¾ã™ã€‚

```python
<!--IMPORTS:[{"imported": "HumanMessage", "source": "langchain_core.messages", "docs": "https://api.python.langchain.com/en/latest/messages/langchain_core.messages.human.HumanMessage.html", "title": "\ud83e\udd9c\ud83d\udd78\ufe0fLangGraph"}]-->
from langchain_core.messages import HumanMessage

inputs = {"messages": [HumanMessage(content="what is the weather in sf")]}
app.invoke(inputs)
```

ã“ã‚Œã¯å°‘ã—æ™‚é–“ãŒã‹ã‹ã‚‹ã‹ã‚‚ã—ã‚Œã¾ã›ã‚“ - è£ã§ã„ãã¤ã‹ã®å‘¼ã³å‡ºã—ã‚’è¡Œã£ã¦ã„ã¾ã™ã€‚
ç™ºç”Ÿã™ã‚‹ä¸­é–“çµæœã‚’ã™ãã«ç¢ºèªã™ã‚‹ãŸã‚ã«ã€ã‚¹ãƒˆãƒªãƒ¼ãƒŸãƒ³ã‚°ã‚’ä½¿ç”¨ã§ãã¾ã™ - è©³ç´°ã¯ä»¥ä¸‹ã‚’å‚ç…§ã—ã¦ãã ã•ã„ã€‚

## ã‚¹ãƒˆãƒªãƒ¼ãƒŸãƒ³ã‚°

LangGraphã¯ã€ã„ãã¤ã‹ã®ç•°ãªã‚‹ç¨®é¡ã®ã‚¹ãƒˆãƒªãƒ¼ãƒŸãƒ³ã‚°ã‚’ã‚µãƒãƒ¼ãƒˆã—ã¦ã„ã¾ã™ã€‚

### ãƒãƒ¼ãƒ‰å‡ºåŠ›ã®ã‚¹ãƒˆãƒªãƒ¼ãƒŸãƒ³ã‚°

LangGraphã‚’ä½¿ç”¨ã™ã‚‹åˆ©ç‚¹ã®1ã¤ã¯ã€å„ãƒãƒ¼ãƒ‰ã«ã‚ˆã£ã¦ç”Ÿæˆã•ã‚Œã‚‹å‡ºåŠ›ã‚’ç°¡å˜ã«ã‚¹ãƒˆãƒªãƒ¼ãƒŸãƒ³ã‚°ã§ãã‚‹ã“ã¨ã§ã™ã€‚

```python
inputs = {"messages": [HumanMessage(content="what is the weather in sf")]}
for output in app.stream(inputs, stream_mode="updates"):
    # stream() yields dictionaries with output keyed by node name
    for key, value in output.items():
        print(f"Output from node '{key}':")
        print("---")
        print(value)
    print("\n---\n")
```

```output
Output from node 'agent':
---
{'messages': [AIMessage(content='', additional_kwargs={'function_call': {'arguments': '{\n  "query": "weather in San Francisco"\n}', 'name': 'tavily_search_results_json'}})]}

---

Output from node 'action':
---
{'messages': [FunctionMessage(content="[{'url': 'https://weatherspark.com/h/m/557/2024/1/Historical-Weather-in-January-2024-in-San-Francisco-California-United-States', 'content': 'January 2024 Weather History in San Francisco California, United States  Daily Precipitation in January 2024 in San Francisco Observed Weather in January 2024 in San Francisco  San Francisco Temperature History January 2024 Hourly Temperature in January 2024 in San Francisco  Hours of Daylight and Twilight in January 2024 in San FranciscoThis report shows the past weather for San Francisco, providing a weather history for January 2024. It features all historical weather data series we have available, including the San Francisco temperature history for January 2024. You can drill down from year to month and even day level reports by clicking on the graphs.'}]", name='tavily_search_results_json')]}

---

Output from node 'agent':
---
{'messages': [AIMessage(content="I couldn't find the current weather in San Francisco. However, you can visit [WeatherSpark](https://weatherspark.com/h/m/557/2024/1/Historical-Weather-in-January-2024-in-San-Francisco-California-United-States) to check the historical weather data for January 2024 in San Francisco.")]}

---

Output from node '__end__':
---
{'messages': [HumanMessage(content='what is the weather in sf'), AIMessage(content='', additional_kwargs={'function_call': {'arguments': '{\n  "query": "weather in San Francisco"\n}', 'name': 'tavily_search_results_json'}}), FunctionMessage(content="[{'url': 'https://weatherspark.com/h/m/557/2024/1/Historical-Weather-in-January-2024-in-San-Francisco-California-United-States', 'content': 'January 2024 Weather History in San Francisco California, United States  Daily Precipitation in January 2024 in San Francisco Observed Weather in January 2024 in San Francisco  San Francisco Temperature History January 2024 Hourly Temperature in January 2024 in San Francisco  Hours of Daylight and Twilight in January 2024 in San FranciscoThis report shows the past weather for San Francisco, providing a weather history for January 2024. It features all historical weather data series we have available, including the San Francisco temperature history for January 2024. You can drill down from year to month and even day level reports by clicking on the graphs.'}]", name='tavily_search_results_json'), AIMessage(content="I couldn't find the current weather in San Francisco. However, you can visit [WeatherSpark](https://weatherspark.com/h/m/557/2024/1/Historical-Weather-in-January-2024-in-San-Francisco-California-United-States) to check the historical weather data for January 2024 in San Francisco.")]}

---
```

### LLMãƒˆãƒ¼ã‚¯ãƒ³ã®ã‚¹ãƒˆãƒªãƒ¼ãƒŸãƒ³ã‚°

å„ãƒãƒ¼ãƒ‰ã«ã‚ˆã£ã¦ç”Ÿæˆã•ã‚Œã‚‹LLMãƒˆãƒ¼ã‚¯ãƒ³ã«ã‚‚ã‚¢ã‚¯ã‚»ã‚¹ã§ãã¾ã™ã€‚
ã“ã®å ´åˆã€ã€Œã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆã€ãƒãƒ¼ãƒ‰ã®ã¿ãŒLLMãƒˆãƒ¼ã‚¯ãƒ³ã‚’ç”Ÿæˆã—ã¾ã™ã€‚
ã“ã‚ŒãŒæ­£ã—ãæ©Ÿèƒ½ã™ã‚‹ãŸã‚ã«ã¯ã€ã‚¹ãƒˆãƒªãƒ¼ãƒŸãƒ³ã‚°ã‚’ã‚µãƒãƒ¼ãƒˆã™ã‚‹LLMã‚’ä½¿ç”¨ã—ã€LLMã‚’æ§‹ç¯‰ã™ã‚‹éš›ã«è¨­å®šã—ã¦ã„ã‚‹å¿…è¦ãŒã‚ã‚Šã¾ã™ï¼ˆä¾‹ï¼š`ChatOpenAI(model="gpt-3.5-turbo-1106", streaming=True)`ï¼‰

```python
inputs = {"messages": [HumanMessage(content="what is the weather in sf")]}
async for output in app.astream_log(inputs, include_types=["llm"]):
    # astream_log() yields the requested logs (here LLMs) in JSONPatch format
    for op in output.ops:
        if op["path"] == "/streamed_output/-":
            # this is the output from .stream()
            ...
        elif op["path"].startswith("/logs/") and op["path"].endswith(
            "/streamed_output/-"
        ):
            # because we chose to only include LLMs, these are LLM tokens
            print(op["value"])
```

```output
content='' additional_kwargs={'function_call': {'arguments': '', 'name': 'tavily_search_results_json'}}
content='' additional_kwargs={'function_call': {'arguments': '{\n', 'name': ''}}}
content='' additional_kwargs={'function_call': {'arguments': ' ', 'name': ''}}
content='' additional_kwargs={'function_call': {'arguments': ' "', 'name': ''}}
content='' additional_kwargs={'function_call': {'arguments': 'query', 'name': ''}}
...
```

## ã„ã¤ä½¿ç”¨ã™ã‚‹ã‹

ã“ã‚Œã‚’[LangChain Expression Language](https://python.langchain.com/docs/expression_language/)ã¨æ¯”è¼ƒã—ã¦ã„ã¤ä½¿ç”¨ã™ã‚‹ã¹ãã§ã—ã‚‡ã†ã‹ï¼Ÿ

ã‚µã‚¤ã‚¯ãƒ«ãŒå¿…è¦ãªå ´åˆã€‚

Langchain Expression Languageã¯ã€ãƒã‚§ã‚¤ãƒ³ï¼ˆDAGï¼‰ã‚’ç°¡å˜ã«å®šç¾©ã§ãã¾ã™ãŒã€ã‚µã‚¤ã‚¯ãƒ«ã‚’è¿½åŠ ã™ã‚‹ãŸã‚ã®è‰¯ã„ãƒ¡ã‚«ãƒ‹ã‚ºãƒ ãŒã‚ã‚Šã¾ã›ã‚“ã€‚
`langgraph`ã¯ãã®æ§‹æ–‡ã‚’è¿½åŠ ã—ã¾ã™ã€‚

## ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆ

ã“ã‚Œã§ä½•ãŒæ§‹ç¯‰ã§ãã‚‹ã‹ã®å‘³è¦‹ãŒã§ããŸã¨æ€ã„ã¾ã™ï¼è©³ç´°ã‚’çŸ¥ã‚‹ã«ã¯ã€æ®‹ã‚Šã®ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆã‚’ãƒã‚§ãƒƒã‚¯ã—ã¦ãã ã•ã„ã€‚

### ãƒãƒ¥ãƒ¼ãƒˆãƒªã‚¢ãƒ«

[LangGraphãƒãƒ¥ãƒ¼ãƒˆãƒªã‚¢ãƒ«](https://langchain-ai.github.io/langgraph/tutorials/)ã§ã‚¬ã‚¤ãƒ‰ä»˜ãã®ä¾‹ã‚’é€šã˜ã¦LangGraphã®æ§‹ç¯‰æ–¹æ³•ã‚’å­¦ã³ã¾ã—ã‚‡ã†ã€‚

ã‚ˆã‚Šé«˜åº¦ãªã‚¬ã‚¤ãƒ‰ã‚’è©¦ã™å‰ã«ã€[LangGraphã®ç´¹ä»‹](https://langchain-ai.github.io/langgraph/tutorials/introduction/)ã‹ã‚‰å§‹ã‚ã‚‹ã“ã¨ã‚’ãŠå‹§ã‚ã—ã¾ã™ã€‚

### ãƒã‚¦ãƒ„ãƒ¼ã‚¬ã‚¤ãƒ‰

[LangGraphãƒã‚¦ãƒ„ãƒ¼ã‚¬ã‚¤ãƒ‰](https://langchain-ai.github.io/langgraph/how-tos/)ã§ã¯ã€ã‚¹ãƒˆãƒªãƒ¼ãƒŸãƒ³ã‚°ã‹ã‚‰ãƒ¡ãƒ¢ãƒªã¨æ°¸ç¶šæ€§ã®è¿½åŠ ã€ä¸€èˆ¬çš„ãªãƒ‡ã‚¶ã‚¤ãƒ³ãƒ‘ã‚¿ãƒ¼ãƒ³ï¼ˆåˆ†å²ã€ã‚µãƒ–ã‚°ãƒ©ãƒ•ãªã©ï¼‰ã¾ã§ã€LangGraphå†…ã§ç‰¹å®šã®ã“ã¨ã‚’é”æˆã™ã‚‹æ–¹æ³•ã‚’ç¤ºã—ã¦ã„ã¾ã™ã€‚ç‰¹å®šã®ã‚³ãƒ¼ãƒ‰ã‚¹ãƒ‹ãƒšãƒƒãƒˆã‚’ã‚³ãƒ”ãƒ¼ã—ã¦å®Ÿè¡Œã—ãŸã„å ´åˆã¯ã€ã“ã“ãŒæœ€é©ã§ã™ã€‚

### ãƒªãƒ•ã‚¡ãƒ¬ãƒ³ã‚¹

LangGraphã®APIã«ã¯ã€ã™ã¹ã¦ã®é‡è¦ãªã‚¯ãƒ©ã‚¹ã¨ãƒ¡ã‚½ãƒƒãƒ‰ãŒ[ãƒªãƒ•ã‚¡ãƒ¬ãƒ³ã‚¹ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆ](https://langchain-ai.github.io/langgraph/reference/graphs/)ã§ã‚«ãƒãƒ¼ã•ã‚Œã¦ã„ã¾ã™ã€‚ç‰¹å®šã®é–¢æ•°å¼•æ•°ã‚„ã€ã‚°ãƒ©ãƒ•ï¼‹ãƒã‚§ãƒƒã‚¯ãƒã‚¤ãƒ³ãƒˆAPIã®ä½¿ç”¨æ–¹æ³•ã®ç°¡å˜ãªä¾‹ã€ã¾ãŸã¯é«˜ãƒ¬ãƒ™ãƒ«ã®ãƒ—ãƒªãƒ“ãƒ«ãƒ‰ã‚³ãƒ³ãƒãƒ¼ãƒãƒ³ãƒˆã®ã„ãã¤ã‹ã‚’ç¢ºèªã™ã‚‹ãŸã‚ã«ã€ã“ã‚Œã‚‰ã‚’ãƒã‚§ãƒƒã‚¯ã—ã¦ãã ã•ã„ã€‚
