---
translated: true
---

# OpenLLM

[ğŸ¦¾ OpenLLM](https://github.com/bentoml/OpenLLM) ã¯ã€æœ¬ç•ªç’°å¢ƒã§å¤§è¦æ¨¡è¨€èªãƒ¢ãƒ‡ãƒ« (LLM) ã‚’æ“ä½œã™ã‚‹ãŸã‚ã®ã‚ªãƒ¼ãƒ—ãƒ³ãƒ—ãƒ©ãƒƒãƒˆãƒ•ã‚©ãƒ¼ãƒ ã§ã™ã€‚é–‹ç™ºè€…ã¯ã€ä»»æ„ã®ã‚ªãƒ¼ãƒ—ãƒ³ã‚½ãƒ¼ã‚¹ã® LLM ã§ã‚¤ãƒ³ãƒ•ã‚¡ãƒ¬ãƒ³ã‚¹ã‚’ç°¡å˜ã«å®Ÿè¡Œã—ã€ã‚¯ãƒ©ã‚¦ãƒ‰ã¾ãŸã¯ã‚ªãƒ³ãƒ—ãƒ¬ãƒŸã‚¹ã«ãƒ‡ãƒ—ãƒ­ã‚¤ã—ã€å¼·åŠ›ãª AI ã‚¢ãƒ—ãƒªã‚’æ§‹ç¯‰ã§ãã¾ã™ã€‚

## ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«

[PyPI](https://pypi.org/project/openllm/) ã‹ã‚‰ `openllm` ã‚’ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«ã—ã¾ã™ã€‚

```python
%pip install --upgrade --quiet  openllm
```

## ãƒ­ãƒ¼ã‚«ãƒ«ã§ OpenLLM ã‚µãƒ¼ãƒãƒ¼ã‚’èµ·å‹•ã™ã‚‹

LLM ã‚µãƒ¼ãƒãƒ¼ã‚’èµ·å‹•ã™ã‚‹ã«ã¯ã€`openllm start` ã‚³ãƒãƒ³ãƒ‰ã‚’ä½¿ç”¨ã—ã¾ã™ã€‚ãŸã¨ãˆã°ã€dolly-v2 ã‚µãƒ¼ãƒãƒ¼ã‚’èµ·å‹•ã™ã‚‹ã«ã¯ã€ã‚¿ãƒ¼ãƒŸãƒŠãƒ«ã‹ã‚‰æ¬¡ã®ã‚³ãƒãƒ³ãƒ‰ã‚’å®Ÿè¡Œã—ã¾ã™:

```bash
openllm start dolly-v2
```

## ãƒ©ãƒƒãƒ‘ãƒ¼

```python
from langchain_community.llms import OpenLLM

server_url = "http://localhost:3000"  # Replace with remote host if you are running on a remote server
llm = OpenLLM(server_url=server_url)
```

### ã‚ªãƒ—ã‚·ãƒ§ãƒ³: ãƒ­ãƒ¼ã‚«ãƒ« LLM ã‚¤ãƒ³ãƒ•ã‚¡ãƒ¬ãƒ³ã‚¹

OpenLLM ã§ç®¡ç†ã•ã‚Œã‚‹ LLM ã‚’ãƒ­ãƒ¼ã‚«ãƒ«ã®ãƒ—ãƒ­ã‚»ã‚¹ã‹ã‚‰åˆæœŸåŒ–ã™ã‚‹ã“ã¨ã‚‚ã§ãã¾ã™ã€‚ã“ã‚Œã¯é–‹ç™ºç›®çš„ã«å½¹ç«‹ã¡ã€é–‹ç™ºè€…ãŒç•°ãªã‚‹ã‚¿ã‚¤ãƒ—ã® LLM ã‚’ç´ æ—©ãè©¦ã™ã“ã¨ãŒã§ãã¾ã™ã€‚

LLM ã‚¢ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³ã‚’æœ¬ç•ªç’°å¢ƒã«ç§»è¡Œã™ã‚‹éš›ã¯ã€OpenLLM ã‚µãƒ¼ãƒãƒ¼ã‚’åˆ¥é€”ãƒ‡ãƒ—ãƒ­ã‚¤ã—ã€ä¸Šè¨˜ã® `server_url` ã‚ªãƒ—ã‚·ãƒ§ãƒ³ã‚’ä½¿ã£ã¦ã‚¢ã‚¯ã‚»ã‚¹ã™ã‚‹ã“ã¨ã‚’ãŠå‹§ã‚ã—ã¾ã™ã€‚

LangChain ãƒ©ãƒƒãƒ‘ãƒ¼ã‚’ä½¿ã£ã¦ãƒ­ãƒ¼ã‚«ãƒ«ã§ LLM ã‚’èª­ã¿è¾¼ã‚€ã«ã¯:

```python
from langchain_community.llms import OpenLLM

llm = OpenLLM(
    model_name="dolly-v2",
    model_id="databricks/dolly-v2-3b",
    temperature=0.94,
    repetition_penalty=1.2,
)
```

### LLMChain ã¨çµ±åˆã™ã‚‹

```python
from langchain.chains import LLMChain
from langchain_core.prompts import PromptTemplate

template = "What is a good name for a company that makes {product}?"

prompt = PromptTemplate.from_template(template)

llm_chain = LLMChain(prompt=prompt, llm=llm)

generated = llm_chain.run(product="mechanical keyboard")
print(generated)
```

```output
iLkb
```
