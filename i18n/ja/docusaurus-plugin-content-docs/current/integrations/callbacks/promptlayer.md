---
translated: true
---

# PromptLayer

>[PromptLayer](https://docs.promptlayer.com/introduction)ã¯ã€ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã‚¨ãƒ³ã‚¸ãƒ‹ã‚¢ãƒªãƒ³ã‚°ã®ãŸã‚ã®ãƒ—ãƒ©ãƒƒãƒˆãƒ•ã‚©ãƒ¼ãƒ ã§ã™ã€‚LLMã®å¯è¦–åŒ–ã€ãƒªã‚¯ã‚¨ã‚¹ãƒˆã®è¡¨ç¤ºã€ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã®ãƒãƒ¼ã‚¸ãƒ§ãƒ³ç®¡ç†ã€ä½¿ç”¨çŠ¶æ³ã®è¿½è·¡ãªã©ã®æ©Ÿèƒ½ã‚‚æä¾›ã—ã¦ã„ã¾ã™ã€‚
>
>`PromptLayer`ã«ã¯ã€LangChainã¨ç›´æ¥çµ±åˆã•ã‚ŒãŸLLMã‚‚ã‚ã‚Šã¾ã™ãŒ(ä¾‹: [`PromptLayerOpenAI`](/docs/integrations/llms/promptlayer_openai))ã€ã‚³ãƒ¼ãƒ«ãƒãƒƒã‚¯ã‚’ä½¿ç”¨ã™ã‚‹ã®ãŒ`PromptLayer`ã¨LangChainã‚’çµ±åˆã™ã‚‹æ¨å¥¨ã•ã‚Œã‚‹æ–¹æ³•ã§ã™ã€‚

ã“ã®ã‚¬ã‚¤ãƒ‰ã§ã¯ã€`PromptLayerCallbackHandler`ã®ã‚»ãƒƒãƒˆã‚¢ãƒƒãƒ—æ–¹æ³•ã‚’èª¬æ˜ã—ã¾ã™ã€‚

è©³ç´°ã¯[PromptLayerã®ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆ](https://docs.promptlayer.com/languages/langchain)ã‚’ã”è¦§ãã ã•ã„ã€‚

## ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«ã¨ã‚»ãƒƒãƒˆã‚¢ãƒƒãƒ—

```python
%pip install --upgrade --quiet  promptlayer --upgrade
```

### APIã‚¯ãƒ¬ãƒ‡ãƒ³ã‚·ãƒ£ãƒ«ã®å–å¾—

PromptLayerã®ã‚¢ã‚«ã‚¦ãƒ³ãƒˆã‚’ãŠæŒã¡ã§ãªã„å ´åˆã¯ã€[promptlayer.com](https://www.promptlayer.com)ã§ä½œæˆã—ã¦ãã ã•ã„ã€‚ãã®å¾Œã€ãƒŠãƒ“ã‚²ãƒ¼ã‚·ãƒ§ãƒ³ãƒãƒ¼ã®è¨­å®šã‚¢ã‚¤ã‚³ãƒ³ã‚’ã‚¯ãƒªãƒƒã‚¯ã—ã¦APIã‚­ãƒ¼ã‚’å–å¾—ã—ã€ç’°å¢ƒå¤‰æ•°`PROMPTLAYER_API_KEY`ã«è¨­å®šã—ã¦ãã ã•ã„ã€‚

## ä½¿ç”¨æ–¹æ³•

`PromptLayerCallbackHandler`ã®ä½¿ã„æ–¹ã¯éå¸¸ã«ç°¡å˜ã§ã™ã€‚2ã¤ã®ã‚ªãƒ—ã‚·ãƒ§ãƒ³å¼•æ•°ã‚’å–ã‚Šã¾ã™:
1. `pl_tags` - PromptLayerã§è¿½è·¡ã™ã‚‹ã‚¿ã‚°ã®ãƒªã‚¹ãƒˆ(æ–‡å­—åˆ—)ã€‚
2. `pl_id_callback` - `promptlayer_request_id`ã‚’å¼•æ•°ã¨ã—ã¦å—ã‘å–ã‚‹é–¢æ•°ã€‚ã“ã® IDã‚’ä½¿ç”¨ã—ã¦ã€PromptLayerã®è¿½è·¡æ©Ÿèƒ½(ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿ã€ã‚¹ã‚³ã‚¢ã€ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã®ä½¿ç”¨çŠ¶æ³ãªã©)ã‚’åˆ©ç”¨ã§ãã¾ã™ã€‚

## ç°¡å˜ãªOpenAIä¾‹

ã“ã®ç°¡å˜ãªä¾‹ã§ã¯ã€`PromptLayerCallbackHandler`ã‚’`ChatOpenAI`ã¨ä¸€ç·’ã«ä½¿ç”¨ã—ã¦ã„ã¾ã™ã€‚`chatopenai`ã¨ã„ã†PromptLayerã‚¿ã‚°ã‚’è¿½åŠ ã—ã¦ã„ã¾ã™ã€‚

```python
import promptlayer  # Don't forget this ğŸ°
from langchain_community.callbacks.promptlayer_callback import (
    PromptLayerCallbackHandler,
)
```

```python
from langchain.schema import (
    HumanMessage,
)
from langchain_openai import ChatOpenAI

chat_llm = ChatOpenAI(
    temperature=0,
    callbacks=[PromptLayerCallbackHandler(pl_tags=["chatopenai"])],
)
llm_results = chat_llm.invoke(
    [
        HumanMessage(content="What comes after 1,2,3 ?"),
        HumanMessage(content="Tell me another joke?"),
    ]
)
print(llm_results)
```

## GPT4Allä¾‹

```python
from langchain_community.llms import GPT4All

model = GPT4All(model="./models/gpt4all-model.bin", n_ctx=512, n_threads=8)
callbacks = [PromptLayerCallbackHandler(pl_tags=["langchain", "gpt4all"])]

response = model.invoke(
    "Once upon a time, ",
    config={"callbacks": callbacks},
)
```

## é«˜åº¦ãªä¾‹

ã“ã®ä¾‹ã§ã¯ã€`PromptLayer`ã®æ©Ÿèƒ½ã‚’ã•ã‚‰ã«æ´»ç”¨ã—ã¦ã„ã¾ã™ã€‚

PromptLayerã§ã¯ã€ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆãƒ†ãƒ³ãƒ—ãƒ¬ãƒ¼ãƒˆã‚’è¦–è¦šçš„ã«ä½œæˆã€ãƒãƒ¼ã‚¸ãƒ§ãƒ³ç®¡ç†ã€è¿½è·¡ã§ãã¾ã™ã€‚[Prompt Registry](https://docs.promptlayer.com/features/prompt-registry)ã‚’ä½¿ç”¨ã—ã¦ã€`example`ã¨ã„ã†åå‰ã®ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆãƒ†ãƒ³ãƒ—ãƒ¬ãƒ¼ãƒˆã‚’ programmatically å–å¾—ã—ã¦ã„ã¾ã™ã€‚

ã¾ãŸã€`pl_id_callback`é–¢æ•°ã‚’å®šç¾©ã—ã€`promptlayer_request_id`ã‚’å—ã‘å–ã£ã¦ã‚¹ã‚³ã‚¢ã®è¨˜éŒ²ã€ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿ã®è¿½åŠ ã€ä½¿ç”¨ã—ãŸãƒ—ãƒ­ãƒ³ãƒ—ãƒˆãƒ†ãƒ³ãƒ—ãƒ¬ãƒ¼ãƒˆã®ãƒªãƒ³ã‚¯ä»˜ã‘ã‚’è¡Œã£ã¦ã„ã¾ã™ã€‚è¿½è·¡ã®è©³ç´°ã¯[ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆ](https://docs.promptlayer.com/features/prompt-history/request-id)ã‚’ã”è¦§ãã ã•ã„ã€‚

```python
from langchain_openai import OpenAI


def pl_id_callback(promptlayer_request_id):
    print("prompt layer id ", promptlayer_request_id)
    promptlayer.track.score(
        request_id=promptlayer_request_id, score=100
    )  # score is an integer 0-100
    promptlayer.track.metadata(
        request_id=promptlayer_request_id, metadata={"foo": "bar"}
    )  # metadata is a dictionary of key value pairs that is tracked on PromptLayer
    promptlayer.track.prompt(
        request_id=promptlayer_request_id,
        prompt_name="example",
        prompt_input_variables={"product": "toasters"},
        version=1,
    )  # link the request to a prompt template


openai_llm = OpenAI(
    model_name="gpt-3.5-turbo-instruct",
    callbacks=[PromptLayerCallbackHandler(pl_id_callback=pl_id_callback)],
)

example_prompt = promptlayer.prompts.get("example", version=1, langchain=True)
openai_llm.invoke(example_prompt.format(product="toasters"))
```

ã“ã‚Œã ã‘ã§è¨­å®šã¯å®Œäº†ã§ã™! è¨­å®šå¾Œã€ã™ã¹ã¦ã®ãƒªã‚¯ã‚¨ã‚¹ãƒˆãŒPromptLayerã®ãƒ€ãƒƒã‚·ãƒ¥ãƒœãƒ¼ãƒ‰ã«è¡¨ç¤ºã•ã‚Œã¾ã™ã€‚
ã“ã®ã‚³ãƒ¼ãƒ«ãƒãƒƒã‚¯ã¯ã€LangChainã§å®Ÿè£…ã•ã‚ŒãŸã™ã¹ã¦ã®LLMã§æ©Ÿèƒ½ã—ã¾ã™ã€‚
