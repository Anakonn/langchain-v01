---
translated: true
---

# Hugging Face

ã“ã®ãƒãƒ¼ãƒˆãƒ–ãƒƒã‚¯ã§ã¯ã€`Hugging Face`ã® LLM ã‚’ chat ãƒ¢ãƒ‡ãƒ«ã¨ã—ã¦ä½¿ã„å§‹ã‚ã‚‹æ–¹æ³•ã‚’ç¤ºã—ã¾ã™ã€‚

ç‰¹ã«ã€ä»¥ä¸‹ã®ã“ã¨ã‚’è¡Œã„ã¾ã™:
1. [HuggingFaceTextGenInference](https://github.com/langchain-ai/langchain/blob/master/libs/langchain/langchain/llms/huggingface_text_gen_inference.py)ã€[HuggingFaceEndpoint](https://github.com/langchain-ai/langchain/blob/master/libs/langchain/langchain/llms/huggingface_endpoint.py)ã€ã¾ãŸã¯ [HuggingFaceHub](https://github.com/langchain-ai/langchain/blob/master/libs/langchain/langchain/llms/huggingface_hub.py) ã‚¤ãƒ³ãƒ†ã‚°ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³ã‚’åˆ©ç”¨ã—ã¦ `LLM` ã‚’ã‚¤ãƒ³ã‚¹ã‚¿ãƒ³ã‚¹åŒ–ã—ã¾ã™ã€‚
2. `ChatHuggingFace` ã‚¯ãƒ©ã‚¹ã‚’åˆ©ç”¨ã—ã¦ã€ã“ã‚Œã‚‰ã® LLM ã‚’ LangChain ã® [Chat Messages](/docs/modules/model_io/chat/#messages) æŠ½è±¡åŒ–ã¨ã‚¤ãƒ³ã‚¿ãƒ¼ãƒ•ã‚§ãƒ¼ã‚¹ã•ã›ã¾ã™ã€‚
3. ã‚ªãƒ¼ãƒ—ãƒ³ã‚½ãƒ¼ã‚¹ã® LLM ã‚’ä½¿ã£ã¦ `ChatAgent` ãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³ã‚’å‹•ä½œã•ã›ã‚‹æ–¹æ³•ã‚’ç¤ºã—ã¾ã™ã€‚

> æ³¨æ„: å§‹ã‚ã‚‹ã«ã¯ã€[Hugging Face ã‚¢ã‚¯ã‚»ã‚¹ãƒˆãƒ¼ã‚¯ãƒ³](https://huggingface.co/docs/hub/security-tokens)ã‚’ç’°å¢ƒå¤‰æ•° `HUGGINGFACEHUB_API_TOKEN` ã¨ã—ã¦ä¿å­˜ã™ã‚‹å¿…è¦ãŒã‚ã‚Šã¾ã™ã€‚

```python
%pip install --upgrade --quiet  text-generation transformers google-search-results numexpr langchainhub sentencepiece jinja2
```

```output
[0mNote: you may need to restart the kernel to use updated packages.
```

## 1. LLM ã‚’ã‚¤ãƒ³ã‚¹ã‚¿ãƒ³ã‚¹åŒ–ã™ã‚‹

3ã¤ã® LLM ã‚ªãƒ—ã‚·ãƒ§ãƒ³ã‹ã‚‰é¸æŠã§ãã¾ã™ã€‚

### `HuggingFaceTextGenInference`

```python
import os

from langchain_community.llms import HuggingFaceTextGenInference

ENDPOINT_URL = "<YOUR_ENDPOINT_URL_HERE>"
HF_TOKEN = os.getenv("HUGGINGFACEHUB_API_TOKEN")

llm = HuggingFaceTextGenInference(
    inference_server_url=ENDPOINT_URL,
    max_new_tokens=512,
    top_k=50,
    temperature=0.1,
    repetition_penalty=1.03,
    server_kwargs={
        "headers": {
            "Authorization": f"Bearer {HF_TOKEN}",
            "Content-Type": "application/json",
        }
    },
)
```

### `HuggingFaceEndpoint`

```python
from langchain_community.llms import HuggingFaceEndpoint

ENDPOINT_URL = "<YOUR_ENDPOINT_URL_HERE>"
llm = HuggingFaceEndpoint(
    endpoint_url=ENDPOINT_URL,
    task="text-generation",
    model_kwargs={
        "max_new_tokens": 512,
        "top_k": 50,
        "temperature": 0.1,
        "repetition_penalty": 1.03,
    },
)
```

### `HuggingFaceHub`

```python
from langchain_community.llms import HuggingFaceHub

llm = HuggingFaceHub(
    repo_id="HuggingFaceH4/zephyr-7b-beta",
    task="text-generation",
    model_kwargs={
        "max_new_tokens": 512,
        "top_k": 30,
        "temperature": 0.1,
        "repetition_penalty": 1.03,
    },
)
```

```output
/Users/jacoblee/langchain/langchain/libs/langchain/.venv/lib/python3.10/site-packages/huggingface_hub/utils/_deprecation.py:127: FutureWarning: '__init__' (from 'huggingface_hub.inference_api') is deprecated and will be removed from version '1.0'. `InferenceApi` client is deprecated in favor of the more feature-complete `InferenceClient`. Check out this guide to learn how to convert your script to use it: https://huggingface.co/docs/huggingface_hub/guides/inference#legacy-inferenceapi-client.
  warnings.warn(warning_message, FutureWarning)
```

## 2. `ChatHuggingFace` ã‚’ã‚¤ãƒ³ã‚¹ã‚¿ãƒ³ã‚¹åŒ–ã—ã¦ãƒãƒ£ãƒƒãƒˆãƒ†ãƒ³ãƒ—ãƒ¬ãƒ¼ãƒˆã‚’é©ç”¨ã™ã‚‹

ãƒãƒ£ãƒƒãƒˆãƒ¢ãƒ‡ãƒ«ã¨ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã‚’ã‚¤ãƒ³ã‚¹ã‚¿ãƒ³ã‚¹åŒ–ã—ã¾ã™ã€‚

```python
from langchain.schema import (
    HumanMessage,
    SystemMessage,
)
from langchain_community.chat_models.huggingface import ChatHuggingFace

messages = [
    SystemMessage(content="You're a helpful assistant"),
    HumanMessage(
        content="What happens when an unstoppable force meets an immovable object?"
    ),
]

chat_model = ChatHuggingFace(llm=llm)
```

```output
WARNING! repo_id is not default parameter.
                    repo_id was transferred to model_kwargs.
                    Please confirm that repo_id is what you intended.
WARNING! task is not default parameter.
                    task was transferred to model_kwargs.
                    Please confirm that task is what you intended.
WARNING! huggingfacehub_api_token is not default parameter.
                    huggingfacehub_api_token was transferred to model_kwargs.
                    Please confirm that huggingfacehub_api_token is what you intended.
None of PyTorch, TensorFlow >= 2.0, or Flax have been found. Models won't be available and only tokenizers, configuration and file/data utilities can be used.
```

ä½¿ç”¨ä¸­ã®ãƒ¢ãƒ‡ãƒ«ã¨ãƒãƒ£ãƒƒãƒˆãƒ†ãƒ³ãƒ—ãƒ¬ãƒ¼ãƒˆã‚’ç¢ºèªã—ã¾ã™ã€‚

```python
chat_model.model_id
```

```output
'HuggingFaceH4/zephyr-7b-beta'
```

LLMã®å‘¼ã³å‡ºã—ã«ä½¿ç”¨ã•ã‚Œã‚‹ãƒãƒ£ãƒƒãƒˆãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã®ãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆã‚’ç¢ºèªã—ã¾ã™ã€‚

```python
chat_model._to_chat_prompt(messages)
```

```output
"<|system|>\nYou're a helpful assistant</s>\n<|user|>\nWhat happens when an unstoppable force meets an immovable object?</s>\n<|assistant|>\n"
```

ãƒ¢ãƒ‡ãƒ«ã‚’å‘¼ã³å‡ºã—ã¾ã™ã€‚

```python
res = chat_model.invoke(messages)
print(res.content)
```

```output
According to a popular philosophical paradox, when an unstoppable force meets an immovable object, it is impossible to determine which one will prevail because both are defined as being completely unyielding and unmovable. The paradox suggests that the very concepts of "unstoppable force" and "immovable object" are inherently contradictory, and therefore, it is illogical to imagine a scenario where they would meet and interact. However, in practical terms, it is highly unlikely for such a scenario to occur in the real world, as the concepts of "unstoppable force" and "immovable object" are often used metaphorically to describe hypothetical situations or abstract concepts, rather than physical objects or forces.
```

## 3. ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆã¨ã—ã¦è©¦ã—ã¦ã¿ã¾ã—ã‚‡ã†!

ã“ã“ã§ã¯ã€`Zephyr-7B-beta`ã‚’ zero-shot `ReAct` ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆã¨ã—ã¦ãƒ†ã‚¹ãƒˆã—ã¾ã™ã€‚ä»¥ä¸‹ã®ä¾‹ã¯[ã“ã¡ã‚‰](/docs/modules/agents/agent_types/react#using-chat-models)ã‹ã‚‰å¼•ç”¨ã—ã¦ã„ã¾ã™ã€‚

> æ³¨æ„: ã“ã®ã‚»ã‚¯ã‚·ãƒ§ãƒ³ã‚’å®Ÿè¡Œã™ã‚‹ã«ã¯ã€[SerpAPI ãƒˆãƒ¼ã‚¯ãƒ³](https://serpapi.com/)ã‚’ç’°å¢ƒå¤‰æ•° `SERPAPI_API_KEY` ã¨ã—ã¦ä¿å­˜ã™ã‚‹å¿…è¦ãŒã‚ã‚Šã¾ã™ã€‚

```python
from langchain import hub
from langchain.agents import AgentExecutor, load_tools
from langchain.agents.format_scratchpad import format_log_to_str
from langchain.agents.output_parsers import (
    ReActJsonSingleInputOutputParser,
)
from langchain.tools.render import render_text_description
from langchain_community.utilities import SerpAPIWrapper
```

`react-json`ã‚¹ã‚¿ã‚¤ãƒ«ã®ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã¨ã‚µãƒ¼ãƒã‚¨ãƒ³ã‚¸ãƒ³ã¨é›»å“ã¸ã®ã‚¢ã‚¯ã‚»ã‚¹ã‚’ä½¿ã£ã¦ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆã‚’è¨­å®šã—ã¾ã™ã€‚

```python
# setup tools
tools = load_tools(["serpapi", "llm-math"], llm=llm)

# setup ReAct style prompt
prompt = hub.pull("hwchase17/react-json")
prompt = prompt.partial(
    tools=render_text_description(tools),
    tool_names=", ".join([t.name for t in tools]),
)

# define the agent
chat_model_with_stop = chat_model.bind(stop=["\nObservation"])
agent = (
    {
        "input": lambda x: x["input"],
        "agent_scratchpad": lambda x: format_log_to_str(x["intermediate_steps"]),
    }
    | prompt
    | chat_model_with_stop
    | ReActJsonSingleInputOutputParser()
)

# instantiate AgentExecutor
agent_executor = AgentExecutor(agent=agent, tools=tools, verbose=True)
```

```python
agent_executor.invoke(
    {
        "input": "Who is Leo DiCaprio's girlfriend? What is her current age raised to the 0.43 power?"
    }
)
```

```output


[1m> Entering new AgentExecutor chain...[0m
[32;1m[1;3mQuestion: Who is Leo DiCaprio's girlfriend? What is her current age raised to the 0.43 power?

Thought: I need to use the Search tool to find out who Leo DiCaprio's current girlfriend is. Then, I can use the Calculator tool to raise her current age to the power of 0.43.

Action:
```

{
  "action": "Search",
  "action_input": "leo dicaprio girlfriend"
}

```output
[0m[36;1m[1;3mLeonardo DiCaprio may have found The One in Vittoria Ceretti. â€œThey are in love,â€ a source exclusively reveals in the latest issue of Us Weekly. â€œLeo was clearly very proud to be showing Vittoria off and letting everyone see how happy they are together.â€[0m[32;1m[1;3mNow that we know Leo DiCaprio's current girlfriend is Vittoria Ceretti, let's find out her current age.

Action:
```

{
  "action": "Search",
  "action_input": "vittoria ceretti age"
}

```output
[0m[36;1m[1;3m25 years[0m[32;1m[1;3mNow that we know Vittoria Ceretti's current age is 25, let's use the Calculator tool to raise it to the power of 0.43.

Action:
```

{
  "action": "Calculator",
  "action_input": "25^0.43"
}

```output
[0m[33;1m[1;3mAnswer: 3.991298452658078[0m[32;1m[1;3mFinal Answer: Vittoria Ceretti, Leo DiCaprio's current girlfriend, when raised to the power of 0.43 is approximately 4.0 rounded to two decimal places. Her current age is 25 years old.[0m

[1m> Finished chain.[0m
```

```output
{'input': "Who is Leo DiCaprio's girlfriend? What is her current age raised to the 0.43 power?",
 'output': "Vittoria Ceretti, Leo DiCaprio's current girlfriend, when raised to the power of 0.43 is approximately 4.0 rounded to two decimal places. Her current age is 25 years old."}
```

ã‚„ã£ãŸãƒ¼! 7bãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã®Zephyrãƒ¢ãƒ‡ãƒ«ã¯ä»¥ä¸‹ã®ã“ã¨ãŒã§ãã¾ã—ãŸ:

1. ä¸€é€£ã®ã‚¢ã‚¯ã‚·ãƒ§ãƒ³ã‚’è¨ˆç”»ã™ã‚‹: `ãƒ¬ã‚ªãƒ»ãƒ‡ã‚£ã‚«ãƒ—ãƒªã‚ªã®ç¾åœ¨ã®å½¼å¥³ã‚’æ¤œç´¢ã™ã‚‹å¿…è¦ãŒã‚ã‚Šã¾ã™ã€‚ãã—ã¦ã€å½¼å¥³ã®ç¾åœ¨ã®å¹´é½¢ã‚’0.43ä¹—ã™ã‚‹è¨ˆç®—ã‚’ã—ã¾ã™ã€‚`
2. SerpAPIãƒ„ãƒ¼ãƒ«ã‚’ä½¿ã£ã¦ã€ãƒ¬ã‚ªãƒ»ãƒ‡ã‚£ã‚«ãƒ—ãƒªã‚ªã®ç¾åœ¨ã®å½¼å¥³ã‚’æ¤œç´¢ã™ã‚‹
3. å½¼å¥³ã®å¹´é½¢ã‚’æ¤œç´¢ã™ã‚‹
4. æœ€å¾Œã«ã€é›»å“ãƒ„ãƒ¼ãƒ«ã‚’ä½¿ã£ã¦å½¼å¥³ã®å¹´é½¢ã‚’0.43ä¹—ã™ã‚‹è¨ˆç®—ã‚’ã™ã‚‹

ã‚ªãƒ¼ãƒ—ãƒ³ã‚½ãƒ¼ã‚¹ã®LLMãŒæ±ç”¨çš„ãªæ¨è«–ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆã¨ã—ã¦ã©ã“ã¾ã§é€²åŒ–ã§ãã‚‹ã‹ãŒã€ã¨ã¦ã‚‚ã‚¨ã‚­ã‚µã‚¤ãƒ†ã‚£ãƒ³ã‚°ã§ã™ã€‚ãœã²è‡ªåˆ†ã§ã‚‚è©¦ã—ã¦ã¿ã¦ãã ã•ã„!
