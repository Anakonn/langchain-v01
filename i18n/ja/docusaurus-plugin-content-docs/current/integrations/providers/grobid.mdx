---
translated: true
---

# Grobid

GROBIDは、生の文書から情報を抽出、解析、再構築するためのマシンラーニングライブラリです。

特に学術論文の解析に適しています。

*注意*: Grobidに提供される記事が大きな文書(例えば博士論文)で、一定数の要素を超える場合は処理されない可能性があります。

このページでは、LangChainでGrobidを使ってArticleを解析する方法を説明します。

## インストール

Grobidのインストールの詳細は https://grobid.readthedocs.io/en/latest/Install-Grobid/ に記載されています。
ただし、ドキュメント[ここ](https://grobid.readthedocs.io/en/latest/Grobid-docker/)に記載されているようにdockerコンテナを使ってGrobidを実行するのが簡単で面倒がありません。

## LangChainでGrobidを使う

Grobidがインストールされ、起動している(http://localhost:8070 にアクセスして確認できます)ら、準備完了です。

GrobidParserを使ってドキュメントを生成できます。

```python
<!--IMPORTS:[{"imported": "GrobidParser", "source": "langchain_community.document_loaders.parsers", "docs": "https://api.python.langchain.com/en/latest/document_loaders/langchain_community.document_loaders.parsers.grobid.GrobidParser.html", "title": "Grobid"}, {"imported": "GenericLoader", "source": "langchain_community.document_loaders.generic", "docs": "https://api.python.langchain.com/en/latest/document_loaders/langchain_community.document_loaders.generic.GenericLoader.html", "title": "Grobid"}]-->
from langchain_community.document_loaders.parsers import GrobidParser
from langchain_community.document_loaders.generic import GenericLoader

#Produce chunks from article paragraphs
loader = GenericLoader.from_filesystem(
    "/Users/31treehaus/Desktop/Papers/",
    glob="*",
    suffixes=[".pdf"],
    parser= GrobidParser(segment_sentences=False)
)
docs = loader.load()

#Produce chunks from article sentences
loader = GenericLoader.from_filesystem(
    "/Users/31treehaus/Desktop/Papers/",
    glob="*",
    suffixes=[".pdf"],
    parser= GrobidParser(segment_sentences=True)
)
docs = loader.load()
```

チャンクのメタデータには境界ボックスが含まれます。これらはちょっと変わった形式ですが、
https://grobid.readthedocs.io/en/latest/Coordinates-in-PDF/ で説明されています。
