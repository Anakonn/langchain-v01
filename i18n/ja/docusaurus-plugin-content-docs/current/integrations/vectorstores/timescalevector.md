---
translated: true
---

# Timescale Vector (Postgres)

>[Timescale Vector](https://www.timescale.com/ai?utm_campaign=vectorlaunch&utm_source=langchain&utm_medium=referral) ã¯AIã‚¢ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³ã®ãŸã‚ã® `PostgreSQL++` ãƒ™ã‚¯ã‚¿ãƒ¼ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã§ã™ã€‚

ã“ã®ãƒãƒ¼ãƒˆãƒ–ãƒƒã‚¯ã§ã¯ã€Postgresãƒ™ã‚¯ã‚¿ãƒ¼ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ `Timescale Vector` ã®ä½¿ã„æ–¹ã‚’ç´¹ä»‹ã—ã¾ã™ã€‚TimescaleVectorã‚’ä½¿ã£ã¦ (1) ã‚»ãƒãƒ³ãƒ†ã‚£ãƒƒã‚¯æ¤œç´¢ã€(2) æ™‚é–“ãƒ™ãƒ¼ã‚¹ã®ãƒ™ã‚¯ã‚¿ãƒ¼æ¤œç´¢ã€(3) è‡ªå·±ã‚¯ã‚¨ãƒªã€ãã—ã¦ (4) ã‚¯ã‚¨ãƒªã‚’é«˜é€ŸåŒ–ã™ã‚‹ãŸã‚ã®ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ã®ä½œæˆæ–¹æ³•ã‚’å­¦ã³ã¾ã™ã€‚

## Timescale Vectorã¨ã¯ï¼Ÿ

`Timescale Vector` ã¯ã€`PostgreSQL` ã«ãŠã„ã¦æ•°ç™¾ä¸‡ã®ãƒ™ã‚¯ã‚¿ãƒ¼åŸ‹ã‚è¾¼ã¿ã‚’åŠ¹ç‡çš„ã«ä¿å­˜ãŠã‚ˆã³ã‚¯ã‚¨ãƒªã™ã‚‹ã“ã¨ã‚’å¯èƒ½ã«ã—ã¾ã™ã€‚
- `pgvector` ã‚’å¼·åŒ–ã—ã€`DiskANN` ã«ã‚¤ãƒ³ã‚¹ãƒ‘ã‚¤ã‚¢ã•ã‚ŒãŸã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ã‚¢ãƒ«ã‚´ãƒªã‚ºãƒ ã«ã‚ˆã‚Šã€100M+ ãƒ™ã‚¯ã‚¿ãƒ¼ã®é«˜é€Ÿã‹ã¤æ­£ç¢ºãªé¡ä¼¼æ€§æ¤œç´¢ã‚’å®Ÿç¾ã—ã¾ã™ã€‚
- è‡ªå‹•çš„ãªæ™‚é–“ãƒ™ãƒ¼ã‚¹ã®ãƒ‘ãƒ¼ãƒ†ã‚£ã‚·ãƒ§ãƒ‹ãƒ³ã‚°ã¨ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ä½œæˆã«ã‚ˆã‚Šã€é«˜é€Ÿãªæ™‚é–“ãƒ™ãƒ¼ã‚¹ã®ãƒ™ã‚¯ã‚¿ãƒ¼æ¤œç´¢ã‚’å¯èƒ½ã«ã—ã¾ã™ã€‚
- ãƒ™ã‚¯ã‚¿ãƒ¼åŸ‹ã‚è¾¼ã¿ã¨ãƒªãƒ¬ãƒ¼ã‚·ãƒ§ãƒŠãƒ«ãƒ‡ãƒ¼ã‚¿ã‚’ã‚¯ã‚¨ãƒªã™ã‚‹ãŸã‚ã®ä½¿ã„æ…£ã‚ŒãŸSQLã‚¤ãƒ³ã‚¿ãƒ¼ãƒ•ã‚§ã‚¤ã‚¹ã‚’æä¾›ã—ã¾ã™ã€‚

`Timescale Vector` ã¯ã€POCã‹ã‚‰æœ¬ç•ªç’°å¢ƒã¾ã§ã‚¹ã‚±ãƒ¼ãƒ«ã™ã‚‹ã‚¯ãƒ©ã‚¦ãƒ‰ `PostgreSQL` for AIã§ã™ï¼š
- ãƒªãƒ¬ãƒ¼ã‚·ãƒ§ãƒŠãƒ«ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿ã€ãƒ™ã‚¯ã‚¿ãƒ¼åŸ‹ã‚è¾¼ã¿ã€ãŠã‚ˆã³æ™‚ç³»åˆ—ãƒ‡ãƒ¼ã‚¿ã‚’å˜ä¸€ã®ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã«ä¿å­˜ã™ã‚‹ã“ã¨ã§ã€é‹ç”¨ã‚’ç°¡ç´ åŒ–ã—ã¾ã™ã€‚
- ã‚¹ãƒˆãƒªãƒ¼ãƒŸãƒ³ã‚°ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—ã¨ãƒ¬ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³ã€é«˜å¯ç”¨æ€§ã€è¡Œãƒ¬ãƒ™ãƒ«ã®ã‚»ã‚­ãƒ¥ãƒªãƒ†ã‚£ãªã©ã€ã‚¨ãƒ³ã‚¿ãƒ¼ãƒ—ãƒ©ã‚¤ã‚ºã‚°ãƒ¬ãƒ¼ãƒ‰ã®æ©Ÿèƒ½ã‚’å‚™ãˆãŸå …ç‰¢ãªPostgreSQLåŸºç›¤ã®æ©æµã‚’å—ã‘ã¾ã™ã€‚
- ã‚¨ãƒ³ã‚¿ãƒ¼ãƒ—ãƒ©ã‚¤ã‚ºã‚°ãƒ¬ãƒ¼ãƒ‰ã®ã‚»ã‚­ãƒ¥ãƒªãƒ†ã‚£ãŠã‚ˆã³ã‚³ãƒ³ãƒ—ãƒ©ã‚¤ã‚¢ãƒ³ã‚¹ã«ã‚ˆã‚Šã€å®‰å¿ƒã—ã¦ä½¿ç”¨ã§ãã¾ã™ã€‚

## Timescale Vectorã¸ã®ã‚¢ã‚¯ã‚»ã‚¹æ–¹æ³•

`Timescale Vector` ã¯ã€ã‚¯ãƒ©ã‚¦ãƒ‰PostgreSQLãƒ—ãƒ©ãƒƒãƒˆãƒ•ã‚©ãƒ¼ãƒ  [Timescale](https://www.timescale.com/ai?utm_campaign=vectorlaunch&utm_source=langchain&utm_medium=referral) ã§åˆ©ç”¨å¯èƒ½ã§ã™ã€‚ï¼ˆç¾æ™‚ç‚¹ã§ã¯ã‚»ãƒ«ãƒ•ãƒ›ã‚¹ãƒˆç‰ˆã¯ã‚ã‚Šã¾ã›ã‚“ã€‚ï¼‰

LangChainãƒ¦ãƒ¼ã‚¶ãƒ¼ã¯ã€Timescale Vectorã‚’90æ—¥é–“ç„¡æ–™ã§è©¦ç”¨ã§ãã¾ã™ã€‚
- å§‹ã‚ã‚‹ã«ã¯ã€Timescaleã«[ã‚µã‚¤ãƒ³ã‚¢ãƒƒãƒ—](https://console.cloud.timescale.com/signup?utm_campaign=vectorlaunch&utm_source=langchain&utm_medium=referral)ã—ã€æ–°ã—ã„ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã‚’ä½œæˆã—ã€ã“ã®ãƒãƒ¼ãƒˆãƒ–ãƒƒã‚¯ã«å¾“ã£ã¦ãã ã•ã„ï¼
- è©³ç´°ãŠã‚ˆã³ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯ã«ã¤ã„ã¦ã¯ã€[Timescale Vectorã®èª¬æ˜ãƒ–ãƒ­ã‚°](https://www.timescale.com/blog/how-we-made-postgresql-the-best-vector-database/?utm_campaign=vectorlaunch&utm_source=langchain&utm_medium=referral) ã‚’å‚ç…§ã—ã¦ãã ã•ã„ã€‚
- Pythonã§Timescale Vectorã‚’ä½¿ç”¨ã™ã‚‹éš›ã®è©³ç´°ã«ã¤ã„ã¦ã¯ã€[ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«æ‰‹é †](https://github.com/timescale/python-vector) ã‚’å‚ç…§ã—ã¦ãã ã•ã„ã€‚

## ã‚»ãƒƒãƒˆã‚¢ãƒƒãƒ—

ã“ã®ãƒãƒ¥ãƒ¼ãƒˆãƒªã‚¢ãƒ«ã«å¾“ã†æº–å‚™ã‚’ã™ã‚‹ãŸã‚ã«ã€ä»¥ä¸‹ã®æ‰‹é †ã«å¾“ã£ã¦ãã ã•ã„ã€‚

```python
# Pip install necessary packages
%pip install --upgrade --quiet  timescale-vector
%pip install --upgrade --quiet  langchain-openai
%pip install --upgrade --quiet  tiktoken
```

ã“ã®ä¾‹ã§ã¯ `OpenAIEmbeddings` ã‚’ä½¿ç”¨ã™ã‚‹ã®ã§ã€OpenAI APIã‚­ãƒ¼ã‚’ãƒ­ãƒ¼ãƒ‰ã—ã¾ã—ã‚‡ã†ã€‚

```python
import os

# Run export OPENAI_API_KEY=sk-YOUR_OPENAI_API_KEY...
# Get openAI api key by reading local .env file
from dotenv import find_dotenv, load_dotenv

_ = load_dotenv(find_dotenv())
OPENAI_API_KEY = os.environ["OPENAI_API_KEY"]
```

```python
# Get the API key and save it as an environment variable
# import os
# import getpass
# os.environ["OPENAI_API_KEY"] = getpass.getpass("OpenAI API Key:")

```

```python
from typing import Tuple
```

æ¬¡ã«ã€å¿…è¦ãªPythonãƒ©ã‚¤ãƒ–ãƒ©ãƒªã¨LangChainã‹ã‚‰ã®ãƒ©ã‚¤ãƒ–ãƒ©ãƒªã‚’ã‚¤ãƒ³ãƒãƒ¼ãƒˆã—ã¾ã™ã€‚`timescale-vector` ãƒ©ã‚¤ãƒ–ãƒ©ãƒªãŠã‚ˆã³TimescaleVector LangChain vectorstoreã‚‚ã‚¤ãƒ³ãƒãƒ¼ãƒˆã™ã‚‹ã“ã¨ã«æ³¨æ„ã—ã¦ãã ã•ã„ã€‚

```python
from datetime import datetime, timedelta

from langchain_community.docstore.document import Document
from langchain_community.document_loaders import TextLoader
from langchain_community.document_loaders.json_loader import JSONLoader
from langchain_community.vectorstores.timescalevector import TimescaleVector
from langchain_openai import OpenAIEmbeddings
from langchain_text_splitters import CharacterTextSplitter
```

## 1. ãƒ¦ãƒ¼ã‚¯ãƒªãƒƒãƒ‰è·é›¢ã«ã‚ˆã‚‹é¡ä¼¼æ€§æ¤œç´¢ï¼ˆãƒ‡ãƒ•ã‚©ãƒ«ãƒˆï¼‰

ã¾ãšã€ä¸ãˆã‚‰ã‚ŒãŸã‚¯ã‚¨ãƒªæ–‡ã«æœ€ã‚‚é¡ä¼¼ã—ãŸæ–‡ã‚’è¦‹ã¤ã‘ã‚‹ãŸã‚ã«ã€State of the Unionã‚¹ãƒ”ãƒ¼ãƒã§é¡ä¼¼æ€§æ¤œç´¢ã‚¯ã‚¨ãƒªã‚’å®Ÿè¡Œã™ã‚‹ä¾‹ã‚’è¦‹ã¦ã¿ã¾ã—ã‚‡ã†ã€‚é¡ä¼¼æ€§ãƒ¡ãƒˆãƒªãƒƒã‚¯ã¨ã—ã¦[ãƒ¦ãƒ¼ã‚¯ãƒªãƒƒãƒ‰è·é›¢](https://en.wikipedia.org/wiki/Euclidean_distance)ã‚’ä½¿ç”¨ã—ã¾ã™ã€‚

```python
# Load the text and split it into chunks
loader = TextLoader("../../../extras/modules/state_of_the_union.txt")
documents = loader.load()
text_splitter = CharacterTextSplitter(chunk_size=1000, chunk_overlap=0)
docs = text_splitter.split_documents(documents)

embeddings = OpenAIEmbeddings()
```

æ¬¡ã«ã€Timescaleãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã®ã‚µãƒ¼ãƒ“ã‚¹URLã‚’ãƒ­ãƒ¼ãƒ‰ã—ã¾ã™ã€‚

ã¾ã ã§ã‚ã‚Œã°ã€[Timescaleã«ã‚µã‚¤ãƒ³ã‚¢ãƒƒãƒ—](https://console.cloud.timescale.com/signup?utm_campaign=vectorlaunch&utm_source=langchain&utm_medium=referral)ã—ã€æ–°ã—ã„ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã‚’ä½œæˆã—ã¾ã™ã€‚

æ¬¡ã«ã€PostgreSQLãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã«æ¥ç¶šã™ã‚‹ãŸã‚ã«ã€ã‚µãƒ¼ãƒ“ã‚¹URIãŒå¿…è¦ã§ã™ã€‚ã“ã‚Œã¯ã€æ–°ã—ã„ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã‚’ä½œæˆã—ãŸå¾Œã«ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ã—ãŸãƒãƒ¼ãƒˆã‚·ãƒ¼ãƒˆã¾ãŸã¯ `.env` ãƒ•ã‚¡ã‚¤ãƒ«ã«è¨˜è¼‰ã•ã‚Œã¦ã„ã¾ã™ã€‚

URIã¯æ¬¡ã®ã‚ˆã†ã«ãªã‚Šã¾ã™ï¼š`postgres://tsdbadmin:<password>@<id>.tsdb.cloud.timescale.com:<port>/tsdb?sslmode=require`.

```python
# Timescale Vector needs the service url to your cloud database. You can see this as soon as you create the
# service in the cloud UI or in your credentials.sql file
SERVICE_URL = os.environ["TIMESCALE_SERVICE_URL"]

# Specify directly if testing
# SERVICE_URL = "postgres://tsdbadmin:<password>@<id>.tsdb.cloud.timescale.com:<port>/tsdb?sslmode=require"

# # You can get also it from an environment variables. We suggest using a .env file.
# import os
# SERVICE_URL = os.environ.get("TIMESCALE_SERVICE_URL", "")
```

æ¬¡ã«TimescaleVector vectorstoreã‚’ä½œæˆã—ã¾ã™ã€‚ãƒ‡ãƒ¼ã‚¿ãŒä¿å­˜ã•ã‚Œã‚‹ãƒ†ãƒ¼ãƒ–ãƒ«ã®åå‰ã«ãªã‚‹ã‚³ãƒ¬ã‚¯ã‚·ãƒ§ãƒ³åã‚’æŒ‡å®šã—ã¾ã™ã€‚

æ³¨æ„ï¼šæ–°ã—ã„ã‚¤ãƒ³ã‚¹ã‚¿ãƒ³ã‚¹ã®TimescaleVectorã‚’ä½œæˆã™ã‚‹éš›ã€TimescaleVectorãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«ã¯ã‚³ãƒ¬ã‚¯ã‚·ãƒ§ãƒ³ã®åå‰ã§ãƒ†ãƒ¼ãƒ–ãƒ«ã‚’ä½œæˆã—ã‚ˆã†ã¨ã—ã¾ã™ã€‚ãã®ãŸã‚ã€ã‚³ãƒ¬ã‚¯ã‚·ãƒ§ãƒ³åãŒä¸€æ„ã§ã‚ã‚‹ã“ã¨ï¼ˆã¤ã¾ã‚Šæ—¢ã«å­˜åœ¨ã—ãªã„ã“ã¨ï¼‰ã‚’ç¢ºèªã—ã¦ãã ã•ã„ã€‚

```python
# The TimescaleVector Module will create a table with the name of the collection.
COLLECTION_NAME = "state_of_the_union_test"

# Create a Timescale Vector instance from the collection of documents
db = TimescaleVector.from_documents(
    embedding=embeddings,
    documents=docs,
    collection_name=COLLECTION_NAME,
    service_url=SERVICE_URL,
)
```

ãƒ‡ãƒ¼ã‚¿ã‚’ãƒ­ãƒ¼ãƒ‰ã—ãŸã®ã§ã€é¡ä¼¼æ€§æ¤œç´¢ã‚’å®Ÿè¡Œã§ãã¾ã™ã€‚

```python
query = "What did the president say about Ketanji Brown Jackson"
docs_with_score = db.similarity_search_with_score(query)
```

```python
for doc, score in docs_with_score:
    print("-" * 80)
    print("Score: ", score)
    print(doc.page_content)
    print("-" * 80)
```

```output
--------------------------------------------------------------------------------
Score:  0.18443380687035138
Tonight. I call on the Senate to: Pass the Freedom to Vote Act. Pass the John Lewis Voting Rights Act. And while youâ€™re at it, pass the Disclose Act so Americans can know who is funding our elections.

Tonight, Iâ€™d like to honor someone who has dedicated his life to serve this country: Justice Stephen Breyerâ€”an Army veteran, Constitutional scholar, and retiring Justice of the United States Supreme Court. Justice Breyer, thank you for your service.

One of the most serious constitutional responsibilities a President has is nominating someone to serve on the United States Supreme Court.

And I did that 4 days ago, when I nominated Circuit Court of Appeals Judge Ketanji Brown Jackson. One of our nationâ€™s top legal minds, who will continue Justice Breyerâ€™s legacy of excellence.
--------------------------------------------------------------------------------
--------------------------------------------------------------------------------
Score:  0.18452197313308139
Tonight. I call on the Senate to: Pass the Freedom to Vote Act. Pass the John Lewis Voting Rights Act. And while youâ€™re at it, pass the Disclose Act so Americans can know who is funding our elections.

Tonight, Iâ€™d like to honor someone who has dedicated his life to serve this country: Justice Stephen Breyerâ€”an Army veteran, Constitutional scholar, and retiring Justice of the United States Supreme Court. Justice Breyer, thank you for your service.

One of the most serious constitutional responsibilities a President has is nominating someone to serve on the United States Supreme Court.

And I did that 4 days ago, when I nominated Circuit Court of Appeals Judge Ketanji Brown Jackson. One of our nationâ€™s top legal minds, who will continue Justice Breyerâ€™s legacy of excellence.
--------------------------------------------------------------------------------
--------------------------------------------------------------------------------
Score:  0.21720781018594182
A former top litigator in private practice. A former federal public defender. And from a family of public school educators and police officers. A consensus builder. Since sheâ€™s been nominated, sheâ€™s received a broad range of supportâ€”from the Fraternal Order of Police to former judges appointed by Democrats and Republicans.

And if we are to advance liberty and justice, we need to secure the Border and fix the immigration system.

We can do both. At our border, weâ€™ve installed new technology like cutting-edge scanners to better detect drug smuggling.

Weâ€™ve set up joint patrols with Mexico and Guatemala to catch more human traffickers.

Weâ€™re putting in place dedicated immigration judges so families fleeing persecution and violence can have their cases heard faster.

Weâ€™re securing commitments and supporting partners in South and Central America to host more refugees and secure their own borders.
--------------------------------------------------------------------------------
--------------------------------------------------------------------------------
Score:  0.21724902288621384
A former top litigator in private practice. A former federal public defender. And from a family of public school educators and police officers. A consensus builder. Since sheâ€™s been nominated, sheâ€™s received a broad range of supportâ€”from the Fraternal Order of Police to former judges appointed by Democrats and Republicans.

And if we are to advance liberty and justice, we need to secure the Border and fix the immigration system.

We can do both. At our border, weâ€™ve installed new technology like cutting-edge scanners to better detect drug smuggling.

Weâ€™ve set up joint patrols with Mexico and Guatemala to catch more human traffickers.

Weâ€™re putting in place dedicated immigration judges so families fleeing persecution and violence can have their cases heard faster.

Weâ€™re securing commitments and supporting partners in South and Central America to host more refugees and secure their own borders.
--------------------------------------------------------------------------------
```

### ãƒ¬ãƒˆãƒªãƒãƒ¼ã¨ã—ã¦ã®Timescale Vectorã®ä½¿ç”¨

TimescaleVectorã‚¹ãƒˆã‚¢ã‚’åˆæœŸåŒ–ã—ãŸå¾Œã€ãã‚Œã‚’[ãƒ¬ãƒˆãƒªãƒãƒ¼](/docs/modules/data_connection/retrievers/)ã¨ã—ã¦ä½¿ç”¨ã§ãã¾ã™ã€‚

```python
# Use TimescaleVector as a retriever
retriever = db.as_retriever()
```

```python
print(retriever)
```

```output
tags=['TimescaleVector', 'OpenAIEmbeddings'] metadata=None vectorstore=<langchain_community.vectorstores.timescalevector.TimescaleVector object at 0x10fc8d070> search_type='similarity' search_kwargs={}
```

Timescale Vectorã‚’ãƒ¬ãƒˆãƒªãƒãƒ¼ã¨ã—ã¦ä½¿ç”¨ã™ã‚‹ä¾‹ã‚’ã€RetrievalQAãƒã‚§ãƒ¼ãƒ³ãŠã‚ˆã³stuff documentsãƒã‚§ãƒ¼ãƒ³ã§è¦‹ã¦ã¿ã¾ã—ã‚‡ã†ã€‚

ã“ã®ä¾‹ã§ã¯ã€ä¸Šè¨˜ã¨åŒã˜ã‚¯ã‚¨ãƒªã‚’å®Ÿè¡Œã—ã¾ã™ãŒã€ã“ã®æ™‚ã¯Timescale Vectorã‹ã‚‰è¿”ã•ã‚ŒãŸé–¢é€£æ–‡æ›¸ã‚’ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆã¨ã—ã¦LLMã«æ¸¡ã—ã¦ã€è³ªå•ã«ç­”ãˆã¾ã™ã€‚

ã¾ãšã€stuffãƒã‚§ãƒ¼ãƒ³ã‚’ä½œæˆã—ã¾ã™ï¼š

```python
# Initialize GPT3.5 model
from langchain_openai import ChatOpenAI

llm = ChatOpenAI(temperature=0.1, model="gpt-3.5-turbo-16k")

# Initialize a RetrievalQA class from a stuff chain
from langchain.chains import RetrievalQA

qa_stuff = RetrievalQA.from_chain_type(
    llm=llm,
    chain_type="stuff",
    retriever=retriever,
    verbose=True,
)
```

```python
query = "What did the president say about Ketanji Brown Jackson?"
response = qa_stuff.run(query)
```

```output


[1m> Entering new RetrievalQA chain...[0m

[1m> Finished chain.[0m
```

```python
print(response)
```

```output
The President said that he nominated Circuit Court of Appeals Judge Ketanji Brown Jackson, who is one of our nation's top legal minds and will continue Justice Breyer's legacy of excellence. He also mentioned that since her nomination, she has received a broad range of support from various groups, including the Fraternal Order of Police and former judges appointed by Democrats and Republicans.
```

## 2. æ™‚é–“ãƒ™ãƒ¼ã‚¹ã®ãƒ•ã‚£ãƒ«ã‚¿ãƒªãƒ³ã‚°ã«ã‚ˆã‚‹é¡ä¼¼æ€§æ¤œç´¢

Timescale Vectorã®ä¸»è¦ãªä½¿ç”¨ä¾‹ã¯ã€åŠ¹ç‡çš„ãªæ™‚é–“ãƒ™ãƒ¼ã‚¹ã®ãƒ™ã‚¯ã‚¿ãƒ¼æ¤œç´¢ã§ã™ã€‚Timescale Vectorã¯ãƒ™ã‚¯ã‚¿ãƒ¼ï¼ˆãŠã‚ˆã³é–¢é€£ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿ï¼‰ã‚’æ™‚é–“ã§è‡ªå‹•çš„ã«ãƒ‘ãƒ¼ãƒ†ã‚£ã‚·ãƒ§ãƒ‹ãƒ³ã‚°ã™ã‚‹ã“ã¨ã§ã“ã‚Œã‚’å®Ÿç¾ã—ã¾ã™ã€‚ã“ã‚Œã«ã‚ˆã‚Šã€ã‚¯ã‚¨ãƒªãƒ™ã‚¯ã‚¿ãƒ¼ã¨ã®é¡ä¼¼æ€§ã¨æ™‚é–“ã®ä¸¡æ–¹ã§ãƒ™ã‚¯ã‚¿ãƒ¼ã‚’åŠ¹ç‡çš„ã«ã‚¯ã‚¨ãƒªã§ãã¾ã™ã€‚

æ™‚é–“ãƒ™ãƒ¼ã‚¹ã®ãƒ™ã‚¯ã‚¿ãƒ¼æ¤œç´¢æ©Ÿèƒ½ã¯ã€ä»¥ä¸‹ã®ã‚ˆã†ãªã‚¢ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³ã«å½¹ç«‹ã¡ã¾ã™ï¼š
- LLMå¿œç­”å±¥æ­´ã®ä¿å­˜ã¨å–å¾—ï¼ˆä¾‹ï¼šãƒãƒ£ãƒƒãƒˆãƒœãƒƒãƒˆï¼‰
- ã‚¯ã‚¨ãƒªãƒ™ã‚¯ã‚¿ãƒ¼ã«é¡ä¼¼ã—ãŸæœ€æ–°ã®åŸ‹ã‚è¾¼ã¿ã®æ¤œç´¢ï¼ˆä¾‹ï¼šæœ€è¿‘ã®ãƒ‹ãƒ¥ãƒ¼ã‚¹ï¼‰
- çŸ¥è­˜ãƒ™ãƒ¼ã‚¹ã«é–¢ã™ã‚‹æ™‚é–“ãƒ™ãƒ¼ã‚¹ã®è³ªå•ã‚’ã™ã‚‹ãŸã‚ã®é¡ä¼¼æ€§æ¤œç´¢ã®åˆ¶ç´„ï¼ˆä¾‹ï¼šæ™‚é–“ãƒ™ãƒ¼ã‚¹ã®è³ªå•ï¼‰

TimescaleVectorã®æ™‚é–“ãƒ™ãƒ¼ã‚¹ã®ãƒ™ã‚¯ã‚¿ãƒ¼æ¤œç´¢æ©Ÿèƒ½ã®ä½¿ã„æ–¹ã‚’èª¬æ˜ã™ã‚‹ãŸã‚ã«ã€TimescaleDBã®gitãƒ­ã‚°å±¥æ­´ã«ã¤ã„ã¦è³ªå•ã—ã¾ã™ã€‚ã‚¿ã‚¤ãƒ ãƒ™ãƒ¼ã‚¹ã®UUIDã‚’ä½¿ç”¨ã—ã¦æ–‡æ›¸ã‚’è¿½åŠ ã—ã€æ™‚é–“ç¯„å›²ãƒ•ã‚£ãƒ«ã‚¿ãƒ¼ã§é¡ä¼¼æ€§æ¤œç´¢ã‚’å®Ÿè¡Œã™ã‚‹æ–¹æ³•ã‚’èª¬æ˜ã—ã¾ã™ã€‚

### gitãƒ­ã‚°JSONã‹ã‚‰ã®ã‚³ãƒ³ãƒ†ãƒ³ãƒ„ã¨ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿ã®æŠ½å‡º

ã¾ãšã€gitãƒ­ã‚°ãƒ‡ãƒ¼ã‚¿ã‚’ `timescale_commits` ã¨ã„ã†åå‰ã®æ–°ã—ã„ã‚³ãƒ¬ã‚¯ã‚·ãƒ§ãƒ³ã«PostgreSQLãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã«ãƒ­ãƒ¼ãƒ‰ã—ã¾ã™ã€‚

ã‚¿ã‚¤ãƒ ã‚¹ã‚¿ãƒ³ãƒ—ã«åŸºã¥ã„ã¦ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆã¨é–¢é€£ãƒ™ã‚¯ã‚¿ãƒ¼åŸ‹ã‚è¾¼ã¿ã®ãŸã‚ã®UUIDã‚’ä½œæˆã™ã‚‹ãƒ˜ãƒ«ãƒ‘ãƒ¼é–¢æ•°ã‚’å®šç¾©ã—ã¾ã™ã€‚ã“ã®é–¢æ•°ã‚’ä½¿ç”¨ã—ã¦ã€å„gitãƒ­ã‚°ã‚¨ãƒ³ãƒˆãƒªã®UUIDã‚’ä½œæˆã—ã¾ã™ã€‚

é‡è¦ãªæ³¨æ„ç‚¹ï¼šãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆã‚’æ‰±ã£ã¦ã„ã¦ã€æ™‚é–“ãƒ™ãƒ¼ã‚¹ã®æ¤œç´¢ã®ãŸã‚ã«ãƒ™ã‚¯ã‚¿ãƒ¼ã«ç¾åœ¨ã®æ—¥ä»˜ã¨æ™‚åˆ»ã‚’é–¢é€£ä»˜ã‘ãŸã„å ´åˆã¯ã€ã“ã®æ‰‹é †ã‚’ã‚¹ã‚­ãƒƒãƒ—ã§ãã¾ã™ã€‚ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆã§ã¯ã€ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆãŒã‚¤ãƒ³ã‚¸ã‚§ã‚¹ãƒˆã•ã‚Œã‚‹ã¨ãã«UUIDãŒè‡ªå‹•çš„ã«ç”Ÿæˆã•ã‚Œã¾ã™ã€‚

```python
from timescale_vector import client


# Function to take in a date string in the past and return a uuid v1
def create_uuid(date_string: str):
    if date_string is None:
        return None
    time_format = "%a %b %d %H:%M:%S %Y %z"
    datetime_obj = datetime.strptime(date_string, time_format)
    uuid = client.uuid_from_time(datetime_obj)
    return str(uuid)
```

æ¬¡ã«ã€JSONãƒ¬ã‚³ãƒ¼ãƒ‰ã‹ã‚‰é–¢é€£ã™ã‚‹ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿ã‚’æŠ½å‡ºã™ã‚‹ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿é–¢æ•°ã‚’å®šç¾©ã—ã¾ã™ã€‚ã“ã®é–¢æ•°ã‚’JSONLoaderã«æ¸¡ã—ã¾ã™ã€‚è©³ç´°ã«ã¤ã„ã¦ã¯ã€[JSONãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆãƒ­ãƒ¼ãƒ€ãƒ¼ã®ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆ](/docs/modules/data_connection/document_loaders/json) ã‚’å‚ç…§ã—ã¦ãã ã•ã„ã€‚

```python
# Helper function to split name and email given an author string consisting of Name Lastname <email>
def split_name(input_string: str) -> Tuple[str, str]:
    if input_string is None:
        return None, None
    start = input_string.find("<")
    end = input_string.find(">")
    name = input_string[:start].strip()
    email = input_string[start + 1 : end].strip()
    return name, email


# Helper function to transform a date string into a timestamp_tz string
def create_date(input_string: str) -> datetime:
    if input_string is None:
        return None
    # Define a dictionary to map month abbreviations to their numerical equivalents
    month_dict = {
        "Jan": "01",
        "Feb": "02",
        "Mar": "03",
        "Apr": "04",
        "May": "05",
        "Jun": "06",
        "Jul": "07",
        "Aug": "08",
        "Sep": "09",
        "Oct": "10",
        "Nov": "11",
        "Dec": "12",
    }

    # Split the input string into its components
    components = input_string.split()
    # Extract relevant information
    day = components[2]
    month = month_dict[components[1]]
    year = components[4]
    time = components[3]
    timezone_offset_minutes = int(components[5])  # Convert the offset to minutes
    timezone_hours = timezone_offset_minutes // 60  # Calculate the hours
    timezone_minutes = timezone_offset_minutes % 60  # Calculate the remaining minutes
    # Create a formatted string for the timestamptz in PostgreSQL format
    timestamp_tz_str = (
        f"{year}-{month}-{day} {time}+{timezone_hours:02}{timezone_minutes:02}"
    )
    return timestamp_tz_str


# Metadata extraction function to extract metadata from a JSON record
def extract_metadata(record: dict, metadata: dict) -> dict:
    record_name, record_email = split_name(record["author"])
    metadata["id"] = create_uuid(record["date"])
    metadata["date"] = create_date(record["date"])
    metadata["author_name"] = record_name
    metadata["author_email"] = record_email
    metadata["commit_hash"] = record["commit"]
    return metadata
```

æ¬¡ã«ã€[ã‚µãƒ³ãƒ—ãƒ«ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã‚’ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰](https://s3.amazonaws.com/assets.timescale.com/ai/ts_git_log.json)ã—ã€ã“ã®ãƒãƒ¼ãƒˆãƒ–ãƒƒã‚¯ã¨åŒã˜ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã«é…ç½®ã—ã¾ã™ã€‚

ä»¥ä¸‹ã®ã‚³ãƒãƒ³ãƒ‰ã‚’ä½¿ç”¨ã§ãã¾ã™ï¼š

```python
# Download the file using curl and save it as commit_history.csv
# Note: Execute this command in your terminal, in the same directory as the notebook
!curl -O https://s3.amazonaws.com/assets.timescale.com/ai/ts_git_log.json
```

æœ€å¾Œã«ã€JSONãƒ¬ã‚³ãƒ¼ãƒ‰ã‚’è§£æã™ã‚‹ãŸã‚ã«JSONãƒ­ãƒ¼ãƒ€ãƒ¼ã‚’åˆæœŸåŒ–ã—ã¾ã™ã€‚ç°¡å˜ã®ãŸã‚ã€ç©ºã®ãƒ¬ã‚³ãƒ¼ãƒ‰ã‚’å‰Šé™¤ã—ã¾ã™ã€‚

```python
# Define path to the JSON file relative to this notebook
# Change this to the path to your JSON file
FILE_PATH = "../../../../../ts_git_log.json"

# Load data from JSON file and extract metadata
loader = JSONLoader(
    file_path=FILE_PATH,
    jq_schema=".commit_history[]",
    text_content=False,
    metadata_func=extract_metadata,
)
documents = loader.load()

# Remove documents with None dates
documents = [doc for doc in documents if doc.metadata["date"] is not None]
```

```python
print(documents[0])
```

```output
page_content='{"commit": "44e41c12ab25e36c202f58e068ced262eadc8d16", "author": "Lakshmi Narayanan Sreethar<lakshmi@timescale.com>", "date": "Tue Sep 5 21:03:21 2023 +0530", "change summary": "Fix segfault in set_integer_now_func", "change details": "When an invalid function oid is passed to set_integer_now_func, it finds out that the function oid is invalid but before throwing the error, it calls ReleaseSysCache on an invalid tuple causing a segfault. Fixed that by removing the invalid call to ReleaseSysCache.  Fixes #6037 "}' metadata={'source': '/Users/avtharsewrathan/sideprojects2023/timescaleai/tsv-langchain/ts_git_log.json', 'seq_num': 1, 'id': '8b407680-4c01-11ee-96a6-b82284ddccc6', 'date': '2023-09-5 21:03:21+0850', 'author_name': 'Lakshmi Narayanan Sreethar', 'author_email': 'lakshmi@timescale.com', 'commit_hash': '44e41c12ab25e36c202f58e068ced262eadc8d16'}
```

### TimescaleVector vectorstoreã¸ã®ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆã¨ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿ã®ãƒ­ãƒ¼ãƒ‰

ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆã®æº–å‚™ãŒæ•´ã£ãŸã®ã§ã€ã“ã‚Œã‚’å‡¦ç†ã—ã€ãƒ™ã‚¯ã‚¿ãƒ¼åŸ‹ã‚è¾¼ã¿è¡¨ç¾ã¨ã¨ã‚‚ã«TimescaleVector vectorstoreã«ãƒ­ãƒ¼ãƒ‰ã—ã¾ã™ã€‚

ã“ã‚Œã¯ãƒ‡ãƒ¢ãªã®ã§ã€æœ€åˆã®500ãƒ¬ã‚³ãƒ¼ãƒ‰ã®ã¿ã‚’ãƒ­ãƒ¼ãƒ‰ã—ã¾ã™ã€‚å®Ÿéš›ã«ã¯ã€å¿…è¦ãªã ã‘å¤šãã®ãƒ¬ã‚³ãƒ¼ãƒ‰ã‚’ãƒ­ãƒ¼ãƒ‰ã§ãã¾ã™ã€‚

```python
NUM_RECORDS = 500
documents = documents[:NUM_RECORDS]
```

æ¬¡ã«ã€CharacterTextSplitterã‚’ä½¿ç”¨ã—ã¦ã€æ–‡æ›¸ã‚’å¿…è¦ã«å¿œã˜ã¦å°ã•ãªãƒãƒ£ãƒ³ã‚¯ã«åˆ†å‰²ã—ã€åŸ‹ã‚è¾¼ã¿ã‚’å®¹æ˜“ã«ã—ã¾ã™ã€‚ã“ã®åˆ†å‰²ãƒ—ãƒ­ã‚»ã‚¹ã¯ã€å„æ–‡æ›¸ã®ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿ã‚’ä¿æŒã—ã¾ã™ã€‚

```python
# Split the documents into chunks for embedding
text_splitter = CharacterTextSplitter(
    chunk_size=1000,
    chunk_overlap=200,
)
docs = text_splitter.split_documents(documents)
```

æ¬¡ã«ã€å‰å‡¦ç†ãŒå®Œäº†ã—ãŸãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆã®ã‚³ãƒ¬ã‚¯ã‚·ãƒ§ãƒ³ã‹ã‚‰Timescale Vectorã‚¤ãƒ³ã‚¹ã‚¿ãƒ³ã‚¹ã‚’ä½œæˆã—ã¾ã™ã€‚

ã¾ãšã€ã‚³ãƒ¬ã‚¯ã‚·ãƒ§ãƒ³åã‚’å®šç¾©ã—ã¾ã™ã€‚ã“ã‚Œã¯PostgreSQLãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã®ãƒ†ãƒ¼ãƒ–ãƒ«åã«ãªã‚Šã¾ã™ã€‚

ã¾ãŸã€ã‚¿ã‚¤ãƒ ãƒ‡ãƒ«ã‚¿ã‚’å®šç¾©ã—ã€`time_partition_interval` å¼•æ•°ã«æ¸¡ã—ã¾ã™ã€‚ã“ã‚Œã¯ãƒ‡ãƒ¼ã‚¿ã‚’æ™‚é–“ã§ãƒ‘ãƒ¼ãƒ†ã‚£ã‚·ãƒ§ãƒ‹ãƒ³ã‚°ã™ã‚‹ãŸã‚ã®é–“éš”ã¨ã—ã¦ä½¿ç”¨ã•ã‚Œã¾ã™ã€‚å„ãƒ‘ãƒ¼ãƒ†ã‚£ã‚·ãƒ§ãƒ³ã¯æŒ‡å®šã•ã‚ŒãŸæœŸé–“ã®ãƒ‡ãƒ¼ã‚¿ã§æ§‹æˆã•ã‚Œã¾ã™ã€‚ç°¡å˜ã®ãŸã‚ã«7æ—¥é–“ã‚’ä½¿ç”¨ã—ã¾ã™ãŒã€ãƒ¦ãƒ¼ã‚¹ã‚±ãƒ¼ã‚¹ã«å¿œã˜ã¦é©åˆ‡ãªå€¤ã‚’é¸æŠã§ãã¾ã™ã€‚ä¾‹ãˆã°ã€æœ€è¿‘ã®ãƒ™ã‚¯ã‚¿ãƒ¼ã‚’é »ç¹ã«ã‚¯ã‚¨ãƒªã™ã‚‹å ´åˆã¯1æ—¥ãªã©ã®å°ã•ãªã‚¿ã‚¤ãƒ ãƒ‡ãƒ«ã‚¿ã‚’ä½¿ç”¨ã™ã‚‹ã“ã¨ãŒã§ãã¾ã™ã—ã€æ•°åå¹´ã«æ¸¡ã‚‹ãƒ™ã‚¯ã‚¿ãƒ¼ã‚’ã‚¯ã‚¨ãƒªã™ã‚‹å ´åˆã¯6ãƒ¶æœˆã‚„1å¹´ãªã©ã®å¤§ããªã‚¿ã‚¤ãƒ ãƒ‡ãƒ«ã‚¿ã‚’ä½¿ç”¨ã™ã‚‹ã“ã¨ãŒã§ãã¾ã™ã€‚

æœ€å¾Œã«ã€TimescaleVectorã‚¤ãƒ³ã‚¹ã‚¿ãƒ³ã‚¹ã‚’ä½œæˆã—ã¾ã™ã€‚å‰å‡¦ç†ã‚¹ãƒ†ãƒƒãƒ—ã§ä½œæˆã—ãŸãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿ã®`uuid`ãƒ•ã‚£ãƒ¼ãƒ«ãƒ‰ã‚’ `ids` å¼•æ•°ã«æŒ‡å®šã—ã¾ã™ã€‚ã“ã‚Œã¯ã€UUIDã®æ™‚é–“éƒ¨åˆ†ãŒéå»ã®æ—¥ä»˜ã‚’åæ˜ ã™ã‚‹ã‚ˆã†ã«ã™ã‚‹ãŸã‚ã§ã™ï¼ˆã¤ã¾ã‚Šã€ã‚³ãƒŸãƒƒãƒˆãŒè¡Œã‚ã‚ŒãŸæ™‚ï¼‰ã€‚ãŸã ã—ã€ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆã«ç¾åœ¨ã®æ—¥ä»˜ã¨æ™‚åˆ»ã‚’é–¢é€£ä»˜ã‘ãŸã„å ´åˆã¯ã€idå¼•æ•°ã‚’å‰Šé™¤ã—ã¦UUIDã‚’è‡ªå‹•çš„ã«ç¾åœ¨ã®æ—¥ä»˜ã¨æ™‚åˆ»ã§ä½œæˆã™ã‚‹ã“ã¨ãŒã§ãã¾ã™ã€‚

```python
# Define collection name
COLLECTION_NAME = "timescale_commits"
embeddings = OpenAIEmbeddings()

# Create a Timescale Vector instance from the collection of documents
db = TimescaleVector.from_documents(
    embedding=embeddings,
    ids=[doc.metadata["id"] for doc in docs],
    documents=docs,
    collection_name=COLLECTION_NAME,
    service_url=SERVICE_URL,
    time_partition_interval=timedelta(days=7),
)
```

### æ™‚é–“ã¨é¡ä¼¼æ€§ã«ã‚ˆã‚‹ãƒ™ã‚¯ãƒˆãƒ«ã®ã‚¯ã‚¨ãƒª

TimescaleVectorã«ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆã‚’ãƒ­ãƒ¼ãƒ‰ã—ãŸã®ã§ã€æ™‚é–“ã¨é¡ä¼¼æ€§ã§ã‚¯ã‚¨ãƒªã‚’å®Ÿè¡Œã§ãã¾ã™ã€‚

TimescaleVectorã¯ã€æ™‚é–“ãƒ™ãƒ¼ã‚¹ã®ãƒ•ã‚£ãƒ«ã‚¿ãƒªãƒ³ã‚°ã‚’ä½¿ç”¨ã—ã¦é¡ä¼¼æ€§æ¤œç´¢ã‚’è¡Œã†ãŸã‚ã®è¤‡æ•°ã®æ–¹æ³•ã‚’æä¾›ã—ã¾ã™ã€‚

ä»¥ä¸‹ã«å„æ–¹æ³•ã‚’è¦‹ã¦ã¿ã¾ã—ã‚‡ã†ï¼š

```python
# Time filter variables
start_dt = datetime(2023, 8, 1, 22, 10, 35)  # Start date = 1 August 2023, 22:10:35
end_dt = datetime(2023, 8, 30, 22, 10, 35)  # End date = 30 August 2023, 22:10:35
td = timedelta(days=7)  # Time delta = 7 days

query = "What's new with TimescaleDB functions?"
```

æ–¹æ³•1: æŒ‡å®šã•ã‚ŒãŸé–‹å§‹æ—¥ã¨çµ‚äº†æ—¥å†…ã§ãƒ•ã‚£ãƒ«ã‚¿ãƒªãƒ³ã‚°ã€‚

```python
# Method 1: Query for vectors between start_date and end_date
docs_with_score = db.similarity_search_with_score(
    query, start_date=start_dt, end_date=end_dt
)

for doc, score in docs_with_score:
    print("-" * 80)
    print("Score: ", score)
    print("Date: ", doc.metadata["date"])
    print(doc.page_content)
    print("-" * 80)
```

```output
--------------------------------------------------------------------------------
Score:  0.17488396167755127
Date:  2023-08-29 18:13:24+0320
{"commit": " e4facda540286b0affba47ccc63959fefe2a7b26", "author": "Sven Klemm<sven@timescale.com>", "date": "Tue Aug 29 18:13:24 2023 +0200", "change summary": "Add compatibility layer for _timescaledb_internal functions", "change details": "With timescaledb 2.12 all the functions present in _timescaledb_internal were moved into the _timescaledb_functions schema to improve schema security. This patch adds a compatibility layer so external callers of these internal functions will not break and allow for more flexibility when migrating. "}
--------------------------------------------------------------------------------
--------------------------------------------------------------------------------
Score:  0.18102192878723145
Date:  2023-08-20 22:47:10+0320
{"commit": " 0a66bdb8d36a1879246bd652e4c28500c4b951ab", "author": "Sven Klemm<sven@timescale.com>", "date": "Sun Aug 20 22:47:10 2023 +0200", "change summary": "Move functions to _timescaledb_functions schema", "change details": "To increase schema security we do not want to mix our own internal objects with user objects. Since chunks are created in the _timescaledb_internal schema our internal functions should live in a different dedicated schema. This patch make the necessary adjustments for the following functions:  - to_unix_microseconds(timestamptz) - to_timestamp(bigint) - to_timestamp_without_timezone(bigint) - to_date(bigint) - to_interval(bigint) - interval_to_usec(interval) - time_to_internal(anyelement) - subtract_integer_from_now(regclass, bigint) "}
--------------------------------------------------------------------------------
--------------------------------------------------------------------------------
Score:  0.18150119891755445
Date:  2023-08-22 12:01:19+0320
{"commit": " cf04496e4b4237440274eb25e4e02472fc4e06fc", "author": "Sven Klemm<sven@timescale.com>", "date": "Tue Aug 22 12:01:19 2023 +0200", "change summary": "Move utility functions to _timescaledb_functions schema", "change details": "To increase schema security we do not want to mix our own internal objects with user objects. Since chunks are created in the _timescaledb_internal schema our internal functions should live in a different dedicated schema. This patch make the necessary adjustments for the following functions:  - generate_uuid() - get_git_commit() - get_os_info() - tsl_loaded() "}
--------------------------------------------------------------------------------
--------------------------------------------------------------------------------
Score:  0.18422493887617963
Date:  2023-08-9 15:26:03+0500
{"commit": " 44eab9cf9bef34274c88efd37a750eaa74cd8044", "author": "Konstantina Skovola<konstantina@timescale.com>", "date": "Wed Aug 9 15:26:03 2023 +0300", "change summary": "Release 2.11.2", "change details": "This release contains bug fixes since the 2.11.1 release. We recommend that you upgrade at the next available opportunity.  **Features** * #5923 Feature flags for TimescaleDB features  **Bugfixes** * #5680 Fix DISTINCT query with JOIN on multiple segmentby columns * #5774 Fixed two bugs in decompression sorted merge code * #5786 Ensure pg_config --cppflags are passed * #5906 Fix quoting owners in sql scripts. * #5912 Fix crash in 1-step integer policy creation  **Thanks** * @mrksngl for submitting a PR to fix extension upgrade scripts * @ericdevries for reporting an issue with DISTINCT queries using segmentby columns of compressed hypertable "}
--------------------------------------------------------------------------------
```

ã‚¯ã‚¨ãƒªãŒæŒ‡å®šã•ã‚ŒãŸæ—¥ä»˜ç¯„å›²å†…ã®çµæœã®ã¿ã‚’è¿”ã™ã“ã¨ã«æ³¨ç›®ã—ã¦ãã ã•ã„ã€‚

æ–¹æ³•2: æŒ‡å®šã•ã‚ŒãŸé–‹å§‹æ—¥ã¨ã€ãã®å¾Œã®æ™‚é–“ãƒ‡ãƒ«ã‚¿å†…ã§ãƒ•ã‚£ãƒ«ã‚¿ãƒªãƒ³ã‚°ã€‚

```python
# Method 2: Query for vectors between start_dt and a time delta td later
# Most relevant vectors between 1 August and 7 days later
docs_with_score = db.similarity_search_with_score(
    query, start_date=start_dt, time_delta=td
)

for doc, score in docs_with_score:
    print("-" * 80)
    print("Score: ", score)
    print("Date: ", doc.metadata["date"])
    print(doc.page_content)
    print("-" * 80)
```

```output
--------------------------------------------------------------------------------
Score:  0.18458807468414307
Date:  2023-08-3 14:30:23+0500
{"commit": " 7aeed663b9c0f337b530fd6cad47704a51a9b2ec", "author": "Dmitry Simonenko<dmitry@timescale.com>", "date": "Thu Aug 3 14:30:23 2023 +0300", "change summary": "Feature flags for TimescaleDB features", "change details": "This PR adds several GUCs which allow to enable/disable major timescaledb features:  - enable_hypertable_create - enable_hypertable_compression - enable_cagg_create - enable_policy_create "}
--------------------------------------------------------------------------------
--------------------------------------------------------------------------------
Score:  0.20492422580718994
Date:  2023-08-7 18:31:40+0320
{"commit": " 07762ea4cedefc88497f0d1f8712d1515cdc5b6e", "author": "Sven Klemm<sven@timescale.com>", "date": "Mon Aug 7 18:31:40 2023 +0200", "change summary": "Test timescaledb debian 12 packages in CI", "change details": ""}
--------------------------------------------------------------------------------
--------------------------------------------------------------------------------
Score:  0.21106326580047607
Date:  2023-08-3 14:36:39+0500
{"commit": " 2863daf3df83c63ee36c0cf7b66c522da5b4e127", "author": "Dmitry Simonenko<dmitry@timescale.com>", "date": "Thu Aug 3 14:36:39 2023 +0300", "change summary": "Support CREATE INDEX ONLY ON main table", "change details": "This PR adds support for CREATE INDEX ONLY ON clause which allows to create index only on the main table excluding chunks.  Fix #5908 "}
--------------------------------------------------------------------------------
--------------------------------------------------------------------------------
Score:  0.21698051691055298
Date:  2023-08-2 20:24:14+0140
{"commit": " 3af0d282ea71d9a8f27159a6171e9516e62ec9cb", "author": "Lakshmi Narayanan Sreethar<lakshmi@timescale.com>", "date": "Wed Aug 2 20:24:14 2023 +0100", "change summary": "PG16: ExecInsertIndexTuples requires additional parameter", "change details": "PG16 adds a new boolean parameter to the ExecInsertIndexTuples function to denote if the index is a BRIN index, which is then used to determine if the index update can be skipped. The fix also removes the INDEX_ATTR_BITMAP_ALL enum value.  Adapt these changes by updating the compat function to accomodate the new parameter added to the ExecInsertIndexTuples function and using an alternative for the removed INDEX_ATTR_BITMAP_ALL enum value.  postgres/postgres@19d8e23 "}
--------------------------------------------------------------------------------
```

å†ã³ã€æŒ‡å®šã•ã‚ŒãŸæ™‚é–“ãƒ•ã‚£ãƒ«ã‚¿å†…ã§çµæœãŒå¾—ã‚‰ã‚Œã‚‹ã“ã¨ã«æ³¨ç›®ã—ã¦ãã ã•ã„ã€‚ã“ã‚Œã¯å‰ã®ã‚¯ã‚¨ãƒªã¨ã¯ç•°ãªã‚Šã¾ã™ã€‚

æ–¹æ³•3: æŒ‡å®šã•ã‚ŒãŸçµ‚äº†æ—¥ã¨ã€ãã®å‰ã®æ™‚é–“ãƒ‡ãƒ«ã‚¿å†…ã§ãƒ•ã‚£ãƒ«ã‚¿ãƒªãƒ³ã‚°ã€‚

```python
# Method 3: Query for vectors between end_dt and a time delta td earlier
# Most relevant vectors between 30 August and 7 days earlier
docs_with_score = db.similarity_search_with_score(query, end_date=end_dt, time_delta=td)

for doc, score in docs_with_score:
    print("-" * 80)
    print("Score: ", score)
    print("Date: ", doc.metadata["date"])
    print(doc.page_content)
    print("-" * 80)
```

```output
--------------------------------------------------------------------------------
Score:  0.17488396167755127
Date:  2023-08-29 18:13:24+0320
{"commit": " e4facda540286b0affba47ccc63959fefe2a7b26", "author": "Sven Klemm<sven@timescale.com>", "date": "Tue Aug 29 18:13:24 2023 +0200", "change summary": "Add compatibility layer for _timescaledb_internal functions", "change details": "With timescaledb 2.12 all the functions present in _timescaledb_internal were moved into the _timescaledb_functions schema to improve schema security. This patch adds a compatibility layer so external callers of these internal functions will not break and allow for more flexibility when migrating. "}
--------------------------------------------------------------------------------
--------------------------------------------------------------------------------
Score:  0.18496227264404297
Date:  2023-08-29 10:49:47+0320
{"commit": " a9751ccd5eb030026d7b975d22753f5964972389", "author": "Sven Klemm<sven@timescale.com>", "date": "Tue Aug 29 10:49:47 2023 +0200", "change summary": "Move partitioning functions to _timescaledb_functions schema", "change details": "To increase schema security we do not want to mix our own internal objects with user objects. Since chunks are created in the _timescaledb_internal schema our internal functions should live in a different dedicated schema. This patch make the necessary adjustments for the following functions:  - get_partition_for_key(val anyelement) - get_partition_hash(val anyelement) "}
--------------------------------------------------------------------------------
--------------------------------------------------------------------------------
Score:  0.1871250867843628
Date:  2023-08-28 23:26:23+0320
{"commit": " b2a91494a11d8b82849b6f11f9ea6dc26ef8a8cb", "author": "Sven Klemm<sven@timescale.com>", "date": "Mon Aug 28 23:26:23 2023 +0200", "change summary": "Move ddl_internal functions to _timescaledb_functions schema", "change details": "To increase schema security we do not want to mix our own internal objects with user objects. Since chunks are created in the _timescaledb_internal schema our internal functions should live in a different dedicated schema. This patch make the necessary adjustments for the following functions:  - chunk_constraint_add_table_constraint(_timescaledb_catalog.chunk_constraint) - chunk_drop_replica(regclass,name) - chunk_index_clone(oid) - chunk_index_replace(oid,oid) - create_chunk_replica_table(regclass,name) - drop_stale_chunks(name,integer[]) - health() - hypertable_constraint_add_table_fk_constraint(name,name,name,integer) - process_ddl_event() - wait_subscription_sync(name,name,integer,numeric) "}
--------------------------------------------------------------------------------
--------------------------------------------------------------------------------
Score:  0.18867712088363497
Date:  2023-08-27 13:20:04+0320
{"commit": " e02b1f348eb4c48def00b7d5227238b4d9d41a4a", "author": "Sven Klemm<sven@timescale.com>", "date": "Sun Aug 27 13:20:04 2023 +0200", "change summary": "Simplify schema move update script", "change details": "Use dynamic sql to create the ALTER FUNCTION statements for those functions that may not exist in previous versions. "}
--------------------------------------------------------------------------------
```

æ–¹æ³•4: ã‚¯ã‚¨ãƒªã§é–‹å§‹æ—¥ã®ã¿ã‚’æŒ‡å®šã™ã‚‹ã“ã¨ã§ã€æŒ‡å®šã•ã‚ŒãŸæ—¥ä»˜ä»¥é™ã®ã™ã¹ã¦ã®ãƒ™ã‚¯ãƒˆãƒ«ã‚’ãƒ•ã‚£ãƒ«ã‚¿ãƒªãƒ³ã‚°ã™ã‚‹ã“ã¨ã‚‚ã§ãã¾ã™ã€‚

æ–¹æ³•5: åŒæ§˜ã«ã€ã‚¯ã‚¨ãƒªã§çµ‚äº†æ—¥ã®ã¿ã‚’æŒ‡å®šã™ã‚‹ã“ã¨ã§ã€æŒ‡å®šã•ã‚ŒãŸæ—¥ä»˜å‰ã®ã™ã¹ã¦ã®ãƒ™ã‚¯ãƒˆãƒ«ã‚’ãƒ•ã‚£ãƒ«ã‚¿ãƒªãƒ³ã‚°ã§ãã¾ã™ã€‚

```python
# Method 4: Query all vectors after start_date
docs_with_score = db.similarity_search_with_score(query, start_date=start_dt)

for doc, score in docs_with_score:
    print("-" * 80)
    print("Score: ", score)
    print("Date: ", doc.metadata["date"])
    print(doc.page_content)
    print("-" * 80)
```

```output
--------------------------------------------------------------------------------
Score:  0.17488396167755127
Date:  2023-08-29 18:13:24+0320
{"commit": " e4facda540286b0affba47ccc63959fefe2a7b26", "author": "Sven Klemm<sven@timescale.com>", "date": "Tue Aug 29 18:13:24 2023 +0200", "change summary": "Add compatibility layer for _timescaledb_internal functions", "change details": "With timescaledb 2.12 all the functions present in _timescaledb_internal were moved into the _timescaledb_functions schema to improve schema security. This patch adds a compatibility layer so external callers of these internal functions will not break and allow for more flexibility when migrating. "}
--------------------------------------------------------------------------------
--------------------------------------------------------------------------------
Score:  0.18102192878723145
Date:  2023-08-20 22:47:10+0320
{"commit": " 0a66bdb8d36a1879246bd652e4c28500c4b951ab", "author": "Sven Klemm<sven@timescale.com>", "date": "Sun Aug 20 22:47:10 2023 +0200", "change summary": "Move functions to _timescaledb_functions schema", "change details": "To increase schema security we do not want to mix our own internal objects with user objects. Since chunks are created in the _timescaledb_internal schema our internal functions should live in a different dedicated schema. This patch make the necessary adjustments for the following functions:  - to_unix_microseconds(timestamptz) - to_timestamp(bigint) - to_timestamp_without_timezone(bigint) - to_date(bigint) - to_interval(bigint) - interval_to_usec(interval) - time_to_internal(anyelement) - subtract_integer_from_now(regclass, bigint) "}
--------------------------------------------------------------------------------
--------------------------------------------------------------------------------
Score:  0.18150119891755445
Date:  2023-08-22 12:01:19+0320
{"commit": " cf04496e4b4237440274eb25e4e02472fc4e06fc", "author": "Sven Klemm<sven@timescale.com>", "date": "Tue Aug 22 12:01:19 2023 +0200", "change summary": "Move utility functions to _timescaledb_functions schema", "change details": "To increase schema security we do not want to mix our own internal objects with user objects. Since chunks are created in the _timescaledb_internal schema our internal functions should live in a different dedicated schema. This patch make the necessary adjustments for the following functions:  - generate_uuid() - get_git_commit() - get_os_info() - tsl_loaded() "}
--------------------------------------------------------------------------------
--------------------------------------------------------------------------------
Score:  0.18422493887617963
Date:  2023-08-9 15:26:03+0500
{"commit": " 44eab9cf9bef34274c88efd37a750eaa74cd8044", "author": "Konstantina Skovola<konstantina@timescale.com>", "date": "Wed Aug 9 15:26:03 2023 +0300", "change summary": "Release 2.11.2", "change details": "This release contains bug fixes since the 2.11.1 release. We recommend that you upgrade at the next available opportunity.  **Features** * #5923 Feature flags for TimescaleDB features  **Bugfixes** * #5680 Fix DISTINCT query with JOIN on multiple segmentby columns * #5774 Fixed two bugs in decompression sorted merge code * #5786 Ensure pg_config --cppflags are passed * #5906 Fix quoting owners in sql scripts. * #5912 Fix crash in 1-step integer policy creation  **Thanks** * @mrksngl for submitting a PR to fix extension upgrade scripts * @ericdevries for reporting an issue with DISTINCT queries using segmentby columns of compressed hypertable "}
--------------------------------------------------------------------------------
```

```python
# Method 5: Query all vectors before end_date
docs_with_score = db.similarity_search_with_score(query, end_date=end_dt)

for doc, score in docs_with_score:
    print("-" * 80)
    print("Score: ", score)
    print("Date: ", doc.metadata["date"])
    print(doc.page_content)
    print("-" * 80)
```

```output
--------------------------------------------------------------------------------
Score:  0.16723191738128662
Date:  2023-04-11 22:01:14+0320
{"commit": " 0595ff0888f2ffb8d313acb0bda9642578a9ade3", "author": "Sven Klemm<sven@timescale.com>", "date": "Tue Apr 11 22:01:14 2023 +0200", "change summary": "Move type support functions into _timescaledb_functions schema", "change details": ""}
--------------------------------------------------------------------------------
--------------------------------------------------------------------------------
Score:  0.1706540584564209
Date:  2023-04-6 13:00:00+0320
{"commit": " 04f43335dea11e9c467ee558ad8edfc00c1a45ed", "author": "Sven Klemm<sven@timescale.com>", "date": "Thu Apr 6 13:00:00 2023 +0200", "change summary": "Move aggregate support function into _timescaledb_functions", "change details": "This patch moves the support functions for histogram, first and last into the _timescaledb_functions schema. Since we alter the schema of the existing functions in upgrade scripts and do not change the aggregates this should work completely transparently for any user objects using those aggregates. "}
--------------------------------------------------------------------------------
--------------------------------------------------------------------------------
Score:  0.17462033033370972
Date:  2023-03-31 08:22:57+0320
{"commit": " feef9206facc5c5f506661de4a81d96ef059b095", "author": "Sven Klemm<sven@timescale.com>", "date": "Fri Mar 31 08:22:57 2023 +0200", "change summary": "Add _timescaledb_functions schema", "change details": "Currently internal user objects like chunks and our functions live in the same schema making locking down that schema hard. This patch adds a new schema _timescaledb_functions that is meant to be the schema used for timescaledb internal functions to allow separation of code and chunks or other user objects. "}
--------------------------------------------------------------------------------
--------------------------------------------------------------------------------
Score:  0.17488396167755127
Date:  2023-08-29 18:13:24+0320
{"commit": " e4facda540286b0affba47ccc63959fefe2a7b26", "author": "Sven Klemm<sven@timescale.com>", "date": "Tue Aug 29 18:13:24 2023 +0200", "change summary": "Add compatibility layer for _timescaledb_internal functions", "change details": "With timescaledb 2.12 all the functions present in _timescaledb_internal were moved into the _timescaledb_functions schema to improve schema security. This patch adds a compatibility layer so external callers of these internal functions will not break and allow for more flexibility when migrating. "}
--------------------------------------------------------------------------------
```

ä¸»ãªãƒã‚¤ãƒ³ãƒˆã¯ã€ä¸Šè¨˜ã®å„çµæœã§ã€æŒ‡å®šã•ã‚ŒãŸæ™‚é–“ç¯„å›²å†…ã®ãƒ™ã‚¯ãƒˆãƒ«ã®ã¿ãŒè¿”ã•ã‚Œã‚‹ã“ã¨ã§ã™ã€‚ã“ã‚Œã‚‰ã®ã‚¯ã‚¨ãƒªã¯ã€é–¢é€£ã™ã‚‹ãƒ‘ãƒ¼ãƒ†ã‚£ã‚·ãƒ§ãƒ³ã®ã¿ã‚’æ¤œç´¢ã™ã‚‹å¿…è¦ãŒã‚ã‚‹ãŸã‚ã€éå¸¸ã«åŠ¹ç‡çš„ã§ã™ã€‚

ã“ã®æ©Ÿèƒ½ã‚’è³ªå•å¿œç­”ã«ä½¿ç”¨ã™ã‚‹ã“ã¨ã‚‚ã§ãã¾ã™ã€‚æŒ‡å®šã•ã‚ŒãŸæ™‚é–“ç¯„å›²å†…ã§æœ€ã‚‚é–¢é€£æ€§ã®é«˜ã„ãƒ™ã‚¯ãƒˆãƒ«ã‚’è¦‹ã¤ã‘ã¦ã€è³ªå•ã«ç­”ãˆã‚‹ãŸã‚ã®ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆã¨ã—ã¦ä½¿ç”¨ã—ã¾ã™ã€‚ä»¥ä¸‹ã®ä¾‹ã§ã¯ã€Timescale Vectorã‚’ãƒªãƒˆãƒªãƒ¼ãƒãƒ¼ã¨ã—ã¦ä½¿ç”¨ã—ã¾ã™ï¼š

```python
# Set timescale vector as a retriever and specify start and end dates via kwargs
retriever = db.as_retriever(search_kwargs={"start_date": start_dt, "end_date": end_dt})
```

```python
from langchain_openai import ChatOpenAI

llm = ChatOpenAI(temperature=0.1, model="gpt-3.5-turbo-16k")

from langchain.chains import RetrievalQA

qa_stuff = RetrievalQA.from_chain_type(
    llm=llm,
    chain_type="stuff",
    retriever=retriever,
    verbose=True,
)

query = (
    "What's new with the timescaledb functions? Tell me when these changes were made."
)
response = qa_stuff.run(query)
print(response)
```

```output


[1m> Entering new RetrievalQA chain...[0m

[1m> Finished chain.[0m
The following changes were made to the timescaledb functions:

1. "Add compatibility layer for _timescaledb_internal functions" - This change was made on Tue Aug 29 18:13:24 2023 +0200.
2. "Move functions to _timescaledb_functions schema" - This change was made on Sun Aug 20 22:47:10 2023 +0200.
3. "Move utility functions to _timescaledb_functions schema" - This change was made on Tue Aug 22 12:01:19 2023 +0200.
4. "Move partitioning functions to _timescaledb_functions schema" - This change was made on Tue Aug 29 10:49:47 2023 +0200.
```

LLMãŒå›ç­”ã‚’æ§‹æˆã™ã‚‹ãŸã‚ã«ä½¿ç”¨ã™ã‚‹ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆã¯ã€æŒ‡å®šã•ã‚ŒãŸæ—¥ä»˜ç¯„å›²å†…ã®å–å¾—ã•ã‚ŒãŸãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆã®ã¿ã‹ã‚‰ã§ã‚ã‚‹ã“ã¨ã«æ³¨æ„ã—ã¦ãã ã•ã„ã€‚

ã“ã‚Œã«ã‚ˆã‚Šã€Timescale Vectorã‚’ä½¿ç”¨ã—ã¦ã€ã‚¯ã‚¨ãƒªã«é–¢é€£ã™ã‚‹æ™‚é–“ç¯„å›²å†…ã®ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆã‚’å–å¾—ã™ã‚‹ã“ã¨ã§ã€å–å¾—æ‹¡å¼µç”Ÿæˆã‚’å¼·åŒ–ã™ã‚‹æ–¹æ³•ãŒç¤ºã•ã‚Œã¾ã™ã€‚

## 3. ã‚¯ã‚¨ãƒªã‚’é«˜é€ŸåŒ–ã™ã‚‹ãŸã‚ã®ANN Search Indexesã®ä½¿ç”¨

ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ã‚’åŸ‹ã‚è¾¼ã¿åˆ—ã«ä½œæˆã™ã‚‹ã“ã¨ã§ã€é¡ä¼¼æ€§ã‚¯ã‚¨ãƒªã‚’é«˜é€ŸåŒ–ã§ãã¾ã™ã€‚ã“ã‚Œã¯ã€ãƒ‡ãƒ¼ã‚¿ã®å¤§éƒ¨åˆ†ã‚’å–ã‚Šè¾¼ã‚“ã å¾Œã«ã®ã¿è¡Œã†ã¹ãã§ã™ã€‚

Timescale Vectorã¯ä»¥ä¸‹ã®ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ã‚’ã‚µãƒãƒ¼ãƒˆã—ã¦ã„ã¾ã™ï¼š
- timescale_vectorã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ï¼ˆtsvï¼‰ï¼šé«˜é€Ÿé¡ä¼¼æ€§æ¤œç´¢ã®ãŸã‚ã®ãƒ‡ã‚£ã‚¹ã‚¯ãƒ™ãƒ¼ã‚¹ã®ANNã‚¤ãƒ³ã‚¹ãƒ‘ã‚¤ã‚¢ã•ã‚ŒãŸã‚°ãƒ©ãƒ•ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ï¼ˆãƒ‡ãƒ•ã‚©ãƒ«ãƒˆï¼‰ã€‚
- pgvectorã®HNSWã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ï¼šé«˜é€Ÿé¡ä¼¼æ€§æ¤œç´¢ã®ãŸã‚ã®éšå±¤çš„ãƒŠãƒ“ã‚²ãƒ¼ã‚·ãƒ§ãƒ³å¯èƒ½ãªã‚¹ãƒ¢ãƒ¼ãƒ«ãƒ¯ãƒ¼ãƒ«ãƒ‰ã‚°ãƒ©ãƒ•ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ã€‚
- pgvectorã®IVFFLATã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ï¼šé«˜é€Ÿé¡ä¼¼æ€§æ¤œç´¢ã®ãŸã‚ã®å€’ç«‹ãƒ•ã‚¡ã‚¤ãƒ«ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ã€‚

é‡è¦ãªæ³¨æ„ç‚¹ï¼šPostgreSQLã§ã¯ã€å„ãƒ†ãƒ¼ãƒ–ãƒ«ã¯ç‰¹å®šã®åˆ—ã«å¯¾ã—ã¦1ã¤ã®ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ã—ã‹æŒã¦ã¾ã›ã‚“ã€‚ã—ãŸãŒã£ã¦ã€ç•°ãªã‚‹ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ã‚¿ã‚¤ãƒ—ã®ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ã‚’ãƒ†ã‚¹ãƒˆã—ãŸã„å ´åˆã¯ã€ï¼ˆ1ï¼‰ç•°ãªã‚‹ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ã‚’æŒã¤è¤‡æ•°ã®ãƒ†ãƒ¼ãƒ–ãƒ«ã‚’ä½œæˆã™ã‚‹ã€ï¼ˆ2ï¼‰åŒã˜ãƒ†ãƒ¼ãƒ–ãƒ«ã«è¤‡æ•°ã®ãƒ™ã‚¯ãƒˆãƒ«åˆ—ã‚’ä½œæˆã—ã€å„åˆ—ã«ç•°ãªã‚‹ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ã‚’ä½œæˆã™ã‚‹ã€ã¾ãŸã¯ï¼ˆ3ï¼‰åŒã˜åˆ—ã®ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ã‚’å‰Šé™¤ã—ã¦å†ä½œæˆã—ã€çµæœã‚’æ¯”è¼ƒã™ã‚‹ã“ã¨ãŒã§ãã¾ã™ã€‚

```python
# Initialize an existing TimescaleVector store
COLLECTION_NAME = "timescale_commits"
embeddings = OpenAIEmbeddings()
db = TimescaleVector(
    collection_name=COLLECTION_NAME,
    service_url=SERVICE_URL,
    embedding_function=embeddings,
)
```

è¿½åŠ ã®å¼•æ•°ãªã—ã§`create_index()`é–¢æ•°ã‚’ä½¿ç”¨ã™ã‚‹ã¨ã€ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆã§timescale_vector_indexãŒãƒ‡ãƒ•ã‚©ãƒ«ãƒˆã®ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã‚’ä½¿ç”¨ã—ã¦ä½œæˆã•ã‚Œã¾ã™ã€‚

```python
# create an index
# by default this will create a Timescale Vector (DiskANN) index
db.create_index()
```

ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ã®ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã‚’æŒ‡å®šã™ã‚‹ã“ã¨ã‚‚ã§ãã¾ã™ã€‚ç•°ãªã‚‹ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã¨ãã®ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ã¸ã®å½±éŸ¿ã«ã¤ã„ã¦ã®è©³ç´°ã¯ã€Timescale Vectorã®ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆã‚’å‚ç…§ã—ã¦ãã ã•ã„ã€‚

æ³¨ï¼šãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã‚’æŒ‡å®šã™ã‚‹å¿…è¦ã¯ã‚ã‚Šã¾ã›ã‚“ã€‚ã‚¹ãƒãƒ¼ãƒˆãªãƒ‡ãƒ•ã‚©ãƒ«ãƒˆã‚’è¨­å®šã—ã¦ã„ã¾ã™ãŒã€ç‰¹å®šã®ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã®ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ã‚’å‘ä¸Šã•ã›ã‚‹ãŸã‚ã«å®Ÿé¨“ã‚’è¡Œã„ãŸã„å ´åˆã¯ã€å¸¸ã«ç‹¬è‡ªã®ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã‚’æŒ‡å®šã§ãã¾ã™ã€‚

```python
# drop the old index
db.drop_index()

# create an index
# Note: You don't need to specify m and ef_construction parameters as we set smart defaults.
db.create_index(index_type="tsv", max_alpha=1.0, num_neighbors=50)
```

Timescale Vectorã¯ã€HNSW ANNã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ã‚¢ãƒ«ã‚´ãƒªã‚ºãƒ ã¨ã€ivfflat ANNã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ã‚¢ãƒ«ã‚´ãƒªã‚ºãƒ ã‚‚ã‚µãƒãƒ¼ãƒˆã—ã¦ã„ã¾ã™ã€‚`index_type`å¼•æ•°ã§ä½œæˆã—ãŸã„ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ã‚’æŒ‡å®šã—ã€ã‚ªãƒ—ã‚·ãƒ§ãƒ³ã§ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ã®ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã‚’æŒ‡å®šã™ã‚‹ã ã‘ã§ã™ã€‚

```python
# drop the old index
db.drop_index()

# Create an HNSW index
# Note: You don't need to specify m and ef_construction parameters as we set smart defaults.
db.create_index(index_type="hnsw", m=16, ef_construction=64)
```

```python
# drop the old index
db.drop_index()

# Create an IVFFLAT index
# Note: You don't need to specify num_lists and num_records parameters as we set smart defaults.
db.create_index(index_type="ivfflat", num_lists=20, num_records=1000)
```

ä¸€èˆ¬çš„ã«ã¯ã€ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆã®timescale vectorã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ã€ã¾ãŸã¯HNSWã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ã‚’ä½¿ç”¨ã™ã‚‹ã“ã¨ã‚’ãŠå‹§ã‚ã—ã¾ã™ã€‚

```python
# drop the old index
db.drop_index()
# Create a new timescale vector index
db.create_index()
```

## 4. Timescale Vectorã«ã‚ˆã‚‹Self Querying Retriever

Timescale Vectorã¯ã€è‡ªå·±ã‚¯ã‚¨ãƒªãƒªãƒˆãƒªãƒ¼ãƒãƒ¼æ©Ÿèƒ½ã‚‚ã‚µãƒãƒ¼ãƒˆã—ã¦ãŠã‚Šã€è‡ªåˆ†è‡ªèº«ã‚’ã‚¯ã‚¨ãƒªã™ã‚‹æ©Ÿèƒ½ã‚’æä¾›ã—ã¾ã™ã€‚ã‚¯ã‚¨ãƒªã‚¹ãƒ†ãƒ¼ãƒˆãƒ¡ãƒ³ãƒˆã¨ãƒ•ã‚£ãƒ«ã‚¿ï¼ˆå˜ä¸€ã¾ãŸã¯è¤‡åˆï¼‰ã‚’å«ã‚€è‡ªç„¶è¨€èªã®ã‚¯ã‚¨ãƒªãŒä¸ãˆã‚‰ã‚Œã‚‹ã¨ã€ãƒªãƒˆãƒªãƒ¼ãƒãƒ¼ã¯SQLã‚¯ã‚¨ãƒªã‚’ä½œæˆã™ã‚‹LLMãƒã‚§ãƒ¼ãƒ³ã‚’ä½¿ç”¨ã—ã¦ã€Timescale Vectorã®ãƒ™ã‚¯ãƒˆãƒ«ã‚¹ãƒˆã‚¢å†…ã®PostgreSQLãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã«é©ç”¨ã—ã¾ã™ã€‚

è‡ªå·±ã‚¯ã‚¨ãƒªã«é–¢ã™ã‚‹è©³ç´°ã¯ã€[ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆ](/docs/modules/data_connection/retrievers/self_query/)ã‚’å‚ç…§ã—ã¦ãã ã•ã„ã€‚

Timescale Vectorã‚’ä½¿ç”¨ã—ãŸè‡ªå·±ã‚¯ã‚¨ãƒªã‚’èª¬æ˜ã™ã‚‹ãŸã‚ã«ã€ãƒ‘ãƒ¼ãƒˆ3ã®gitlogãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã‚’ä½¿ç”¨ã—ã¾ã™ã€‚

```python
COLLECTION_NAME = "timescale_commits"
vectorstore = TimescaleVector(
    embedding_function=OpenAIEmbeddings(),
    collection_name=COLLECTION_NAME,
    service_url=SERVICE_URL,
)
```

æ¬¡ã«ã€è‡ªå·±ã‚¯ã‚¨ãƒªãƒªãƒˆãƒªãƒ¼ãƒãƒ¼ã‚’ä½œæˆã—ã¾ã™ã€‚ã“ã‚Œã‚’è¡Œã†ã«ã¯ã€ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆãŒã‚µãƒãƒ¼ãƒˆã™ã‚‹ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿ãƒ•ã‚£ãƒ¼ãƒ«ãƒ‰ã¨ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆå†…å®¹ã®ç°¡å˜ãªèª¬æ˜ã«é–¢ã™ã‚‹æƒ…å ±ã‚’äº‹å‰ã«æä¾›ã™ã‚‹å¿…è¦ãŒã‚ã‚Šã¾ã™ã€‚

```python
from langchain.chains.query_constructor.base import AttributeInfo
from langchain.retrievers.self_query.base import SelfQueryRetriever
from langchain_openai import OpenAI

# Give LLM info about the metadata fields
metadata_field_info = [
    AttributeInfo(
        name="id",
        description="A UUID v1 generated from the date of the commit",
        type="uuid",
    ),
    AttributeInfo(
        name="date",
        description="The date of the commit in timestamptz format",
        type="timestamptz",
    ),
    AttributeInfo(
        name="author_name",
        description="The name of the author of the commit",
        type="string",
    ),
    AttributeInfo(
        name="author_email",
        description="The email address of the author of the commit",
        type="string",
    ),
]
document_content_description = "The git log commit summary containing the commit hash, author, date of commit, change summary and change details"

# Instantiate the self-query retriever from an LLM
llm = OpenAI(temperature=0)
retriever = SelfQueryRetriever.from_llm(
    llm,
    vectorstore,
    document_content_description,
    metadata_field_info,
    enable_limit=True,
    verbose=True,
)
```

æ¬¡ã«ã€gitlogãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã§è‡ªå·±ã‚¯ã‚¨ãƒªãƒªãƒˆãƒªãƒ¼ãƒãƒ¼ã‚’ãƒ†ã‚¹ãƒˆã—ã¦ã¿ã¾ã—ã‚‡ã†ã€‚

ä»¥ä¸‹ã®ã‚¯ã‚¨ãƒªã‚’å®Ÿè¡Œã—ã€ã‚¯ã‚¨ãƒªã€ãƒ•ã‚£ãƒ«ã‚¿ä»˜ãã‚¯ã‚¨ãƒªã€è¤‡åˆãƒ•ã‚£ãƒ«ã‚¿ä»˜ãã‚¯ã‚¨ãƒªï¼ˆANDã€ORã‚’å«ã‚€ãƒ•ã‚£ãƒ«ã‚¿ï¼‰ã‚’è‡ªç„¶è¨€èªã§æŒ‡å®šã§ãã‚‹ã“ã¨ã«æ³¨ç›®ã—ã¦ãã ã•ã„ã€‚è‡ªå·±ã‚¯ã‚¨ãƒªãƒªãƒˆãƒªãƒ¼ãƒãƒ¼ã¯ã€ãã®ã‚¯ã‚¨ãƒªã‚’SQLã«å¤‰æ›ã—ã€Timescale Vector PostgreSQLãƒ™ã‚¯ãƒˆãƒ«ã‚¹ãƒˆã‚¢ã§æ¤œç´¢ã‚’å®Ÿè¡Œã—ã¾ã™ã€‚

ã“ã‚Œã«ã‚ˆã‚Šã€è‡ªå·±ã‚¯ã‚¨ãƒªãƒªãƒˆãƒªãƒ¼ãƒãƒ¼ã®åŠ›ãŒç¤ºã•ã‚Œã¾ã™ã€‚SQLã‚’ç›´æ¥æ›¸ãã“ã¨ãªãã€è¤‡é›‘ãªæ¤œç´¢ã‚’ãƒ™ã‚¯ãƒˆãƒ«ã‚¹ãƒˆã‚¢ã§å®Ÿè¡Œã§ãã¾ã™ï¼

```python
# This example specifies a relevant query
retriever.invoke("What are improvements made to continuous aggregates?")
```

```output
/Users/avtharsewrathan/sideprojects2023/timescaleai/tsv-langchain/langchain/libs/langchain/langchain/chains/llm.py:275: UserWarning: The predict_and_parse method is deprecated, instead pass an output parser directly to LLMChain.
  warnings.warn(

query='improvements to continuous aggregates' filter=None limit=None
```

```output
[Document(page_content='{"commit": " 35c91204987ccb0161d745af1a39b7eb91bc65a5", "author": "Fabr\\u00edzio de Royes Mello<fabriziomello@gmail.com>", "date": "Thu Nov 24 13:19:36 2022 -0300", "change summary": "Add Hierarchical Continuous Aggregates validations", "change details": "Commit 3749953e introduce Hierarchical Continuous Aggregates (aka Continuous Aggregate on top of another Continuous Aggregate) but it lacks of some basic validations.  Validations added during the creation of a Hierarchical Continuous Aggregate:  * Forbid create a continuous aggregate with fixed-width bucket on top of   a continuous aggregate with variable-width bucket.  * Forbid incompatible bucket widths:   - should not be equal;   - bucket width of the new continuous aggregate should be greater than     the source continuous aggregate;   - bucket width of the new continuous aggregate should be multiple of     the source continuous aggregate. "}', metadata={'id': 'c98d1c00-6c13-11ed-9bbe-23925ce74d13', 'date': '2022-11-24 13:19:36+-500', 'source': '/Users/avtharsewrathan/sideprojects2023/timescaleai/tsv-langchain/langchain/docs/docs/modules/ts_git_log.json', 'seq_num': 446, 'author_name': 'FabrÃ­zio de Royes Mello', 'commit_hash': ' 35c91204987ccb0161d745af1a39b7eb91bc65a5', 'author_email': 'fabriziomello@gmail.com'}),
 Document(page_content='{"commit": " 3749953e9704e45df8f621607989ada0714ce28d", "author": "Fabr\\u00edzio de Royes Mello<fabriziomello@gmail.com>", "date": "Wed Oct 5 18:45:40 2022 -0300", "change summary": "Hierarchical Continuous Aggregates", "change details": "Enable users create Hierarchical Continuous Aggregates (aka Continuous Aggregates on top of another Continuous Aggregates).  With this PR users can create levels of aggregation granularity in Continuous Aggregates making the refresh process even faster.  A problem with this feature can be in upper levels we can end up with the \\"average of averages\\". But to get the \\"real average\\" we can rely on \\"stats_aggs\\" TimescaleDB Toolkit function that calculate and store the partials that can be finalized with other toolkit functions like \\"average\\" and \\"sum\\".  Closes #1400 "}', metadata={'id': '0df31a00-44f7-11ed-9794-ebcc1227340f', 'date': '2022-10-5 18:45:40+-500', 'source': '/Users/avtharsewrathan/sideprojects2023/timescaleai/tsv-langchain/langchain/docs/docs/modules/ts_git_log.json', 'seq_num': 470, 'author_name': 'FabrÃ­zio de Royes Mello', 'commit_hash': ' 3749953e9704e45df8f621607989ada0714ce28d', 'author_email': 'fabriziomello@gmail.com'}),
 Document(page_content='{"commit": " a6ff7ba6cc15b280a275e5acd315741ec9c86acc", "author": "Mats Kindahl<mats@timescale.com>", "date": "Tue Feb 28 12:04:17 2023 +0100", "change summary": "Rename columns in old-style continuous aggregates", "change details": "For continuous aggregates with the old-style partial aggregates renaming columns that are not in the group-by clause will generate an error when upgrading to a later version. The reason is that it is implicitly assumed that the name of the column is the same as for the direct view. This holds true for new-style continous aggregates, but is not always true for old-style continuous aggregates. In particular, columns that are not part of the `GROUP BY` clause can have an internally generated name.  This commit fixes that by extracting the name of the column from the partial view and use that when renaming the partial view column and the materialized table column. "}', metadata={'id': 'a49ace80-b757-11ed-8138-2390fd44ffd9', 'date': '2023-02-28 12:04:17+0140', 'source': '/Users/avtharsewrathan/sideprojects2023/timescaleai/tsv-langchain/langchain/docs/docs/modules/ts_git_log.json', 'seq_num': 294, 'author_name': 'Mats Kindahl', 'commit_hash': ' a6ff7ba6cc15b280a275e5acd315741ec9c86acc', 'author_email': 'mats@timescale.com'}),
 Document(page_content='{"commit": " 5bba74a2ec083728f8e93e09d03d102568fd72b5", "author": "Fabr\\u00edzio de Royes Mello<fabriziomello@gmail.com>", "date": "Mon Aug 7 19:49:47 2023 -0300", "change summary": "Relax strong table lock when refreshing a CAGG", "change details": "When refreshing a Continuous Aggregate we take a table lock on _timescaledb_catalog.continuous_aggs_invalidation_threshold when processing the invalidation logs (the first transaction of the refresh Continuous Aggregate procedure). It means that even two different Continuous Aggregates over two different hypertables will wait each other in the first phase of the refreshing procedure. Also it lead to problems when a pg_dump is running because it take an AccessShareLock on tables so Continuous Aggregate refresh execution will wait until the pg_dump finish.  Improved it by relaxing the strong table-level lock to a row-level lock so now the Continuous Aggregate refresh procedure can be executed in multiple sessions with less locks.  Fix #3554 "}', metadata={'id': 'b5583780-3574-11ee-a5ba-2e305874a58f', 'date': '2023-08-7 19:49:47+-500', 'source': '/Users/avtharsewrathan/sideprojects2023/timescaleai/tsv-langchain/langchain/docs/docs/modules/ts_git_log.json', 'seq_num': 27, 'author_name': 'FabrÃ­zio de Royes Mello', 'commit_hash': ' 5bba74a2ec083728f8e93e09d03d102568fd72b5', 'author_email': 'fabriziomello@gmail.com'})]
```

```python
# This example specifies a filter
retriever.invoke("What commits did Sven Klemm add?")
```

```output
query=' ' filter=Comparison(comparator=<Comparator.EQ: 'eq'>, attribute='author_name', value='Sven Klemm') limit=None
```

```output
[Document(page_content='{"commit": " e2e7ae304521b74ac6b3f157a207da047d44ab06", "author": "Sven Klemm<sven@timescale.com>", "date": "Fri Mar 3 11:22:06 2023 +0100", "change summary": "Don\'t run sanitizer test on individual PRs", "change details": "Sanitizer tests take a long time to run so we don\'t want to run them on individual PRs but instead run them nightly and on commits to master. "}', metadata={'id': '3f401b00-b9ad-11ed-b5ea-a3fd40b9ac16', 'date': '2023-03-3 11:22:06+0140', 'source': '/Users/avtharsewrathan/sideprojects2023/timescaleai/tsv-langchain/langchain/docs/docs/modules/ts_git_log.json', 'seq_num': 295, 'author_name': 'Sven Klemm', 'commit_hash': ' e2e7ae304521b74ac6b3f157a207da047d44ab06', 'author_email': 'sven@timescale.com'}),
 Document(page_content='{"commit": " d8f19e57a04d17593df5f2c694eae8775faddbc7", "author": "Sven Klemm<sven@timescale.com>", "date": "Wed Feb 1 08:34:20 2023 +0100", "change summary": "Bump version of setup-wsl github action", "change details": "The currently used version pulls in Node.js 12 which is deprecated on github.  https://github.blog/changelog/2022-09-22-github-actions-all-actions-will-begin-running-on-node16-instead-of-node12/ "}', metadata={'id': 'd70de600-a202-11ed-85d6-30b6df240f49', 'date': '2023-02-1 08:34:20+0140', 'source': '/Users/avtharsewrathan/sideprojects2023/timescaleai/tsv-langchain/langchain/docs/docs/modules/ts_git_log.json', 'seq_num': 350, 'author_name': 'Sven Klemm', 'commit_hash': ' d8f19e57a04d17593df5f2c694eae8775faddbc7', 'author_email': 'sven@timescale.com'}),
 Document(page_content='{"commit": " 83b13cf6f73a74656dde9cc6ec6cf76740cddd3c", "author": "Sven Klemm<sven@timescale.com>", "date": "Fri Nov 25 08:27:45 2022 +0100", "change summary": "Use packaged postgres for sqlsmith and coverity CI", "change details": "The sqlsmith and coverity workflows used the cache postgres build but could not produce a build by themselves and therefore relied on other workflows to produce the cached binaries. This patch changes those workflows to use normal postgres packages instead of custom built postgres to remove that dependency. "}', metadata={'id': 'a786ae80-6c92-11ed-bd6c-a57bd3348b97', 'date': '2022-11-25 08:27:45+0140', 'source': '/Users/avtharsewrathan/sideprojects2023/timescaleai/tsv-langchain/langchain/docs/docs/modules/ts_git_log.json', 'seq_num': 447, 'author_name': 'Sven Klemm', 'commit_hash': ' 83b13cf6f73a74656dde9cc6ec6cf76740cddd3c', 'author_email': 'sven@timescale.com'}),
 Document(page_content='{"commit": " b1314e63f2ff6151ab5becfb105afa3682286a4d", "author": "Sven Klemm<sven@timescale.com>", "date": "Thu Dec 22 12:03:35 2022 +0100", "change summary": "Fix RPM package test for PG15 on centos 7", "change details": "Installing PG15 on Centos 7 requires the EPEL repository to satisfy the dependencies. "}', metadata={'id': '477b1d80-81e8-11ed-9c8c-9b5abbd67c98', 'date': '2022-12-22 12:03:35+0140', 'source': '/Users/avtharsewrathan/sideprojects2023/timescaleai/tsv-langchain/langchain/docs/docs/modules/ts_git_log.json', 'seq_num': 408, 'author_name': 'Sven Klemm', 'commit_hash': ' b1314e63f2ff6151ab5becfb105afa3682286a4d', 'author_email': 'sven@timescale.com'})]
```

```python
# This example specifies a query and filter
retriever.invoke("What commits about timescaledb_functions did Sven Klemm add?")
```

```output
query='timescaledb_functions' filter=Comparison(comparator=<Comparator.EQ: 'eq'>, attribute='author_name', value='Sven Klemm') limit=None
```

```output
[Document(page_content='{"commit": " 04f43335dea11e9c467ee558ad8edfc00c1a45ed", "author": "Sven Klemm<sven@timescale.com>", "date": "Thu Apr 6 13:00:00 2023 +0200", "change summary": "Move aggregate support function into _timescaledb_functions", "change details": "This patch moves the support functions for histogram, first and last into the _timescaledb_functions schema. Since we alter the schema of the existing functions in upgrade scripts and do not change the aggregates this should work completely transparently for any user objects using those aggregates. "}', metadata={'id': '2cb47800-d46a-11ed-8f0e-2b624245c561', 'date': '2023-04-6 13:00:00+0320', 'source': '/Users/avtharsewrathan/sideprojects2023/timescaleai/tsv-langchain/langchain/docs/docs/modules/ts_git_log.json', 'seq_num': 233, 'author_name': 'Sven Klemm', 'commit_hash': ' 04f43335dea11e9c467ee558ad8edfc00c1a45ed', 'author_email': 'sven@timescale.com'}),
 Document(page_content='{"commit": " feef9206facc5c5f506661de4a81d96ef059b095", "author": "Sven Klemm<sven@timescale.com>", "date": "Fri Mar 31 08:22:57 2023 +0200", "change summary": "Add _timescaledb_functions schema", "change details": "Currently internal user objects like chunks and our functions live in the same schema making locking down that schema hard. This patch adds a new schema _timescaledb_functions that is meant to be the schema used for timescaledb internal functions to allow separation of code and chunks or other user objects. "}', metadata={'id': '7a257680-cf8c-11ed-848c-a515e8687479', 'date': '2023-03-31 08:22:57+0320', 'source': '/Users/avtharsewrathan/sideprojects2023/timescaleai/tsv-langchain/langchain/docs/docs/modules/ts_git_log.json', 'seq_num': 239, 'author_name': 'Sven Klemm', 'commit_hash': ' feef9206facc5c5f506661de4a81d96ef059b095', 'author_email': 'sven@timescale.com'}),
 Document(page_content='{"commit": " 0a66bdb8d36a1879246bd652e4c28500c4b951ab", "author": "Sven Klemm<sven@timescale.com>", "date": "Sun Aug 20 22:47:10 2023 +0200", "change summary": "Move functions to _timescaledb_functions schema", "change details": "To increase schema security we do not want to mix our own internal objects with user objects. Since chunks are created in the _timescaledb_internal schema our internal functions should live in a different dedicated schema. This patch make the necessary adjustments for the following functions:  - to_unix_microseconds(timestamptz) - to_timestamp(bigint) - to_timestamp_without_timezone(bigint) - to_date(bigint) - to_interval(bigint) - interval_to_usec(interval) - time_to_internal(anyelement) - subtract_integer_from_now(regclass, bigint) "}', metadata={'id': 'bb99db00-3f9a-11ee-a8dc-0b9c1a5a37c4', 'date': '2023-08-20 22:47:10+0320', 'source': '/Users/avtharsewrathan/sideprojects2023/timescaleai/tsv-langchain/langchain/docs/docs/modules/ts_git_log.json', 'seq_num': 41, 'author_name': 'Sven Klemm', 'commit_hash': ' 0a66bdb8d36a1879246bd652e4c28500c4b951ab', 'author_email': 'sven@timescale.com'}),
 Document(page_content='{"commit": " 56ea8b4de93cefc38e002202d8ac96947dcbaa77", "author": "Sven Klemm<sven@timescale.com>", "date": "Thu Apr 13 13:16:14 2023 +0200", "change summary": "Move trigger functions to _timescaledb_functions schema", "change details": "To increase schema security we do not want to mix our own internal objects with user objects. Since chunks are created in the _timescaledb_internal schema our internal functions should live in a different dedicated schema. This patch make the necessary adjustments for our trigger functions. "}', metadata={'id': '9a255300-d9ec-11ed-988f-7086c8ca463a', 'date': '2023-04-13 13:16:14+0320', 'source': '/Users/avtharsewrathan/sideprojects2023/timescaleai/tsv-langchain/langchain/docs/docs/modules/ts_git_log.json', 'seq_num': 44, 'author_name': 'Sven Klemm', 'commit_hash': ' 56ea8b4de93cefc38e002202d8ac96947dcbaa77', 'author_email': 'sven@timescale.com'})]
```

```python
# This example specifies a time-based filter
retriever.invoke("What commits were added in July 2023?")
```

```output
query=' ' filter=Operation(operator=<Operator.AND: 'and'>, arguments=[Comparison(comparator=<Comparator.GTE: 'gte'>, attribute='date', value='2023-07-01T00:00:00Z'), Comparison(comparator=<Comparator.LTE: 'lte'>, attribute='date', value='2023-07-31T23:59:59Z')]) limit=None
```

```output
[Document(page_content='{"commit": " 5cf354e2469ee7e43248bed382a4b49fc7ccfecd", "author": "Markus Engel<engel@sero-systems.de>", "date": "Mon Jul 31 11:28:25 2023 +0200", "change summary": "Fix quoting owners in sql scripts.", "change details": "When referring to a role from a string type, it must be properly quoted using pg_catalog.quote_ident before it can be casted to regrole. Fixed this, especially in update scripts. "}', metadata={'id': '99590280-2f84-11ee-915b-5715b2447de4', 'date': '2023-07-31 11:28:25+0320', 'source': '/Users/avtharsewrathan/sideprojects2023/timescaleai/tsv-langchain/langchain/docs/docs/modules/ts_git_log.json', 'seq_num': 76, 'author_name': 'Markus Engel', 'commit_hash': ' 5cf354e2469ee7e43248bed382a4b49fc7ccfecd', 'author_email': 'engel@sero-systems.de'}),
 Document(page_content='{"commit": " 88aaf23ae37fe7f47252b87325eb570aa417c607", "author": "noctarius aka Christoph Engelbert<me@noctarius.com>", "date": "Wed Jul 12 14:53:40 2023 +0200", "change summary": "Allow Replica Identity (Alter Table) on CAGGs (#5868)", "change details": "This commit is a follow up of #5515, which added support for ALTER TABLE\\r ... REPLICA IDENTITY (FULL | INDEX) on hypertables.\\r \\r This commit allows the execution against materialized hypertables to\\r enable update / delete operations on continuous aggregates when logical\\r replication in enabled for them."}', metadata={'id': '1fcfa200-20b3-11ee-9a18-370561c7cb1a', 'date': '2023-07-12 14:53:40+0320', 'source': '/Users/avtharsewrathan/sideprojects2023/timescaleai/tsv-langchain/langchain/docs/docs/modules/ts_git_log.json', 'seq_num': 96, 'author_name': 'noctarius aka Christoph Engelbert', 'commit_hash': ' 88aaf23ae37fe7f47252b87325eb570aa417c607', 'author_email': 'me@noctarius.com'}),
 Document(page_content='{"commit": " d5268c36fbd23fa2a93c0371998286e8688247bb", "author": "Alexander Kuzmenkov<36882414+akuzm@users.noreply.github.com>", "date": "Fri Jul 28 13:35:05 2023 +0200", "change summary": "Fix SQLSmith workflow", "change details": "The build was failing because it was picking up the wrong version of Postgres. Remove it. "}', metadata={'id': 'cc0fba80-2d3a-11ee-ae7d-36dc25cad3b8', 'date': '2023-07-28 13:35:05+0320', 'source': '/Users/avtharsewrathan/sideprojects2023/timescaleai/tsv-langchain/langchain/docs/docs/modules/ts_git_log.json', 'seq_num': 82, 'author_name': 'Alexander Kuzmenkov', 'commit_hash': ' d5268c36fbd23fa2a93c0371998286e8688247bb', 'author_email': '36882414+akuzm@users.noreply.github.com'}),
 Document(page_content='{"commit": " 61c288ec5eb966a9b4d8ed90cd026ffc5e3543c9", "author": "Lakshmi Narayanan Sreethar<lakshmi@timescale.com>", "date": "Tue Jul 25 16:11:35 2023 +0530", "change summary": "Fix broken CI after PG12 removal", "change details": "The commit cdea343cc updated the gh_matrix_builder.py script but failed to import PG_LATEST variable into the script thus breaking the CI. Import that variable to fix the CI tests. "}', metadata={'id': 'd3835980-2ad7-11ee-b98d-c4e3092e076e', 'date': '2023-07-25 16:11:35+0850', 'source': '/Users/avtharsewrathan/sideprojects2023/timescaleai/tsv-langchain/langchain/docs/docs/modules/ts_git_log.json', 'seq_num': 84, 'author_name': 'Lakshmi Narayanan Sreethar', 'commit_hash': ' 61c288ec5eb966a9b4d8ed90cd026ffc5e3543c9', 'author_email': 'lakshmi@timescale.com'})]
```

```python
# This example specifies a query and a LIMIT value
retriever.invoke("What are two commits about hierarchical continuous aggregates?")
```

```output
query='hierarchical continuous aggregates' filter=None limit=2
```

```output
[Document(page_content='{"commit": " 35c91204987ccb0161d745af1a39b7eb91bc65a5", "author": "Fabr\\u00edzio de Royes Mello<fabriziomello@gmail.com>", "date": "Thu Nov 24 13:19:36 2022 -0300", "change summary": "Add Hierarchical Continuous Aggregates validations", "change details": "Commit 3749953e introduce Hierarchical Continuous Aggregates (aka Continuous Aggregate on top of another Continuous Aggregate) but it lacks of some basic validations.  Validations added during the creation of a Hierarchical Continuous Aggregate:  * Forbid create a continuous aggregate with fixed-width bucket on top of   a continuous aggregate with variable-width bucket.  * Forbid incompatible bucket widths:   - should not be equal;   - bucket width of the new continuous aggregate should be greater than     the source continuous aggregate;   - bucket width of the new continuous aggregate should be multiple of     the source continuous aggregate. "}', metadata={'id': 'c98d1c00-6c13-11ed-9bbe-23925ce74d13', 'date': '2022-11-24 13:19:36+-500', 'source': '/Users/avtharsewrathan/sideprojects2023/timescaleai/tsv-langchain/langchain/docs/docs/modules/ts_git_log.json', 'seq_num': 446, 'author_name': 'FabrÃ­zio de Royes Mello', 'commit_hash': ' 35c91204987ccb0161d745af1a39b7eb91bc65a5', 'author_email': 'fabriziomello@gmail.com'}),
 Document(page_content='{"commit": " 3749953e9704e45df8f621607989ada0714ce28d", "author": "Fabr\\u00edzio de Royes Mello<fabriziomello@gmail.com>", "date": "Wed Oct 5 18:45:40 2022 -0300", "change summary": "Hierarchical Continuous Aggregates", "change details": "Enable users create Hierarchical Continuous Aggregates (aka Continuous Aggregates on top of another Continuous Aggregates).  With this PR users can create levels of aggregation granularity in Continuous Aggregates making the refresh process even faster.  A problem with this feature can be in upper levels we can end up with the \\"average of averages\\". But to get the \\"real average\\" we can rely on \\"stats_aggs\\" TimescaleDB Toolkit function that calculate and store the partials that can be finalized with other toolkit functions like \\"average\\" and \\"sum\\".  Closes #1400 "}', metadata={'id': '0df31a00-44f7-11ed-9794-ebcc1227340f', 'date': '2022-10-5 18:45:40+-500', 'source': '/Users/avtharsewrathan/sideprojects2023/timescaleai/tsv-langchain/langchain/docs/docs/modules/ts_git_log.json', 'seq_num': 470, 'author_name': 'FabrÃ­zio de Royes Mello', 'commit_hash': ' 3749953e9704e45df8f621607989ada0714ce28d', 'author_email': 'fabriziomello@gmail.com'})]
```

## 5. æ—¢å­˜ã®TimescaleVectorãƒ™ã‚¯ãƒˆãƒ«ã‚¹ãƒˆã‚¢ã‚’ä½¿ç”¨ã™ã‚‹

ä¸Šè¨˜ã®ä¾‹ã§ã¯ã€ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆã®ã‚³ãƒ¬ã‚¯ã‚·ãƒ§ãƒ³ã‹ã‚‰ãƒ™ã‚¯ãƒˆãƒ«ã‚¹ãƒˆã‚¢ã‚’ä½œæˆã—ã¾ã—ãŸã€‚ã—ã‹ã—ã€æ—¢å­˜ã®ãƒ™ã‚¯ãƒˆãƒ«ã‚¹ãƒˆã‚¢ã«ãƒ‡ãƒ¼ã‚¿ã‚’æŒ¿å…¥ã—ã€ã‚¯ã‚¨ãƒªã‚’å®Ÿè¡Œã™ã‚‹ã“ã¨ãŒã‚ˆãã‚ã‚Šã¾ã™ã€‚TimescaleVectorãƒ™ã‚¯ãƒˆãƒ«ã‚¹ãƒˆã‚¢å†…ã®æ—¢å­˜ã®ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆã‚³ãƒ¬ã‚¯ã‚·ãƒ§ãƒ³ã‚’åˆæœŸåŒ–ã—ã€ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆã‚’è¿½åŠ ã—ã€ã‚¯ã‚¨ãƒªã‚’å®Ÿè¡Œã™ã‚‹æ–¹æ³•ã‚’è¦‹ã¦ã¿ã¾ã—ã‚‡ã†ã€‚

æ—¢å­˜ã®Timescale Vectorã‚¹ãƒˆã‚¢ã‚’ä½¿ç”¨ã™ã‚‹ã«ã¯ã€ã‚¯ã‚¨ãƒªã™ã‚‹ãƒ†ãƒ¼ãƒ–ãƒ«ã®åå‰ï¼ˆ`COLLECTION_NAME`ï¼‰ã¨ã€ã‚¯ãƒ©ã‚¦ãƒ‰PostgreSQLãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã®URLï¼ˆ`SERVICE_URL`ï¼‰ã‚’çŸ¥ã£ã¦ã„ã‚‹å¿…è¦ãŒã‚ã‚Šã¾ã™ã€‚

```python
# Initialize the existing
COLLECTION_NAME = "timescale_commits"
embeddings = OpenAIEmbeddings()
vectorstore = TimescaleVector(
    collection_name=COLLECTION_NAME,
    service_url=SERVICE_URL,
    embedding_function=embeddings,
)
```

ãƒ†ãƒ¼ãƒ–ãƒ«ã«æ–°ã—ã„ãƒ‡ãƒ¼ã‚¿ã‚’ãƒ­ãƒ¼ãƒ‰ã™ã‚‹ã«ã¯ã€`add_document()`é–¢æ•°ã‚’ä½¿ç”¨ã—ã¾ã™ã€‚ã“ã®é–¢æ•°ã¯ã€ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆã®ãƒªã‚¹ãƒˆã¨ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿ã®ãƒªã‚¹ãƒˆã‚’å—ã‘å–ã‚Šã¾ã™ã€‚ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿ã«ã¯å„ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆã®ä¸€æ„ã®IDãŒå«ã¾ã‚Œã¦ã„ã‚‹å¿…è¦ãŒã‚ã‚Šã¾ã™ã€‚

ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆã‚’ç¾åœ¨ã®æ—¥ä»˜ã¨æ™‚é–“ã«é–¢é€£ä»˜ã‘ãŸã„å ´åˆã€IDã®ãƒªã‚¹ãƒˆã‚’ä½œæˆã™ã‚‹å¿…è¦ã¯ã‚ã‚Šã¾ã›ã‚“ã€‚UUIDãŒå„ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆã«è‡ªå‹•çš„ã«ç”Ÿæˆã•ã‚Œã¾ã™ã€‚

ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆã‚’éå»ã®æ—¥ä»˜ã¨æ™‚é–“ã«é–¢é€£ä»˜ã‘ãŸã„å ´åˆã€ã‚»ã‚¯ã‚·ãƒ§ãƒ³2ã§ç¤ºã—ãŸã‚ˆã†ã«ã€`timecale-vector` Pythonãƒ©ã‚¤ãƒ–ãƒ©ãƒªã®`uuid_from_time`é–¢æ•°ã‚’ä½¿ç”¨ã—ã¦IDã®ãƒªã‚¹ãƒˆã‚’ä½œæˆã§ãã¾ã™ã€‚ã“ã®é–¢æ•°ã¯datetimeã‚ªãƒ–ã‚¸ã‚§ã‚¯ãƒˆã‚’å—ã‘å–ã‚Šã€æ—¥ä»˜ã¨æ™‚é–“ãŒã‚¨ãƒ³ã‚³ãƒ¼ãƒ‰ã•ã‚ŒãŸUUIDã‚’è¿”ã—ã¾ã™ã€‚

```python
# Add documents to a collection in TimescaleVector
ids = vectorstore.add_documents([Document(page_content="foo")])
ids
```

```output
['a34f2b8a-53d7-11ee-8cc3-de1e4b2a0118']
```

```python
# Query the vectorstore for similar documents
docs_with_score = vectorstore.similarity_search_with_score("foo")
```

```python
docs_with_score[0]
```

```output
(Document(page_content='foo', metadata={}), 5.006789860928507e-06)
```

```python
docs_with_score[1]
```

```output
(Document(page_content='{"commit": " 00b566dfe478c11134bcf1e7bcf38943e7fafe8f", "author": "Fabr\\u00edzio de Royes Mello<fabriziomello@gmail.com>", "date": "Mon Mar 6 15:51:03 2023 -0300", "change summary": "Remove unused functions", "change details": "We don\'t use `ts_catalog_delete[_only]` functions anywhere and instead we rely on `ts_catalog_delete_tid[_only]` functions so removing it from our code base. "}', metadata={'id': 'd7f5c580-bc4f-11ed-9712-ffa0126a201a', 'date': '2023-03-6 15:51:03+-500', 'source': '/Users/avtharsewrathan/sideprojects2023/timescaleai/tsv-langchain/langchain/docs/docs/modules/ts_git_log.json', 'seq_num': 285, 'author_name': 'FabrÃ­zio de Royes Mello', 'commit_hash': ' 00b566dfe478c11134bcf1e7bcf38943e7fafe8f', 'author_email': 'fabriziomello@gmail.com'}),
 0.23607668446580354)
```

### ãƒ‡ãƒ¼ã‚¿ã®å‰Šé™¤

UUIDã¾ãŸã¯ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿ã®ãƒ•ã‚£ãƒ«ã‚¿ã§ãƒ‡ãƒ¼ã‚¿ã‚’å‰Šé™¤ã§ãã¾ã™ã€‚

```python
ids = vectorstore.add_documents([Document(page_content="Bar")])

vectorstore.delete(ids)
```

```output
True
```

ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿ã‚’ä½¿ç”¨ã—ãŸå‰Šé™¤ã¯ã€ç‰¹å®šã®ã‚½ãƒ¼ã‚¹ã‹ã‚‰ã‚¹ã‚¯ãƒ¬ã‚¤ãƒ”ãƒ³ã‚°ã•ã‚ŒãŸæƒ…å ±ã‚„ç‰¹å®šã®æ—¥ä»˜ã€ãã®ä»–ã®ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿å±æ€§ã‚’å®šæœŸçš„ã«æ›´æ–°ã—ãŸã„å ´åˆã«ç‰¹ã«ä¾¿åˆ©ã§ã™ã€‚

```python
vectorstore.add_documents(
    [Document(page_content="Hello World", metadata={"source": "www.example.com/hello"})]
)
vectorstore.add_documents(
    [Document(page_content="Adios", metadata={"source": "www.example.com/adios"})]
)

vectorstore.delete_by_metadata({"source": "www.example.com/adios"})

vectorstore.add_documents(
    [
        Document(
            page_content="Adios, but newer!",
            metadata={"source": "www.example.com/adios"},
        )
    ]
)
```

```output
['c6367004-53d7-11ee-8cc3-de1e4b2a0118']
```

### ãƒ™ã‚¯ãƒˆãƒ«ã‚¹ãƒˆã‚¢ã®ä¸Šæ›¸ã

æ—¢å­˜ã®ã‚³ãƒ¬ã‚¯ã‚·ãƒ§ãƒ³ãŒã‚ã‚‹å ´åˆã€`from_documents`ã‚’å®Ÿè¡Œã—ã€`pre_delete_collection` = Trueã‚’è¨­å®šã™ã‚‹ã“ã¨ã§ä¸Šæ›¸ãã§ãã¾ã™ã€‚

```python
db = TimescaleVector.from_documents(
    documents=docs,
    embedding=embeddings,
    collection_name=COLLECTION_NAME,
    service_url=SERVICE_URL,
    pre_delete_collection=True,
)
```

```python
docs_with_score = db.similarity_search_with_score("foo")
```

```python
docs_with_score[0]
```
