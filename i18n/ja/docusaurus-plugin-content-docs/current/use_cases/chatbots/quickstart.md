---
sidebar_position: 0
translated: true
---

# ã‚¯ã‚¤ãƒƒã‚¯ã‚¹ã‚¿ãƒ¼ãƒˆ

[![](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/langchain-ai/langchain/blob/master/docs/docs/use_cases/chatbots.ipynb)

## æ¦‚è¦

LLMã‚’åˆ©ç”¨ã—ãŸãƒãƒ£ãƒƒãƒˆãƒœãƒƒãƒˆã®è¨­è¨ˆã¨å®Ÿè£…ã®ä¾‹ã‚’ç´¹ä»‹ã—ã¾ã™ã€‚ä»¥ä¸‹ã¯ä¸»ãªã‚³ãƒ³ãƒãƒ¼ãƒãƒ³ãƒˆã§ã™ï¼š

- `ãƒãƒ£ãƒƒãƒˆãƒ¢ãƒ‡ãƒ«`ã€‚ãƒãƒ£ãƒƒãƒˆãƒœãƒƒãƒˆã®ã‚¤ãƒ³ã‚¿ãƒ¼ãƒ•ã‚§ãƒ¼ã‚¹ã¯ç”Ÿã®ãƒ†ã‚­ã‚¹ãƒˆã§ã¯ãªããƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã‚’ä¸­å¿ƒã«æ§‹ç¯‰ã•ã‚Œã¦ãŠã‚Šã€ãƒ†ã‚­ã‚¹ãƒˆLLMã‚ˆã‚Šã‚‚ãƒãƒ£ãƒƒãƒˆãƒ¢ãƒ‡ãƒ«ã«é©ã—ã¦ã„ã¾ã™ã€‚ãƒãƒ£ãƒƒãƒˆãƒ¢ãƒ‡ãƒ«ã®çµ±åˆãƒªã‚¹ãƒˆã¯[ã“ã¡ã‚‰](/docs/integrations/chat)ã‚’ã”è¦§ãã ã•ã„ã€‚LangChainã«ãŠã‘ã‚‹ãƒãƒ£ãƒƒãƒˆãƒ¢ãƒ‡ãƒ«ã‚¤ãƒ³ã‚¿ãƒ¼ãƒ•ã‚§ãƒ¼ã‚¹ã®ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆã¯[ã“ã¡ã‚‰](/docs/modules/model_io/chat)ã‚’ã”è¦§ãã ã•ã„ã€‚ãƒãƒ£ãƒƒãƒˆãƒœãƒƒãƒˆã«ã¯`LLMs`ï¼ˆ[ã“ã¡ã‚‰](/docs/modules/model_io/llms)å‚ç…§ï¼‰ã‚‚ä½¿ç”¨ã§ãã¾ã™ãŒã€ãƒãƒ£ãƒƒãƒˆãƒ¢ãƒ‡ãƒ«ã®æ–¹ãŒä¼šè©±ã®ãƒˆãƒ¼ãƒ³ãŒã‚ã‚Šã€ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã‚¤ãƒ³ã‚¿ãƒ¼ãƒ•ã‚§ãƒ¼ã‚¹ã‚’ãƒã‚¤ãƒ†ã‚£ãƒ–ã«ã‚µãƒãƒ¼ãƒˆã—ã¦ã„ã¾ã™ã€‚
- `ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆãƒ†ãƒ³ãƒ—ãƒ¬ãƒ¼ãƒˆ`ã€‚ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆã®ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã€ãƒ¦ãƒ¼ã‚¶ãƒ¼å…¥åŠ›ã€ãƒãƒ£ãƒƒãƒˆå±¥æ­´ã€ãŠã‚ˆã³ï¼ˆã‚ªãƒ—ã‚·ãƒ§ãƒ³ã§ï¼‰è¿½åŠ ã®å–å¾—ã—ãŸã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆã‚’çµ„ã¿åˆã‚ã›ã‚‹ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã®ä½œæˆã‚’ç°¡ç´ åŒ–ã—ã¾ã™ã€‚
- `ãƒãƒ£ãƒƒãƒˆå±¥æ­´`ã€‚ãƒãƒ£ãƒƒãƒˆãƒœãƒƒãƒˆãŒéå»ã®ã‚„ã‚Šå–ã‚Šã‚’ã€Œè¦šãˆã¦ã„ã¦ã€ã€ãƒ•ã‚©ãƒ­ãƒ¼ã‚¢ãƒƒãƒ—ã®è³ªå•ã«ç­”ãˆã‚‹ã¨ãã«è€ƒæ…®ã«å…¥ã‚Œã‚‹ã“ã¨ãŒã§ãã¾ã™ã€‚è©³ç´°ã¯[ã“ã¡ã‚‰](/docs/modules/memory/chat_messages/)ã‚’ã”è¦§ãã ã•ã„ã€‚
- `ãƒªãƒˆãƒªãƒ¼ãƒãƒ¼`ï¼ˆã‚ªãƒ—ã‚·ãƒ§ãƒ³ï¼‰ã€‚ãƒ‰ãƒ¡ã‚¤ãƒ³å›ºæœ‰ã®æœ€æ–°çŸ¥è­˜ã‚’ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆã¨ã—ã¦ä½¿ç”¨ã—ã¦å¿œç­”ã‚’å¼·åŒ–ã™ã‚‹ãƒãƒ£ãƒƒãƒˆãƒœãƒƒãƒˆã‚’ä½œæˆã™ã‚‹å ´åˆã«å½¹ç«‹ã¡ã¾ã™ã€‚å–å¾—ã‚·ã‚¹ãƒ†ãƒ ã®è©³ç´°ãªãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆã¯[ã“ã¡ã‚‰](/docs/modules/data_connection/retrievers)ã‚’ã”è¦§ãã ã•ã„ã€‚

ã“ã‚Œã‚‰ã®ã‚³ãƒ³ãƒãƒ¼ãƒãƒ³ãƒˆã‚’ã©ã®ã‚ˆã†ã«çµ„ã¿åˆã‚ã›ã¦å¼·åŠ›ãªä¼šè©±å‹ãƒãƒ£ãƒƒãƒˆãƒœãƒƒãƒˆã‚’ä½œæˆã™ã‚‹ã‹ã‚’èª¬æ˜ã—ã¾ã™ã€‚

## ã‚¯ã‚¤ãƒƒã‚¯ã‚¹ã‚¿ãƒ¼ãƒˆ

ã¾ãšã€ä¾å­˜é–¢ä¿‚ã‚’ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«ã—ã€å¿…è¦ãªã‚¯ãƒ¬ãƒ‡ãƒ³ã‚·ãƒ£ãƒ«ã‚’è¨­å®šã—ã¾ã—ã‚‡ã†ï¼š

```python
%pip install --upgrade --quiet langchain langchain-openai langchain-chroma

# Set env var OPENAI_API_KEY or load from a .env file:
import dotenv

dotenv.load_dotenv()
```

```output
[33mWARNING: You are using pip version 22.0.4; however, version 23.3.2 is available.
You should consider upgrading via the '/Users/jacoblee/.pyenv/versions/3.10.5/bin/python -m pip install --upgrade pip' command.[0m[33m
[0mNote: you may need to restart the kernel to use updated packages.
```

```output
True
```

ãƒãƒ£ãƒƒãƒˆãƒœãƒƒãƒˆã®é ­è„³ã¨ãªã‚‹ãƒãƒ£ãƒƒãƒˆãƒ¢ãƒ‡ãƒ«ã‚’åˆæœŸåŒ–ã—ã¾ã—ã‚‡ã†ï¼š

```python
from langchain_openai import ChatOpenAI

chat = ChatOpenAI(model="gpt-3.5-turbo-1106", temperature=0.2)
```

ãƒãƒ£ãƒƒãƒˆãƒ¢ãƒ‡ãƒ«ã‚’å‘¼ã³å‡ºã™ã¨ã€å‡ºåŠ›ã¯`AIMessage`ã«ãªã‚Šã¾ã™ï¼š

```python
from langchain_core.messages import HumanMessage

chat.invoke(
    [
        HumanMessage(
            content="Translate this sentence from English to French: I love programming."
        )
    ]
)
```

```output
AIMessage(content="J'adore programmer.")
```

ãƒ¢ãƒ‡ãƒ«è‡ªä½“ã«ã¯çŠ¶æ…‹ã®æ¦‚å¿µãŒã‚ã‚Šã¾ã›ã‚“ã€‚ä¾‹ãˆã°ã€ãƒ•ã‚©ãƒ­ãƒ¼ã‚¢ãƒƒãƒ—ã®è³ªå•ã‚’ã™ã‚‹ã¨ï¼š

```python
chat.invoke([HumanMessage(content="What did you just say?")])
```

```output
AIMessage(content='I said, "What did you just say?"')
```

ä»¥å‰ã®ä¼šè©±ã®ã‚¿ãƒ¼ãƒ³ã‚’è€ƒæ…®ã«å…¥ã‚Œã¦ã„ãªã„ãŸã‚ã€è³ªå•ã«ç­”ãˆã‚‹ã“ã¨ãŒã§ãã¾ã›ã‚“ã€‚

ã“ã‚Œã‚’è§£æ±ºã™ã‚‹ãŸã‚ã«ã€å…¨ä¼šè©±å±¥æ­´ã‚’ãƒ¢ãƒ‡ãƒ«ã«æ¸¡ã™å¿…è¦ãŒã‚ã‚Šã¾ã™ã€‚è©¦ã—ã¦ã¿ã¾ã—ã‚‡ã†ï¼š

```python
from langchain_core.messages import AIMessage

chat.invoke(
    [
        HumanMessage(
            content="Translate this sentence from English to French: I love programming."
        ),
        AIMessage(content="J'adore la programmation."),
        HumanMessage(content="What did you just say?"),
    ]
)
```

```output
AIMessage(content='I said "J\'adore la programmation," which means "I love programming" in French.')
```

ã“ã‚Œã§è‰¯ã„å¿œç­”ãŒå¾—ã‚‰ã‚Œã‚‹ã“ã¨ãŒã‚ã‹ã‚Šã¾ã™ï¼

ã“ã‚ŒãŒãƒãƒ£ãƒƒãƒˆãƒœãƒƒãƒˆãŒä¼šè©±å½¢å¼ã§ã‚„ã‚Šå–ã‚Šã§ãã‚‹åŸºæœ¬çš„ãªã‚¢ã‚¤ãƒ‡ã‚¢ã§ã™ã€‚

## ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆãƒ†ãƒ³ãƒ—ãƒ¬ãƒ¼ãƒˆ

ãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆã‚’å°‘ã—ç°¡å˜ã«ã™ã‚‹ãŸã‚ã«ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆãƒ†ãƒ³ãƒ—ãƒ¬ãƒ¼ãƒˆã‚’å®šç¾©ã—ã¾ã—ã‚‡ã†ã€‚ã“ã‚Œã‚’ãƒ¢ãƒ‡ãƒ«ã«ãƒ‘ã‚¤ãƒ—ã§ç¹‹ãã“ã¨ã§ãƒã‚§ãƒ¼ãƒ³ã‚’ä½œæˆã§ãã¾ã™ï¼š

```python
from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder

prompt = ChatPromptTemplate.from_messages(
    [
        (
            "system",
            "You are a helpful assistant. Answer all questions to the best of your ability.",
        ),
        MessagesPlaceholder(variable_name="messages"),
    ]
)

chain = prompt | chat
```

ä¸Šè¨˜ã®`MessagesPlaceholder`ã¯ã€ãƒã‚§ãƒ¼ãƒ³ã®å…¥åŠ›ã¨ã—ã¦æ¸¡ã•ã‚ŒãŸãƒãƒ£ãƒƒãƒˆãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã‚’`chat_history`ã¨ã—ã¦ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã«ç›´æ¥æŒ¿å…¥ã—ã¾ã™ã€‚ãã—ã¦ã€æ¬¡ã®ã‚ˆã†ã«ãƒã‚§ãƒ¼ãƒ³ã‚’å‘¼ã³å‡ºã™ã“ã¨ãŒã§ãã¾ã™ï¼š

```python
chain.invoke(
    {
        "messages": [
            HumanMessage(
                content="Translate this sentence from English to French: I love programming."
            ),
            AIMessage(content="J'adore la programmation."),
            HumanMessage(content="What did you just say?"),
        ],
    }
)
```

```output
AIMessage(content='I said "J\'adore la programmation," which means "I love programming" in French.')
```

## ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸å±¥æ­´

ãƒãƒ£ãƒƒãƒˆå±¥æ­´ã‚’ç®¡ç†ã™ã‚‹ã‚·ãƒ§ãƒ¼ãƒˆã‚«ãƒƒãƒˆã¨ã—ã¦ã€[`MessageHistory`](/docs/modules/memory/chat_messages/)ã‚¯ãƒ©ã‚¹ã‚’ä½¿ç”¨ã§ãã¾ã™ã€‚ã“ã‚Œã¯ãƒãƒ£ãƒƒãƒˆãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã®ä¿å­˜ã¨èª­ã¿è¾¼ã¿ã‚’æ‹…å½“ã—ã¾ã™ã€‚å¤šãã®å†…è”µãƒ¡ãƒƒã‚»ãƒ¼ã‚¸å±¥æ­´çµ±åˆãŒã‚ã‚Šã€ã•ã¾ã–ã¾ãªãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã«ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã‚’ä¿å­˜ã§ãã¾ã™ãŒã€ã“ã®ã‚¯ã‚¤ãƒƒã‚¯ã‚¹ã‚¿ãƒ¼ãƒˆã§ã¯ãƒ¡ãƒ¢ãƒªå†…ã®ãƒ‡ãƒ¢ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸å±¥æ­´ã§ã‚ã‚‹`ChatMessageHistory`ã‚’ä½¿ç”¨ã—ã¾ã™ã€‚

ç›´æ¥ä½¿ç”¨ã™ã‚‹ä¾‹ã‚’ç¤ºã—ã¾ã™ï¼š

```python
from langchain.memory import ChatMessageHistory

demo_ephemeral_chat_history = ChatMessageHistory()

demo_ephemeral_chat_history.add_user_message("hi!")

demo_ephemeral_chat_history.add_ai_message("whats up?")

demo_ephemeral_chat_history.messages
```

```output
[HumanMessage(content='hi!'), AIMessage(content='whats up?')]
```

ã“ã‚Œã‚’è¡Œã†ã¨ã€ä¿å­˜ã•ã‚ŒãŸãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã‚’ãƒã‚§ãƒ¼ãƒ³ã®ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã¨ã—ã¦ç›´æ¥æ¸¡ã™ã“ã¨ãŒã§ãã¾ã™ï¼š

```python
demo_ephemeral_chat_history.add_user_message(
    "Translate this sentence from English to French: I love programming."
)

response = chain.invoke({"messages": demo_ephemeral_chat_history.messages})

response
```

```output
AIMessage(content='The translation of "I love programming" in French is "J\'adore la programmation."')
```

```python
demo_ephemeral_chat_history.add_ai_message(response)

demo_ephemeral_chat_history.add_user_message("What did you just say?")

chain.invoke({"messages": demo_ephemeral_chat_history.messages})
```

```output
AIMessage(content='I said "J\'adore la programmation," which is the French translation for "I love programming."')
```

ã“ã‚Œã§åŸºæœ¬çš„ãªãƒãƒ£ãƒƒãƒˆãƒœãƒƒãƒˆãŒå®Œæˆã—ã¾ã—ãŸï¼

ã“ã®ãƒã‚§ãƒ¼ãƒ³ã¯ãƒ¢ãƒ‡ãƒ«ã®å†…éƒ¨çŸ¥è­˜ã ã‘ã§å½¹ç«‹ã¤ãƒãƒ£ãƒƒãƒˆãƒœãƒƒãƒˆã¨ã—ã¦æ©Ÿèƒ½ã—ã¾ã™ãŒã€ãƒ‰ãƒ¡ã‚¤ãƒ³å›ºæœ‰ã®çŸ¥è­˜ã‚’åˆ©ç”¨ã—ã¦ãƒãƒ£ãƒƒãƒˆãƒœãƒƒãƒˆã‚’ã‚ˆã‚Šç„¦ç‚¹ã‚’å½“ã¦ãŸã‚‚ã®ã«ã™ã‚‹ãŸã‚ã«`retrieval-augmented generation`ï¼ˆRAGï¼‰ã‚’å°å…¥ã™ã‚‹ã“ã¨ãŒã‚ˆãã‚ã‚Šã¾ã™ã€‚æ¬¡ã«ã“ã‚Œã‚’èª¬æ˜ã—ã¾ã™ã€‚

## ãƒªãƒˆãƒªãƒ¼ãƒãƒ¼

ãƒãƒ£ãƒƒãƒˆãƒœãƒƒãƒˆã®ãŸã‚ã«ãƒ‰ãƒ¡ã‚¤ãƒ³å›ºæœ‰ã®çŸ¥è­˜ã‚’å¼•ãå‡ºã™ãŸã‚ã«[`Retriever`](/docs/modules/data_connection/retrievers/)ã‚’è¨­å®šã—ã¦ä½¿ç”¨ã§ãã¾ã™ã€‚ã“ã‚Œã‚’ç¤ºã™ãŸã‚ã«ã€ä¸Šã§ä½œæˆã—ãŸã‚·ãƒ³ãƒ—ãƒ«ãªãƒãƒ£ãƒƒãƒˆãƒœãƒƒãƒˆã‚’æ‹¡å¼µã—ã¦LangSmithã«é–¢ã™ã‚‹è³ªå•ã«ç­”ãˆã‚‰ã‚Œã‚‹ã‚ˆã†ã«ã—ã¾ã™ã€‚

[LangSmithã®ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆ](https://docs.smith.langchain.com/overview)ã‚’ç´ æã¨ã—ã¦ä½¿ç”¨ã—ã€å¾Œã§å–å¾—ã™ã‚‹ãŸã‚ã«ãƒ™ã‚¯ãƒˆãƒ«ã‚¹ãƒˆã‚¢ã«ä¿å­˜ã—ã¾ã™ã€‚ã“ã®ä¾‹ã§ã¯ãƒ‡ãƒ¼ã‚¿ã‚½ãƒ¼ã‚¹ã®è§£æã¨ä¿å­˜ã«é–¢ã™ã‚‹è©³ç´°ã¯çœç•¥ã—ã¾ã™ãŒã€[å–å¾—ã‚·ã‚¹ãƒ†ãƒ ã®ä½œæˆã«é–¢ã™ã‚‹è©³ç´°ãªãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆã¯ã“ã¡ã‚‰](/docs/use_cases/question_answering/)ã§ç¢ºèªã§ãã¾ã™ã€‚

ãƒªãƒˆãƒªãƒ¼ãƒãƒ¼ã‚’è¨­å®šã—ã¾ã—ã‚‡ã†ã€‚ã¾ãšã€å¿…è¦ãªãƒ‡ãƒšãƒ³ãƒ‡ãƒ³ã‚·ãƒ¼ã‚’ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«ã—ã¾ã™ï¼š

```python
%pip install --upgrade --quiet langchain-chroma beautifulsoup4
```

```output
[33mWARNING: You are using pip version 22.0.4; however, version 23.3.2 is available.
You should consider upgrading via the '/Users/jacoblee/.pyenv/versions/3.10.5/bin/python -m pip install --upgrade pip' command.[0m[33m
[0mNote: you may need to restart the kernel to use updated packages.
```

æ¬¡ã«ã€ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆãƒ­ãƒ¼ãƒ€ãƒ¼ã‚’ä½¿ç”¨ã—ã¦ã‚¦ã‚§ãƒ–ãƒšãƒ¼ã‚¸ã‹ã‚‰ãƒ‡ãƒ¼ã‚¿ã‚’å–å¾—ã—ã¾ã™ï¼š

```python
from langchain_community.document_loaders import WebBaseLoader

loader = WebBaseLoader("https://docs.smith.langchain.com/overview")
data = loader.load()
```

æ¬¡ã«ã€ãã‚Œã‚’LLMã®ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆã‚¦ã‚£ãƒ³ãƒ‰ã‚¦ãŒå‡¦ç†ã§ãã‚‹å°ã•ãªãƒãƒ£ãƒ³ã‚¯ã«åˆ†å‰²ã—ã€ãƒ™ã‚¯ãƒˆãƒ«ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã«ä¿å­˜ã—ã¾ã™ï¼š

```python
from langchain_text_splitters import RecursiveCharacterTextSplitter

text_splitter = RecursiveCharacterTextSplitter(chunk_size=500, chunk_overlap=0)
all_splits = text_splitter.split_documents(data)
```

æ¬¡ã«ã€ãã‚Œã‚‰ã®ãƒãƒ£ãƒ³ã‚¯ã‚’åŸ‹ã‚è¾¼ã¿ã€ãƒ™ã‚¯ãƒˆãƒ«ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã«ä¿å­˜ã—ã¾ã™ï¼š

```python
from langchain_chroma import Chroma
from langchain_openai import OpenAIEmbeddings

vectorstore = Chroma.from_documents(documents=all_splits, embedding=OpenAIEmbeddings())
```

æœ€å¾Œã«ã€åˆæœŸåŒ–ã•ã‚ŒãŸãƒ™ã‚¯ãƒˆãƒ«ã‚¹ãƒˆã‚¢ã‹ã‚‰ãƒªãƒˆãƒªãƒ¼ãƒãƒ¼ã‚’ä½œæˆã—ã¾ã™ï¼š

```python
# k is the number of chunks to retrieve
retriever = vectorstore.as_retriever(k=4)

docs = retriever.invoke("how can langsmith help with testing?")

docs
```

```output
[Document(page_content='You can also quickly edit examples and add them to datasets to expand the surface area of your evaluation sets or to fine-tune a model for improved quality or reduced costs.Monitoring\u200bAfter all this, your app might finally ready to go in production. LangSmith can also be used to monitor your application in much the same way that you used for debugging. You can log all traces, visualize latency and token usage statistics, and troubleshoot specific issues as they arise. Each run can also be', metadata={'description': 'Building reliable LLM applications can be challenging. LangChain simplifies the initial setup, but there is still work needed to bring the performance of prompts, chains and agents up the level where they are reliable enough to be used in production.', 'language': 'en', 'source': 'https://docs.smith.langchain.com/overview', 'title': 'LangSmith Overview and User Guide | ğŸ¦œï¸ğŸ› ï¸ LangSmith'}),
 Document(page_content='inputs, and see what happens. At some point though, our application is performing\nwell and we want to be more rigorous about testing changes. We can use a dataset\nthat weâ€™ve constructed along the way (see above). Alternatively, we could spend some\ntime constructing a small dataset by hand. For these situations, LangSmith simplifies', metadata={'description': 'Building reliable LLM applications can be challenging. LangChain simplifies the initial setup, but there is still work needed to bring the performance of prompts, chains and agents up the level where they are reliable enough to be used in production.', 'language': 'en', 'source': 'https://docs.smith.langchain.com/overview', 'title': 'LangSmith Overview and User Guide | ğŸ¦œï¸ğŸ› ï¸ LangSmith'}),
 Document(page_content='Skip to main contentğŸ¦œï¸ğŸ› ï¸ LangSmith DocsPython DocsJS/TS DocsSearchGo to AppLangSmithOverviewTracingTesting & EvaluationOrganizationsHubLangSmith CookbookOverviewOn this pageLangSmith Overview and User GuideBuilding reliable LLM applications can be challenging. LangChain simplifies the initial setup, but there is still work needed to bring the performance of prompts, chains and agents up the level where they are reliable enough to be used in production.Over the past two months, we at LangChain', metadata={'description': 'Building reliable LLM applications can be challenging. LangChain simplifies the initial setup, but there is still work needed to bring the performance of prompts, chains and agents up the level where they are reliable enough to be used in production.', 'language': 'en', 'source': 'https://docs.smith.langchain.com/overview', 'title': 'LangSmith Overview and User Guide | ğŸ¦œï¸ğŸ› ï¸ LangSmith'}),
 Document(page_content='have been building and using LangSmith with the goal of bridging this gap. This is our tactical user guide to outline effective ways to use LangSmith and maximize its benefits.On by default\u200bAt LangChain, all of us have LangSmithâ€™s tracing running in the background by default. On the Python side, this is achieved by setting environment variables, which we establish whenever we launch a virtual environment or open our bash shell and leave them set. The same principle applies to most JavaScript', metadata={'description': 'Building reliable LLM applications can be challenging. LangChain simplifies the initial setup, but there is still work needed to bring the performance of prompts, chains and agents up the level where they are reliable enough to be used in production.', 'language': 'en', 'source': 'https://docs.smith.langchain.com/overview', 'title': 'LangSmith Overview and User Guide | ğŸ¦œï¸ğŸ› ï¸ LangSmith'})]
```

ä¸Šè¨˜ã®ãƒªãƒˆãƒªãƒ¼ãƒãƒ¼ã‚’å‘¼ã³å‡ºã™ã¨ã€LangSmithã®ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆã®ä¸€éƒ¨ãŒè¿”ã•ã‚Œã€ãƒãƒ£ãƒƒãƒˆãƒœãƒƒãƒˆãŒè³ªå•ã«ç­”ãˆã‚‹ãŸã‚ã®ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆã¨ã—ã¦ä½¿ç”¨ã§ãã‚‹æƒ…å ±ãŒå«ã¾ã‚Œã¦ã„ã¾ã™ã€‚

### ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆã®æ‰±ã„

å‰ã®ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã‚’ä¿®æ­£ã—ã¦ã€ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆã¨ã—ã¦ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆã‚’å—ã‘å…¥ã‚Œã‚‹ã‚ˆã†ã«ã—ã¾ã—ã‚‡ã†ã€‚[`create_stuff_documents_chain`](https://api.python.langchain.com/en/latest/chains/langchain.chains.combine_documents.stuff.create_stuff_documents_chain.html#langchain.chains.combine_documents.stuff.create_stuff_documents_chain)ãƒ˜ãƒ«ãƒ‘ãƒ¼é–¢æ•°ã‚’ä½¿ç”¨ã—ã¦ã€å…¥åŠ›ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆã‚’ã™ã¹ã¦ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã«ã€Œè©°ã‚è¾¼ã¿ã€ã€ãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆã‚’ä¾¿åˆ©ã«å‡¦ç†ã—ã¾ã™ã€‚[`ChatPromptTemplate.from_messages`](/docs/modules/model_io/prompts/quick_start#chatprompttemplate)ãƒ¡ã‚½ãƒƒãƒ‰ã‚’ä½¿ç”¨ã—ã¦ã€ãƒãƒ£ãƒƒãƒˆå±¥æ­´ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã‚’ç›´æ¥æ³¨å…¥ã™ã‚‹[`MessagesPlaceholder`](/docs/modules/model_io/prompts/quick_start#messagesplaceholder)ã‚’å«ã‚€ã€ãƒ¢ãƒ‡ãƒ«ã«æ¸¡ã—ãŸã„ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸å…¥åŠ›ã‚’ãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆã—ã¾ã™ï¼š

```python
from langchain.chains.combine_documents import create_stuff_documents_chain

chat = ChatOpenAI(model="gpt-3.5-turbo-1106")

question_answering_prompt = ChatPromptTemplate.from_messages(
    [
        (
            "system",
            "Answer the user's questions based on the below context:\n\n{context}",
        ),
        MessagesPlaceholder(variable_name="messages"),
    ]
)

document_chain = create_stuff_documents_chain(chat, question_answering_prompt)
```

ä¸Šè¨˜ã§å–å¾—ã—ãŸç”Ÿã®ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆã‚’ä½¿ç”¨ã—ã¦ã“ã®`document_chain`ã‚’å‘¼ã³å‡ºã™ã“ã¨ãŒã§ãã¾ã™ï¼š

```python
from langchain.memory import ChatMessageHistory

demo_ephemeral_chat_history = ChatMessageHistory()

demo_ephemeral_chat_history.add_user_message("how can langsmith help with testing?")

document_chain.invoke(
    {
        "messages": demo_ephemeral_chat_history.messages,
        "context": docs,
    }
)
```

```output
'LangSmith can assist with testing by providing the capability to quickly edit examples and add them to datasets. This allows for the expansion of evaluation sets or fine-tuning of a model for improved quality or reduced costs. Additionally, LangSmith simplifies the construction of small datasets by hand, providing a convenient way to rigorously test changes in the application.'
```

ç´ æ™´ã‚‰ã—ã„ï¼å…¥åŠ›ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆã®æƒ…å ±ã‹ã‚‰åˆæˆã•ã‚ŒãŸå›ç­”ãŒå¾—ã‚‰ã‚Œã¾ã—ãŸã€‚

### ãƒªãƒˆãƒªãƒ¼ãƒãƒ«ãƒã‚§ãƒ¼ãƒ³ã®ä½œæˆ

æ¬¡ã«ã€ãƒªãƒˆãƒªãƒ¼ãƒãƒ¼ã‚’ãƒã‚§ãƒ¼ãƒ³ã«çµ±åˆã—ã¾ã—ã‚‡ã†ã€‚ãƒªãƒˆãƒªãƒ¼ãƒãƒ¼ã¯ãƒ¦ãƒ¼ã‚¶ãƒ¼ã‹ã‚‰æ¸¡ã•ã‚ŒãŸæœ€å¾Œã®ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã«é–¢é€£ã™ã‚‹æƒ…å ±ã‚’å–å¾—ã™ã‚‹å¿…è¦ãŒã‚ã‚‹ã®ã§ã€ãã‚Œã‚’æŠ½å‡ºã—ã¦é–¢é€£ã™ã‚‹ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆã‚’å–å¾—ã—ã€ãã‚Œã‚’`context`ã¨ã—ã¦ç¾åœ¨ã®ãƒã‚§ãƒ¼ãƒ³ã«è¿½åŠ ã—ã¾ã™ã€‚`context`ã¨ä»¥å‰ã®`messages`ã‚’ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆãƒã‚§ãƒ¼ãƒ³ã«æ¸¡ã—ã¦æœ€çµ‚çš„ãªå›ç­”ã‚’ç”Ÿæˆã—ã¾ã™ã€‚

ã¾ãŸã€[`RunnablePassthrough.assign()`](/docs/expression_language/primitives/assign)ãƒ¡ã‚½ãƒƒãƒ‰ã‚’ä½¿ç”¨ã—ã¦ã€å„å‘¼ã³å‡ºã—æ™‚ã«ä¸­é–“ã‚¹ãƒ†ãƒƒãƒ—ã‚’é€šéã•ã›ã¾ã™ã€‚ä»¥ä¸‹ã®ã‚ˆã†ã«ãªã‚Šã¾ã™ï¼š

```python
from typing import Dict

from langchain_core.runnables import RunnablePassthrough


def parse_retriever_input(params: Dict):
    return params["messages"][-1].content


retrieval_chain = RunnablePassthrough.assign(
    context=parse_retriever_input | retriever,
).assign(
    answer=document_chain,
)
```

```python
response = retrieval_chain.invoke(
    {
        "messages": demo_ephemeral_chat_history.messages,
    }
)

response
```

```output
{'messages': [HumanMessage(content='how can langsmith help with testing?')],
 'context': [Document(page_content='You can also quickly edit examples and add them to datasets to expand the surface area of your evaluation sets or to fine-tune a model for improved quality or reduced costs.Monitoring\u200bAfter all this, your app might finally ready to go in production. LangSmith can also be used to monitor your application in much the same way that you used for debugging. You can log all traces, visualize latency and token usage statistics, and troubleshoot specific issues as they arise. Each run can also be', metadata={'description': 'Building reliable LLM applications can be challenging. LangChain simplifies the initial setup, but there is still work needed to bring the performance of prompts, chains and agents up the level where they are reliable enough to be used in production.', 'language': 'en', 'source': 'https://docs.smith.langchain.com/overview', 'title': 'LangSmith Overview and User Guide | ğŸ¦œï¸ğŸ› ï¸ LangSmith'}),
  Document(page_content='inputs, and see what happens. At some point though, our application is performing\nwell and we want to be more rigorous about testing changes. We can use a dataset\nthat weâ€™ve constructed along the way (see above). Alternatively, we could spend some\ntime constructing a small dataset by hand. For these situations, LangSmith simplifies', metadata={'description': 'Building reliable LLM applications can be challenging. LangChain simplifies the initial setup, but there is still work needed to bring the performance of prompts, chains and agents up the level where they are reliable enough to be used in production.', 'language': 'en', 'source': 'https://docs.smith.langchain.com/overview', 'title': 'LangSmith Overview and User Guide | ğŸ¦œï¸ğŸ› ï¸ LangSmith'}),
  Document(page_content='Skip to main contentğŸ¦œï¸ğŸ› ï¸ LangSmith DocsPython DocsJS/TS DocsSearchGo to AppLangSmithOverviewTracingTesting & EvaluationOrganizationsHubLangSmith CookbookOverviewOn this pageLangSmith Overview and User GuideBuilding reliable LLM applications can be challenging. LangChain simplifies the initial setup, but there is still work needed to bring the performance of prompts, chains and agents up the level where they are reliable enough to be used in production.Over the past two months, we at LangChain', metadata={'description': 'Building reliable LLM applications can be challenging. LangChain simplifies the initial setup, but there is still work needed to bring the performance of prompts, chains and agents up the level where they are reliable enough to be used in production.', 'language': 'en', 'source': 'https://docs.smith.langchain.com/overview', 'title': 'LangSmith Overview and User Guide | ğŸ¦œï¸ğŸ› ï¸ LangSmith'}),
  Document(page_content='have been building and using LangSmith with the goal of bridging this gap. This is our tactical user guide to outline effective ways to use LangSmith and maximize its benefits.On by default\u200bAt LangChain, all of us have LangSmithâ€™s tracing running in the background by default. On the Python side, this is achieved by setting environment variables, which we establish whenever we launch a virtual environment or open our bash shell and leave them set. The same principle applies to most JavaScript', metadata={'description': 'Building reliable LLM applications can be challenging. LangChain simplifies the initial setup, but there is still work needed to bring the performance of prompts, chains and agents up the level where they are reliable enough to be used in production.', 'language': 'en', 'source': 'https://docs.smith.langchain.com/overview', 'title': 'LangSmith Overview and User Guide | ğŸ¦œï¸ğŸ› ï¸ LangSmith'})],
 'answer': 'LangSmith can help with testing in several ways:\n\n1. Dataset Expansion: LangSmith enables quick editing of examples and adding them to datasets, which expands the surface area of evaluation sets. This allows for more comprehensive testing of models and applications.\n\n2. Fine-Tuning Models: LangSmith facilitates the fine-tuning of models for improved quality or reduced costs. This is beneficial for optimizing the performance of models during testing.\n\n3. Monitoring: LangSmith can be used to monitor applications, log traces, visualize latency and token usage statistics, and troubleshoot specific issues as they arise during testing. This monitoring helps in ensuring the reliability and performance of the application during testing phases.\n\nOverall, LangSmith helps in making testing more rigorous and comprehensive, whether by expanding datasets, fine-tuning models, or monitoring application performance.'}
```

```python
demo_ephemeral_chat_history.add_ai_message(response["answer"])

demo_ephemeral_chat_history.add_user_message("tell me more about that!")

retrieval_chain.invoke(
    {
        "messages": demo_ephemeral_chat_history.messages,
    },
)
```

```output
{'messages': [HumanMessage(content='how can langsmith help with testing?'),
  AIMessage(content='LangSmith can help with testing in several ways:\n\n1. Dataset Expansion: LangSmith enables quick editing of examples and adding them to datasets, which expands the surface area of evaluation sets. This allows for more comprehensive testing of models and applications.\n\n2. Fine-Tuning Models: LangSmith facilitates the fine-tuning of models for improved quality or reduced costs. This is beneficial for optimizing the performance of models during testing.\n\n3. Monitoring: LangSmith can be used to monitor applications, log traces, visualize latency and token usage statistics, and troubleshoot specific issues as they arise during testing. This monitoring helps in ensuring the reliability and performance of the application during testing phases.\n\nOverall, LangSmith helps in making testing more rigorous and comprehensive, whether by expanding datasets, fine-tuning models, or monitoring application performance.'),
  HumanMessage(content='tell me more about that!')],
 'context': [Document(page_content='however, there is still no complete substitute for human review to get the utmost quality and reliability from your application.', metadata={'description': 'Building reliable LLM applications can be challenging. LangChain simplifies the initial setup, but there is still work needed to bring the performance of prompts, chains and agents up the level where they are reliable enough to be used in production.', 'language': 'en', 'source': 'https://docs.smith.langchain.com/overview', 'title': 'LangSmith Overview and User Guide | ğŸ¦œï¸ğŸ› ï¸ LangSmith'}),
  Document(page_content='You can also quickly edit examples and add them to datasets to expand the surface area of your evaluation sets or to fine-tune a model for improved quality or reduced costs.Monitoring\u200bAfter all this, your app might finally ready to go in production. LangSmith can also be used to monitor your application in much the same way that you used for debugging. You can log all traces, visualize latency and token usage statistics, and troubleshoot specific issues as they arise. Each run can also be', metadata={'description': 'Building reliable LLM applications can be challenging. LangChain simplifies the initial setup, but there is still work needed to bring the performance of prompts, chains and agents up the level where they are reliable enough to be used in production.', 'language': 'en', 'source': 'https://docs.smith.langchain.com/overview', 'title': 'LangSmith Overview and User Guide | ğŸ¦œï¸ğŸ› ï¸ LangSmith'}),
  Document(page_content="against these known issues.Why is this so impactful? When building LLM applications, itâ€™s often common to start without a dataset of any kind. This is part of the power of LLMs! They are amazing zero-shot learners, making it possible to get started as easily as possible. But this can also be a curse -- as you adjust the prompt, you're wandering blind. You donâ€™t have any examples to benchmark your changes against.LangSmith addresses this problem by including an â€œAdd to Datasetâ€ button for each", metadata={'description': 'Building reliable LLM applications can be challenging. LangChain simplifies the initial setup, but there is still work needed to bring the performance of prompts, chains and agents up the level where they are reliable enough to be used in production.', 'language': 'en', 'source': 'https://docs.smith.langchain.com/overview', 'title': 'LangSmith Overview and User Guide | ğŸ¦œï¸ğŸ› ï¸ LangSmith'}),
  Document(page_content='playground. Here, you can modify the prompt and re-run it to observe the resulting changes to the output - as many times as needed!Currently, this feature supports only OpenAI and Anthropic models and works for LLM and Chat Model calls. We plan to extend its functionality to more LLM types, chains, agents, and retrievers in the future.What is the exact sequence of events?\u200bIn complicated chains and agents, it can often be hard to understand what is going on under the hood. What calls are being', metadata={'description': 'Building reliable LLM applications can be challenging. LangChain simplifies the initial setup, but there is still work needed to bring the performance of prompts, chains and agents up the level where they are reliable enough to be used in production.', 'language': 'en', 'source': 'https://docs.smith.langchain.com/overview', 'title': 'LangSmith Overview and User Guide | ğŸ¦œï¸ğŸ› ï¸ LangSmith'})],
 'answer': 'Certainly! LangSmith offers the following capabilities to aid in testing:\n\n1. Dataset Expansion: By allowing quick editing of examples and adding them to datasets, LangSmith enables the expansion of evaluation sets. This is crucial for thorough testing of models and applications, as it broadens the range of scenarios and inputs that can be used to assess performance.\n\n2. Fine-Tuning Models: LangSmith supports the fine-tuning of models to enhance their quality and reduce operational costs. This capability is valuable during testing as it enables the optimization of model performance based on specific testing requirements and objectives.\n\n3. Monitoring: LangSmith provides monitoring features that allow for the logging of traces, visualization of latency and token usage statistics, and troubleshooting of issues as they occur during testing. This real-time monitoring helps in identifying and addressing any issues that may impact the reliability and performance of the application during testing.\n\nBy leveraging these features, LangSmith enhances the testing process by enabling comprehensive dataset expansion, model fine-tuning, and real-time monitoring to ensure the quality and reliability of applications and models.'}
```

è‰¯ã„ã§ã™ã­ï¼ã“ã‚Œã§ãƒãƒ£ãƒƒãƒˆãƒœãƒƒãƒˆã¯ä¼šè©±å½¢å¼ã§ãƒ‰ãƒ¡ã‚¤ãƒ³å›ºæœ‰ã®è³ªå•ã«ç­”ãˆã‚‹ã“ã¨ãŒã§ãã¾ã™ã€‚

ã¡ãªã¿ã«ã€ã™ã¹ã¦ã®ä¸­é–“ã‚¹ãƒ†ãƒƒãƒ—ã‚’è¿”ã—ãŸããªã„å ´åˆã¯ã€æœ€çµ‚çš„ãª`.assign()`å‘¼ã³å‡ºã—ã®ä»£ã‚ã‚Šã«ãƒ‘ã‚¤ãƒ—ã§ç›´æ¥ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆãƒã‚§ãƒ¼ãƒ³ã«æ¥ç¶šã—ã¦ã€æ¬¡ã®ã‚ˆã†ã«ãƒªãƒˆãƒªãƒ¼ãƒãƒ«ãƒã‚§ãƒ¼ãƒ³ã‚’å®šç¾©ã™ã‚‹ã“ã¨ãŒã§ãã¾ã™ï¼š

```python
retrieval_chain_with_only_answer = (
    RunnablePassthrough.assign(
        context=parse_retriever_input | retriever,
    )
    | document_chain
)

retrieval_chain_with_only_answer.invoke(
    {
        "messages": demo_ephemeral_chat_history.messages,
    },
)
```

```output
"LangSmith offers the capability to quickly edit examples and add them to datasets, thereby enhancing the scope of evaluation sets. This feature is particularly valuable for testing as it allows for a more thorough assessment of model performance and application behavior.\n\nFurthermore, LangSmith enables the fine-tuning of models to enhance quality and reduce costs, which can significantly impact testing outcomes. By adjusting and refining models, developers can ensure that they are thoroughly tested and optimized for various scenarios and use cases.\n\nAdditionally, LangSmith provides monitoring functionality, allowing users to log traces, visualize latency and token usage statistics, and troubleshoot specific issues as they encounter them during testing. This real-time monitoring and troubleshooting capability contribute to the overall effectiveness and reliability of the testing process.\n\nIn essence, LangSmith's features are designed to improve the quality and reliability of testing by expanding evaluation sets, fine-tuning models, and providing comprehensive monitoring capabilities. These aspects collectively contribute to a more robust and thorough testing process for applications and models."
```

## ã‚¯ã‚¨ãƒªå¤‰æ›

ã“ã“ã§æœ€å¾Œã®æœ€é©åŒ–ã«ã¤ã„ã¦èª¬æ˜ã—ã¾ã™ã€‚ä¸Šè¨˜ã®ä¾‹ã§ã¯ã€ãƒ•ã‚©ãƒ­ãƒ¼ã‚¢ãƒƒãƒ—ã®è³ªå•ã¨ã—ã¦ã€Œãã‚Œã«ã¤ã„ã¦ã‚‚ã£ã¨æ•™ãˆã¦ï¼ã€ã¨å°‹ã­ãŸã¨ãã€å–å¾—ã—ãŸãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆã«ãƒ†ã‚¹ãƒˆã«é–¢ã™ã‚‹æƒ…å ±ãŒç›´æ¥å«ã¾ã‚Œã¦ã„ãªã„ã“ã¨ã«æ°—ä»˜ãã‹ã‚‚ã—ã‚Œã¾ã›ã‚“ã€‚ã“ã‚Œã¯ã€Œãã‚Œã«ã¤ã„ã¦ã‚‚ã£ã¨æ•™ãˆã¦ï¼ã€ã‚’ãã®ã¾ã¾ãƒªãƒˆãƒªãƒ¼ãƒãƒ¼ã«ã‚¯ã‚¨ãƒªã¨ã—ã¦æ¸¡ã—ã¦ã„ã‚‹ãŸã‚ã§ã™ã€‚å–å¾—ãƒã‚§ãƒ¼ãƒ³ã®å‡ºåŠ›ã¯ã¾ã å•é¡Œã‚ã‚Šã¾ã›ã‚“ãŒã€ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆãƒã‚§ãƒ¼ãƒ³ã®å–å¾—ãƒã‚§ãƒ¼ãƒ³ã¯ãƒãƒ£ãƒƒãƒˆå±¥æ­´ã«åŸºã¥ã„ã¦å›ç­”ã‚’ç”Ÿæˆã§ãã¾ã™ãŒã€ã‚ˆã‚Šè±Šã‹ã§æƒ…å ±è±Šå¯Œãªãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆã‚’å–å¾—ã™ã‚‹ã“ã¨ãŒã§ãã¾ã™ï¼š

```python
retriever.invoke("how can langsmith help with testing?")
```

```output
[Document(page_content='You can also quickly edit examples and add them to datasets to expand the surface area of your evaluation sets or to fine-tune a model for improved quality or reduced costs.Monitoring\u200bAfter all this, your app might finally ready to go in production. LangSmith can also be used to monitor your application in much the same way that you used for debugging. You can log all traces, visualize latency and token usage statistics, and troubleshoot specific issues as they arise. Each run can also be', metadata={'description': 'Building reliable LLM applications can be challenging. LangChain simplifies the initial setup, but there is still work needed to bring the performance of prompts, chains and agents up the level where they are reliable enough to be used in production.', 'language': 'en', 'source': 'https://docs.smith.langchain.com/overview', 'title': 'LangSmith Overview and User Guide | ğŸ¦œï¸ğŸ› ï¸ LangSmith'}),
 Document(page_content='inputs, and see what happens. At some point though, our application is performing\nwell and we want to be more rigorous about testing changes. We can use a dataset\nthat weâ€™ve constructed along the way (see above). Alternatively, we could spend some\ntime constructing a small dataset by hand. For these situations, LangSmith simplifies', metadata={'description': 'Building reliable LLM applications can be challenging. LangChain simplifies the initial setup, but there is still work needed to bring the performance of prompts, chains and agents up the level where they are reliable enough to be used in production.', 'language': 'en', 'source': 'https://docs.smith.langchain.com/overview', 'title': 'LangSmith Overview and User Guide | ğŸ¦œï¸ğŸ› ï¸ LangSmith'}),
 Document(page_content='Skip to main contentğŸ¦œï¸ğŸ› ï¸ LangSmith DocsPython DocsJS/TS DocsSearchGo to AppLangSmithOverviewTracingTesting & EvaluationOrganizationsHubLangSmith CookbookOverviewOn this pageLangSmith Overview and User GuideBuilding reliable LLM applications can be challenging. LangChain simplifies the initial setup, but there is still work needed to bring the performance of prompts, chains and agents up the level where they are reliable enough to be used in production.Over the past two months, we at LangChain', metadata={'description': 'Building reliable LLM applications can be challenging. LangChain simplifies the initial setup, but there is still work needed to bring the performance of prompts, chains and agents up the level where they are reliable enough to be used in production.', 'language': 'en', 'source': 'https://docs.smith.langchain.com/overview', 'title': 'LangSmith Overview and User Guide | ğŸ¦œï¸ğŸ› ï¸ LangSmith'}),
 Document(page_content='have been building and using LangSmith with the goal of bridging this gap. This is our tactical user guide to outline effective ways to use LangSmith and maximize its benefits.On by default\u200bAt LangChain, all of us have LangSmithâ€™s tracing running in the background by default. On the Python side, this is achieved by setting environment variables, which we establish whenever we launch a virtual environment or open our bash shell and leave them set. The same principle applies to most JavaScript', metadata={'description': 'Building reliable LLM applications can be challenging. LangChain simplifies the initial setup, but there is still work needed to bring the performance of prompts, chains and agents up the level where they are reliable enough to be used in production.', 'language': 'en', 'source': 'https://docs.smith.langchain.com/overview', 'title': 'LangSmith Overview and User Guide | ğŸ¦œï¸ğŸ› ï¸ LangSmith'})]
```

```python
retriever.invoke("tell me more about that!")
```

```output
[Document(page_content='however, there is still no complete substitute for human review to get the utmost quality and reliability from your application.', metadata={'description': 'Building reliable LLM applications can be challenging. LangChain simplifies the initial setup, but there is still work needed to bring the performance of prompts, chains and agents up the level where they are reliable enough to be used in production.', 'language': 'en', 'source': 'https://docs.smith.langchain.com/overview', 'title': 'LangSmith Overview and User Guide | ğŸ¦œï¸ğŸ› ï¸ LangSmith'}),
 Document(page_content='You can also quickly edit examples and add them to datasets to expand the surface area of your evaluation sets or to fine-tune a model for improved quality or reduced costs.Monitoring\u200bAfter all this, your app might finally ready to go in production. LangSmith can also be used to monitor your application in much the same way that you used for debugging. You can log all traces, visualize latency and token usage statistics, and troubleshoot specific issues as they arise. Each run can also be', metadata={'description': 'Building reliable LLM applications can be challenging. LangChain simplifies the initial setup, but there is still work needed to bring the performance of prompts, chains and agents up the level where they are reliable enough to be used in production.', 'language': 'en', 'source': 'https://docs.smith.langchain.com/overview', 'title': 'LangSmith Overview and User Guide | ğŸ¦œï¸ğŸ› ï¸ LangSmith'}),
 Document(page_content="against these known issues.Why is this so impactful? When building LLM applications, itâ€™s often common to start without a dataset of any kind. This is part of the power of LLMs! They are amazing zero-shot learners, making it possible to get started as easily as possible. But this can also be a curse -- as you adjust the prompt, you're wandering blind. You donâ€™t have any examples to benchmark your changes against.LangSmith addresses this problem by including an â€œAdd to Datasetâ€ button for each", metadata={'description': 'Building reliable LLM applications can be challenging. LangChain simplifies the initial setup, but there is still work needed to bring the performance of prompts, chains and agents up the level where they are reliable enough to be used in production.', 'language': 'en', 'source': 'https://docs.smith.langchain.com/overview', 'title': 'LangSmith Overview and User Guide | ğŸ¦œï¸ğŸ› ï¸ LangSmith'}),
 Document(page_content='playground. Here, you can modify the prompt and re-run it to observe the resulting changes to the output - as many times as needed!Currently, this feature supports only OpenAI and Anthropic models and works for LLM and Chat Model calls. We plan to extend its functionality to more LLM types, chains, agents, and retrievers in the future.What is the exact sequence of events?\u200bIn complicated chains and agents, it can often be hard to understand what is going on under the hood. What calls are being', metadata={'description': 'Building reliable LLM applications can be challenging. LangChain simplifies the initial setup, but there is still work needed to bring the performance of prompts, chains and agents up the level where they are reliable enough to be used in production.', 'language': 'en', 'source': 'https://docs.smith.langchain.com/overview', 'title': 'LangSmith Overview and User Guide | ğŸ¦œï¸ğŸ› ï¸ LangSmith'})]
```

ã“ã®ä¸€èˆ¬çš„ãªå•é¡Œã‚’è§£æ±ºã™ã‚‹ãŸã‚ã«ã€å…¥åŠ›ã‹ã‚‰å‚ç…§ã‚’å‰Šé™¤ã™ã‚‹`ã‚¯ã‚¨ãƒªå¤‰æ›`ã‚¹ãƒ†ãƒƒãƒ—ã‚’è¿½åŠ ã—ã¾ã—ã‚‡ã†ã€‚æ¬¡ã®ã‚ˆã†ã«å¤ã„ãƒªãƒˆãƒªãƒ¼ãƒãƒ¼ã‚’ãƒ©ãƒƒãƒ—ã—ã¾ã™ï¼š

```python
from langchain_core.output_parsers import StrOutputParser
from langchain_core.runnables import RunnableBranch

# We need a prompt that we can pass into an LLM to generate a transformed search query

chat = ChatOpenAI(model="gpt-3.5-turbo-1106", temperature=0.2)

query_transform_prompt = ChatPromptTemplate.from_messages(
    [
        MessagesPlaceholder(variable_name="messages"),
        (
            "user",
            "Given the above conversation, generate a search query to look up in order to get information relevant to the conversation. Only respond with the query, nothing else.",
        ),
    ]
)

query_transforming_retriever_chain = RunnableBranch(
    (
        lambda x: len(x.get("messages", [])) == 1,
        # If only one message, then we just pass that message's content to retriever
        (lambda x: x["messages"][-1].content) | retriever,
    ),
    # If messages, then we pass inputs to LLM chain to transform the query, then pass to retriever
    query_transform_prompt | chat | StrOutputParser() | retriever,
).with_config(run_name="chat_retriever_chain")
```

æ¬¡ã«ã€ã“ã®æ–°ã—ã„`query_transforming_retriever_chain`ã‚’ä½¿ç”¨ã—ã¦å…ˆã»ã©ã®ãƒã‚§ãƒ¼ãƒ³ã‚’å†ä½œæˆã—ã¾ã™ã€‚ã“ã®æ–°ã—ã„ãƒã‚§ãƒ¼ãƒ³ã¯å…¥åŠ›ã¨ã—ã¦dictã‚’å—ã‘å…¥ã‚Œã€ãƒªãƒˆãƒªãƒ¼ãƒãƒ¼ã«æ¸¡ã™æ–‡å­—åˆ—ã‚’è§£æã™ã‚‹ãŸã‚ã€ãƒˆãƒƒãƒ—ãƒ¬ãƒ™ãƒ«ã§è¿½åŠ ã®è§£æã‚’è¡Œã†å¿…è¦ã¯ã‚ã‚Šã¾ã›ã‚“ï¼š

```python
document_chain = create_stuff_documents_chain(chat, question_answering_prompt)

conversational_retrieval_chain = RunnablePassthrough.assign(
    context=query_transforming_retriever_chain,
).assign(
    answer=document_chain,
)

demo_ephemeral_chat_history = ChatMessageHistory()
```

æœ€å¾Œã«ã€ãã‚Œã‚’å‘¼ã³å‡ºã—ã¾ã—ã‚‡ã†ï¼

```python
demo_ephemeral_chat_history.add_user_message("how can langsmith help with testing?")

response = conversational_retrieval_chain.invoke(
    {"messages": demo_ephemeral_chat_history.messages},
)

demo_ephemeral_chat_history.add_ai_message(response["answer"])

response
```

```output
{'messages': [HumanMessage(content='how can langsmith help with testing?'),
  AIMessage(content='LangSmith can assist with testing in several ways. It allows you to quickly edit examples and add them to datasets, expanding the range of evaluation sets. This can help in fine-tuning a model for improved quality or reduced costs. Additionally, LangSmith simplifies the construction of small datasets by hand, providing a convenient way to rigorously test changes in your application. Furthermore, it enables monitoring of your application by logging all traces, visualizing latency and token usage statistics, and troubleshooting specific issues as they arise.')],
 'context': [Document(page_content='You can also quickly edit examples and add them to datasets to expand the surface area of your evaluation sets or to fine-tune a model for improved quality or reduced costs.Monitoring\u200bAfter all this, your app might finally ready to go in production. LangSmith can also be used to monitor your application in much the same way that you used for debugging. You can log all traces, visualize latency and token usage statistics, and troubleshoot specific issues as they arise. Each run can also be', metadata={'description': 'Building reliable LLM applications can be challenging. LangChain simplifies the initial setup, but there is still work needed to bring the performance of prompts, chains and agents up the level where they are reliable enough to be used in production.', 'language': 'en', 'source': 'https://docs.smith.langchain.com/overview', 'title': 'LangSmith Overview and User Guide | ğŸ¦œï¸ğŸ› ï¸ LangSmith'}),
  Document(page_content='inputs, and see what happens. At some point though, our application is performing\nwell and we want to be more rigorous about testing changes. We can use a dataset\nthat weâ€™ve constructed along the way (see above). Alternatively, we could spend some\ntime constructing a small dataset by hand. For these situations, LangSmith simplifies', metadata={'description': 'Building reliable LLM applications can be challenging. LangChain simplifies the initial setup, but there is still work needed to bring the performance of prompts, chains and agents up the level where they are reliable enough to be used in production.', 'language': 'en', 'source': 'https://docs.smith.langchain.com/overview', 'title': 'LangSmith Overview and User Guide | ğŸ¦œï¸ğŸ› ï¸ LangSmith'}),
  Document(page_content='Skip to main contentğŸ¦œï¸ğŸ› ï¸ LangSmith DocsPython DocsJS/TS DocsSearchGo to AppLangSmithOverviewTracingTesting & EvaluationOrganizationsHubLangSmith CookbookOverviewOn this pageLangSmith Overview and User GuideBuilding reliable LLM applications can be challenging. LangChain simplifies the initial setup, but there is still work needed to bring the performance of prompts, chains and agents up the level where they are reliable enough to be used in production.Over the past two months, we at LangChain', metadata={'description': 'Building reliable LLM applications can be challenging. LangChain simplifies the initial setup, but there is still work needed to bring the performance of prompts, chains and agents up the level where they are reliable enough to be used in production.', 'language': 'en', 'source': 'https://docs.smith.langchain.com/overview', 'title': 'LangSmith Overview and User Guide | ğŸ¦œï¸ğŸ› ï¸ LangSmith'}),
  Document(page_content='have been building and using LangSmith with the goal of bridging this gap. This is our tactical user guide to outline effective ways to use LangSmith and maximize its benefits.On by default\u200bAt LangChain, all of us have LangSmithâ€™s tracing running in the background by default. On the Python side, this is achieved by setting environment variables, which we establish whenever we launch a virtual environment or open our bash shell and leave them set. The same principle applies to most JavaScript', metadata={'description': 'Building reliable LLM applications can be challenging. LangChain simplifies the initial setup, but there is still work needed to bring the performance of prompts, chains and agents up the level where they are reliable enough to be used in production.', 'language': 'en', 'source': 'https://docs.smith.langchain.com/overview', 'title': 'LangSmith Overview and User Guide | ğŸ¦œï¸ğŸ› ï¸ LangSmith'})],
 'answer': 'LangSmith can assist with testing in several ways. It allows you to quickly edit examples and add them to datasets, expanding the range of evaluation sets. This can help in fine-tuning a model for improved quality or reduced costs. Additionally, LangSmith simplifies the construction of small datasets by hand, providing a convenient way to rigorously test changes in your application. Furthermore, it enables monitoring of your application by logging all traces, visualizing latency and token usage statistics, and troubleshooting specific issues as they arise.'}
```

```python
demo_ephemeral_chat_history.add_user_message("tell me more about that!")

conversational_retrieval_chain.invoke(
    {"messages": demo_ephemeral_chat_history.messages}
)
```

```output
{'messages': [HumanMessage(content='how can langsmith help with testing?'),
  AIMessage(content='LangSmith can assist with testing in several ways. It allows you to quickly edit examples and add them to datasets, expanding the range of evaluation sets. This can help in fine-tuning a model for improved quality or reduced costs. Additionally, LangSmith simplifies the construction of small datasets by hand, providing a convenient way to rigorously test changes in your application. Furthermore, it enables monitoring of your application by logging all traces, visualizing latency and token usage statistics, and troubleshooting specific issues as they arise.'),
  HumanMessage(content='tell me more about that!')],
 'context': [Document(page_content='LangSmith Overview and User Guide | ğŸ¦œï¸ğŸ› ï¸ LangSmith', metadata={'description': 'Building reliable LLM applications can be challenging. LangChain simplifies the initial setup, but there is still work needed to bring the performance of prompts, chains and agents up the level where they are reliable enough to be used in production.', 'language': 'en', 'source': 'https://docs.smith.langchain.com/overview', 'title': 'LangSmith Overview and User Guide | ğŸ¦œï¸ğŸ› ï¸ LangSmith'}),
  Document(page_content='You can also quickly edit examples and add them to datasets to expand the surface area of your evaluation sets or to fine-tune a model for improved quality or reduced costs.Monitoring\u200bAfter all this, your app might finally ready to go in production. LangSmith can also be used to monitor your application in much the same way that you used for debugging. You can log all traces, visualize latency and token usage statistics, and troubleshoot specific issues as they arise. Each run can also be', metadata={'description': 'Building reliable LLM applications can be challenging. LangChain simplifies the initial setup, but there is still work needed to bring the performance of prompts, chains and agents up the level where they are reliable enough to be used in production.', 'language': 'en', 'source': 'https://docs.smith.langchain.com/overview', 'title': 'LangSmith Overview and User Guide | ğŸ¦œï¸ğŸ› ï¸ LangSmith'}),
  Document(page_content='Skip to main contentğŸ¦œï¸ğŸ› ï¸ LangSmith DocsPython DocsJS/TS DocsSearchGo to AppLangSmithOverviewTracingTesting & EvaluationOrganizationsHubLangSmith CookbookOverviewOn this pageLangSmith Overview and User GuideBuilding reliable LLM applications can be challenging. LangChain simplifies the initial setup, but there is still work needed to bring the performance of prompts, chains and agents up the level where they are reliable enough to be used in production.Over the past two months, we at LangChain', metadata={'description': 'Building reliable LLM applications can be challenging. LangChain simplifies the initial setup, but there is still work needed to bring the performance of prompts, chains and agents up the level where they are reliable enough to be used in production.', 'language': 'en', 'source': 'https://docs.smith.langchain.com/overview', 'title': 'LangSmith Overview and User Guide | ğŸ¦œï¸ğŸ› ï¸ LangSmith'}),
  Document(page_content='inputs, and see what happens. At some point though, our application is performing\nwell and we want to be more rigorous about testing changes. We can use a dataset\nthat weâ€™ve constructed along the way (see above). Alternatively, we could spend some\ntime constructing a small dataset by hand. For these situations, LangSmith simplifies', metadata={'description': 'Building reliable LLM applications can be challenging. LangChain simplifies the initial setup, but there is still work needed to bring the performance of prompts, chains and agents up the level where they are reliable enough to be used in production.', 'language': 'en', 'source': 'https://docs.smith.langchain.com/overview', 'title': 'LangSmith Overview and User Guide | ğŸ¦œï¸ğŸ› ï¸ LangSmith'})],
 'answer': 'Certainly! LangSmith simplifies the process of constructing and editing datasets, which is essential for testing and fine-tuning models. By quickly editing examples and adding them to datasets, you can expand the surface area of your evaluation sets, leading to improved model quality and potentially reduced costs. Additionally, LangSmith provides monitoring capabilities for your application, allowing you to log all traces, visualize latency and token usage statistics, and troubleshoot specific issues as they arise. This comprehensive monitoring functionality helps ensure the reliability and performance of your application in production.'}
```

å†…éƒ¨ã§ä½•ãŒèµ·ã“ã£ã¦ã„ã‚‹ã®ã‹ã‚’ç†è§£ã™ã‚‹ãŸã‚ã«ã€[ã“ã®LangSmithãƒˆãƒ¬ãƒ¼ã‚¹](https://smith.langchain.com/public/42f8993b-7d19-42d3-990a-6608a73c5824/r)ã¯æœ€åˆã®å‘¼ã³å‡ºã—ã‚’ç¤ºã—ã¦ã„ã¾ã™ã€‚ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®æœ€åˆã®ã‚¯ã‚¨ãƒªãŒãƒªãƒˆãƒªãƒ¼ãƒãƒ¼ã«ç›´æ¥æ¸¡ã•ã‚Œã€é©åˆ‡ãªãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆãŒè¿”ã•ã‚Œã‚‹ã“ã¨ãŒã‚ã‹ã‚Šã¾ã™ã€‚

ãƒ•ã‚©ãƒ­ãƒ¼ã‚¢ãƒƒãƒ—ã®è³ªå•ã«å¯¾ã™ã‚‹å‘¼ã³å‡ºã—ã¯ã€[ã“ã®LangSmithãƒˆãƒ¬ãƒ¼ã‚¹](https://smith.langchain.com/public/7b463791-868b-42bd-8035-17b471e9c7cd/r)ã§ç¤ºã•ã‚Œã¦ã„ã‚‹ã‚ˆã†ã«ã€ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®æœ€åˆã®è³ªå•ã‚’LangSmithã§ã®ãƒ†ã‚¹ãƒˆã«é–¢é€£ã™ã‚‹ã‚‚ã®ã«è¨€ã„æ›ãˆã€ã‚ˆã‚Šé«˜å“è³ªãªãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆã‚’å–å¾—ã—ã¾ã™ã€‚

ã“ã‚Œã§ä¼šè©±å‹ã®å–å¾—ãŒå¯èƒ½ãªãƒãƒ£ãƒƒãƒˆãƒœãƒƒãƒˆãŒå®Œæˆã—ã¾ã—ãŸï¼

## æ¬¡ã®ã‚¹ãƒ†ãƒƒãƒ—

ã‚ãªãŸã¯éå»ã®ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã‚„ãƒ‰ãƒ¡ã‚¤ãƒ³å›ºæœ‰ã®çŸ¥è­˜ã‚’çµ±åˆã—ã¦ç”Ÿæˆã§ãã‚‹ä¼šè©±å‹ãƒãƒ£ãƒƒãƒˆãƒœãƒƒãƒˆã‚’æ§‹ç¯‰ã™ã‚‹æ–¹æ³•ã‚’å­¦ã³ã¾ã—ãŸã€‚ã“ã‚Œã«é–¢ã—ã¦ä»–ã«ã‚‚å¤šãã®æœ€é©åŒ–ãŒå¯èƒ½ã§ã™ã€‚è©³ç´°ã«ã¤ã„ã¦ã¯ã€ä»¥ä¸‹ã®ãƒšãƒ¼ã‚¸ã‚’å‚ç…§ã—ã¦ãã ã•ã„:

- [ãƒ¡ãƒ¢ãƒªç®¡ç†](/docs/use_cases/chatbots/memory_management): ãƒãƒ£ãƒƒãƒˆå±¥æ­´ã‚’è‡ªå‹•çš„ã«æ›´æ–°ã™ã‚‹ã‚¬ã‚¤ãƒ‰ã‚„ã€é•·ã„ä¼šè©±ã‚’è¦ç´„ã€ãƒˆãƒªãƒŸãƒ³ã‚°ã€ã¾ãŸã¯ãã®ä»–ã®æ–¹æ³•ã§ä¿®æ­£ã—ã¦ãƒœãƒƒãƒˆã‚’é›†ä¸­ã•ã›ã‚‹æ–¹æ³•ã‚’å«ã¿ã¾ã™ã€‚
- [ãƒªãƒˆãƒªãƒ¼ãƒãƒ«](/docs/use_cases/chatbots/retrieval): ãƒãƒ£ãƒƒãƒˆãƒœãƒƒãƒˆã§ç•°ãªã‚‹ã‚¿ã‚¤ãƒ—ã®ãƒªãƒˆãƒªãƒ¼ãƒãƒ«ã‚’ä½¿ç”¨ã™ã‚‹æ–¹æ³•ã«ã¤ã„ã¦ã®è©³ç´°ãªè§£èª¬
- [ãƒ„ãƒ¼ãƒ«ã®ä½¿ç”¨](/docs/use_cases/chatbots/tool_usage): ä»–ã®APIã‚„ã‚·ã‚¹ãƒ†ãƒ ã¨é€£æºã™ã‚‹ãƒ„ãƒ¼ãƒ«ã‚’ãƒãƒ£ãƒƒãƒˆãƒœãƒƒãƒˆã«ä½¿ç”¨ã•ã›ã‚‹æ–¹æ³•
